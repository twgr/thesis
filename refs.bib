@article{lindsten2015uniform,
  title={Uniform ergodicity of the Particle {G}ibbs sampler},
  author={Lindsten, Fredrik and Douc, Randal and Moulines, Eric},
  journal={Scandinavian Journal of Statistics},
  volume={42},
  number={3},
  pages={775--797},
  year={2015},
  publisher={Wiley Online Library}
}

@article{chopin2015,
author = "Chopin, Nicolas and Singh, Sumeetpal S.",
doi = "10.3150/14-BEJ629",
fjournal = "Bernoulli",
journal = "Bernoulli",
month = "08",
number = "3",
pages = "1855--1883",
publisher = "Bernoulli Society for Mathematical Statistics and Probability",
title = "On particle {G}ibbs sampling",
volume = "21",
year = "2015"
}

@ARTICLE{andrieuDH2010,
  author = {Andrieu, Christophe and Doucet, Arnaud and Holenstein, Roman},
  title = {Particle {M}arkov chain {M}onte {C}arlo methods},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year = {2010},
  volume = {72},
  pages = {269--342},
  number = {3},
  issn = {1467-9868},
  publisher = {Blackwell Publishing Ltd}
}

@ARTICLE{berard2014lognormal,
  author = {B{\'e}rard, Jean and Del Moral, Pierre and Doucet, Arnaud},
  title = {A lognormal central limit theorem for particle approximations of
	normalizing constants},
  journal = {Electronic Journal of Probability},
  year = {2014},
  volume = {19},
  pages = {1--28},
  number = {94}
}

@BOOK{doucet2001sequential,
  title = {Sequential {M}onte {C}arlo methods in practice},
  publisher = {Springer Science \& Business Media},
  year = {2001},
  author = {Doucet, Arnaud and de Freitas, Nando and Gordon, Neil}
}

@ARTICLE{doucet2009tutorial,
  author = {Doucet, Arnaud and Johansen, Adam M},
  title = {A tutorial on particle filtering and smoothing: Fifteen years later},
  journal = {Handbook of Nonlinear Filtering},
  year = {2009},
  volume = {12},
  pages = {656--704},
  publisher = {Oxford, UK: Oxford University Press}
}

@ARTICLE{doucet2015efficient,
  author = {Doucet, Arnaud and Pitt, Michael and Deligiannidis, George and Kohn, Robert},
  title = {Efficient implementation of {M}arkov chain {M}onte {C}arlo when using an
	unbiased likelihood estimator},
  journal = {Biometrika},
  year = {2015},
  pages = {asu075},
  publisher = {Biometrika Trust}
}

@ARTICLE{everitt2012,
  author = { Richard G. Everitt },
  title = {Bayesian Parameter Estimation for Latent {M}arkov Random Fields and
	Social Networks},
  journal = {Journal of Computational and Graphical Statistics},
  year = {2012},
  volume = {21},
  pages = {940-960},
  number = {4}
}

@ARTICLE{gordon1993novel,
  author = {Gordon, Neil J and Salmond, David J and Smith, Adrian FM},
  title = {Novel approach to nonlinear/non-{G}aussian {B}ayesian state estimation},
  journal = {IEE Proceedings F (Radar and Signal Processing)},
  year = {1993},
  volume = {140},
  pages = {107--113},
  number = {2},
  organization = {IET}
}

@ARTICLE{huggins2015,
  author = {{Huggins}, Jonathan~H. and {Roy}, Daniel~M.},
  title = {{Convergence of sequential {M}onte {C}arlo-based sampling methods}},
  journal = {ArXiv e-prints, arXiv:1503.00966v1},
  year = {2015},
  month = mar,
  eprint = {1503.00966}
}

@ARTICLE{lindstenJS2014,
  author = {Lindsten, Fredrik and Jordan, Michael I. and Sch\"on, Thomas B.},
  title = {Particle {G}ibbs with ancestor sampling},
  journal = {Journal of Machine Learning Research},
  year = {2014},
  volume = {15},
  pages = {2145--2184},
  month = {june},
  owner = {lindsten},
  quality = {1},
  timestamp = {2014.06.05}
}

@ARTICLE{lindsten2013backward,
  author = {Lindsten, Fredrik and Sch{\"o}n, Thomas B},
  title = {Backward Simulation Methods for {M}onte {C}arlo Statistical Inference},
  journal = {Foundations and Trends in Machine Learning},
  year = {2013},
  volume = {6},
  pages = {1--143},
  number = {1},
  publisher = {now}
}

@INPROCEEDINGS{lindsten2012use,
  author = {Lindsten, Fredrik and Sch\"on, Thomas B},
  title = {On the use of backward simulation in the particle {G}ibbs sampler},
  booktitle = {Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International
	Conference on},
  year = {2012},
  pages = {3845--3848},
  organization = {IEEE}
}

@INPROCEEDINGS{vandemeent_aistats_2015,
  author = {van de Meent, Jan-Willem and Yang, Hongseok and Mansinghka, Vikash
	and Wood, Frank},
  title = {Particle {G}ibbs with Ancestor Sampling for Probabilistic Programs},
  booktitle = {Proceedings of the 18th International conference on Artificial Intelligence
	and Statistics},
  year = {2015},
  pages = {986--994}
}

@INPROCEEDINGS{naessethLS2015nested,
  author = {Naesseth, Christian A. and Lindsten, Fredrik and Sch\"{o}n, Thomas
	B},
  title = {Nested Sequential {M}onte {C}arlo Methods},
  booktitle = {The 32nd International Conference on Machine Learning},
  year = {2015},
  volume = {37},
  series = {JMLR W\&CP},
  pages = {1292--1301},
  address = {Lille, France},
  month = {jul}
}

@INCOLLECTION{naessethLS2014,
  author = {Naesseth, Christian A and Lindsten, Fredrik and Sch\"{o}n, Thomas
	B},
  title = {Sequential {M}onte {C}arlo for Graphical Models},
  booktitle = {Advances in Neural Information Processing Systems 27},
  publisher = {Curran Associates, Inc.},
  year = {2014},
  pages = {1862--1870}
}

@ARTICLE{pitt2012some,
  author = {Pitt, Michael K and dos Santos Silva, Ralph and Giordani, Paolo and
	Kohn, Robert},
  title = {On some properties of {M}arkov chain {M}onte {C}arlo simulation methods
	based on the particle filter},
  journal = {Journal of Econometrics},
  year = {2012},
  volume = {171},
  pages = {134--151},
  number = {2},
  publisher = {Elsevier}
}

@ARTICLE{rauch1965maximum,
  author = {Rauch, Herbert E and Striebel, CT and Tung, F},
  title = {Maximum likelihood estimates of linear dynamic systems},
  journal = {AIAA journal},
  year = {1965},
  volume = {3},
  pages = {1445--1450},
  number = {8}
}

@BOOK{robert2013monte,
  title = {Monte {C}arlo statistical methods},
  publisher = {Springer Science \& Business Media},
  year = {2013},
  author = {Robert, Christian and Casella, George}
}

@INCOLLECTION{tripuraneni2015,
  author = {Tripuraneni, Nilesh and Gu, Shixiang and Ge, Hong and Ghahramani,
	Zoubin},
  title = {Particle {G}ibbs for Infinite Hidden {M}arkov {M}odels},
  booktitle = {Advances in Neural Information Processing Systems 28},
  publisher = {Curran Associates, Inc.},
  year = {2015},
  pages = {2386--2394}
}

@INCOLLECTION{ValeraFSPC2015,
  author = {Valera, Isabel and Francisco, Fran and Svensson, Lennart and Perez-Cruz,
	Fernando},
  title = {Infinite Factorial Dynamical Model},
  booktitle = {Advances in Neural Information Processing Systems 28},
  publisher = {Curran Associates, Inc.},
  year = {2015},
  pages = {1657--1665}
}

@ARTICLE{van2008partially,
  author = {Van Dyk, David A and Park, Taeyoung},
  title = {Partially collapsed {G}ibbs samplers: Theory and methods},
  journal = {Journal of the American Statistical Association},
  year = {2008},
  volume = {103},
  pages = {790--796},
  number = {482},
  publisher = {Taylor \& Francis}
}

@ARTICLE{whiteley2010efficient,
  author = {Whiteley, Nick and Andrieu, Christophe and Doucet, Arnaud},
  title = {Efficient {B}ayesian inference for switching state-space models using
	discrete particle {M}arkov chain {M}onte {C}arlo methods},
  journal = {ArXiv e-prints, arXiv:1011.2437},
  year = {2010}
}

@ARTICLE{whiteley2016,
  author = {Whiteley, Nick and Lee, Anthony and Heine, Kari},
  title = {On the role of interaction in sequential {M}onte {C}arlo algorithms},
  journal = {Bernoulli},
  year = {2016},
  volume = {22},
  pages = {494--529},
  number = {1},
  month = {02},
  fjournal = {Bernoulli},
  publisher = {Bernoulli Society for Mathematical Statistics and Probability},
}

@INPROCEEDINGS{wood2014new,
  author = {Wood, Frank and van de Meent, Jan Willem and Mansinghka, Vikash},
  title = {A new approach to probabilistic programming inference},
  booktitle = {Proceedings of the 17th International conference on Artificial Intelligence
	and Statistics},
  year = {2014},
  pages = {2--46}
}

@phdthesis{holenstein2009particle,
	title={Particle {M}arkov chain {M}onte {C}arlo},
	author={Holenstein, Roman},
	year={2009},
	school={The University Of British Columbia (Vancouver}
}

@article{hastings1970monte,
	title={Monte {C}arlo sampling methods using {M}arkov chains and their applications},
	author={Hastings, W Keith},
	journal={Biometrika},
	volume={57},
	number={1},
	pages={97--109},
	year={1970},
	publisher={Biometrika Trust}
}

@inproceedings{rainforth-icml-2016,
	title = {Interacting Particle {M}arkov Chain {M}onte {C}arlo},
	author = {Rainforth, Tom and Naesseth, Christian A and Lindsten, Fredrik and Paige, Brooks and van de Meent, Jan-Willem and Doucet, Arnaud and Wood, Frank},
	booktitle = {Proceedings of the 33rd International Conference on Machine Learning},
	series = {JMLR: W\&CP},
	volume = {48},
	year = {2016}
}

@article{leone1961folded,
	author = { F. C.   Leone  and  L. S.   Nelson  and  R. B.   Nottingham },
	title = {The Folded Normal Distribution},
	journal = {Technometrics},
	volume = {3},
	number = {4},
	pages = {543-550},
	year = {1961},
}


@book{goodman_book_2014,
	annote = {Accessed: 2015-10-16},
	author = {Goodman, Noah D and Stuhlm{\"{u}}ller, Andreas},
	howpublished = {$\backslash$url{\{}http://dippl.org{\}}},
	title = {{The Design and Implementation of Probabilistic Programming Languages}},
	year = {2014}
}

@book{lizotte2008practical,
	title={Practical {B}ayesian optimization},
	author={Lizotte, Daniel James},
	year={2008},
	publisher={University of Alberta}
}

@article{fisher_ag_1936,
	author = {Fisher, Ronald A},
	journal = {Annals of eugenics},
	number = {2},
	pages = {179--188},
	publisher = {Wiley Online Library},
	title = {{The use of multiple measurements in taxonomic problems}},
	volume = {7},
	year = {1936}
}

@misc{chaoscope,
	title={http://www.chaoscope.org/}
}

@article{xie2012energy2d,
	author = "Xie, Charles",
	title = "Interactive Heat Transfer Simulations for Everyone",
	journal = "The Physics Teacher",
	year = "2012",
	volume = "50",
	number = "4", 
	pages = "237-240",
}

@inproceedings{snoek2012practical,
	title={Practical {B}ayesian optimization of machine learning algorithms},
	author={Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
	booktitle={NIPS},
	pages={2951--2959},
	year={2012}
}

@article{jones1998efficient,
	title={Efficient global optimization of expensive black-box functions},
	author={Jones, Donald R and Schonlau, Matthias and Welch, William J},
	journal={J Global Optim},
	volume={13},
	number={4},
	pages={455--492},
	year={1998},
	publisher={Springer}
}

@incollection{hutter2011sequential,
	title={Sequential model-based optimization for general algorithm configuration},
	author={Hutter, Frank and Hoos, Holger H and Leyton-Brown, Kevin},
	booktitle={Learn. Intell. Optim.},
	pages={507--523},
	year={2011},
	publisher={Springer}
}

@article{stuckman1988global,
	title={A global search method for optimizing nonlinear systems},
	author={Stuckman, Bruce E},
	journal={Systems, Man and Cybernetics, IEEE Transactions on},
	volume={18},
	number={6},
	pages={965--977},
	year={1988},
	publisher={IEEE}
}

@inproceedings{bergstra2011algorithms,
	title={Algorithms for hyper-parameter optimization},
	author={Bergstra, James S and Bardenet, R{\'e}mi and Bengio, Yoshua and K{\'e}gl, Bal{\'a}zs},
	booktitle={NIPS},
	pages={2546--2554},
	year={2011}
}

@book{rasmussen2006gaussian,
	title={Gaussian Processes for Machine Learning},
	author={Rasmussen, Carl and Williams, Chris},
	year={2006},
	publisher={MIT Press}
}

@article{jones2001taxonomy,
	title={A taxonomy of global optimization methods based on response surfaces},
	author={Jones, Donald R},
	journal={J Global Optim},
	volume={21},
	number={4},
	pages={345--383},
	year={2001},
	publisher={Springer}
}


@article{jones1993lipschitzian,
	title={Lipschitzian optimization without the Lipschitz constant},
	author={Jones, Donald R and Perttunen, Cary D and Stuckman, Bruce E},
	journal={J of Optim. Theory Appl.},
	volume={79},
	number={1},
	pages={157--181},
	year={1993},
	publisher={Springer}
}

@article{kolda2003optimization,
	title={Optimization by direct search: New perspectives on some classical and modern methods},
	author={Kolda, Tamara G and Lewis, Robert Michael and Torczon, Virginia},
	journal={SIAM review},
	volume={45},
	number={3},
	pages={385--482},
	year={2003},
	publisher={SIAM}
}

@article{earl2005parallel,
	title={Parallel tempering: Theory, applications, and new perspectives},
	author={Earl, David J and Deem, Michael W},
	journal={Physical Chemistry Chemical Physics},
	volume={7},
	number={23},
	pages={3910--3916},
	year={2005},
	publisher={Royal Society of Chemistry}
}

@book{goldberg2006genetic,
	title={Genetic algorithms},
	author={Goldberg, David E},
	year={2006},
	publisher={Pearson Education India}
}

@article{bergstra2012random,
	title={Random search for hyper-parameter optimization},
	author={Bergstra, James and Bengio, Yoshua},
	journal={J. Mach, Learn. Res.},
	volume={13},
	number={1},
	pages={281--305},
	year={2012},
	publisher={JMLR. org}
}

@incollection{coulom2007efficient,
	title={Efficient selectivity and backup operators in Monte-Carlo tree search},
	author={Coulom, R{\'e}mi},
	booktitle={Computers and games},
	pages={72--83},
	year={2007},
	publisher={Springer}
}

@article{solis1981minimization,
	title={Minimization by random search techniques},
	author={Solis, Francisco J and Wets, Roger J-B},
	journal={Mathematics of operations research},
	volume={6},
	number={1},
	pages={19--30},
	year={1981},
	publisher={INFORMS}
}

@inproceedings{zhou2008particle,
	title={A particle filtering framework for randomized optimization algorithms},
	author={Zhou, Enlu and Fu, Michael C and Marcus, Steven I},
	booktitle={Proceedings of the 40th Conference on Winter Simulation},
	pages={647--654},
	year={2008},
	organization={Winter Simulation Conference}
}

@incollection{benassi2012bayesian,
	title={{B}ayesian optimization using sequential {M}onte {C}arlo},
	author={Benassi, Romain and Bect, Julien and Vazquez, Emmanuel},
	booktitle={Learning and Intelligent Optimization},
	pages={339--342},
	year={2012},
	publisher={Springer}
}

@book{bertsekas1995dynamic,
	title={Dynamic programming and optimal control},
	author={Bertsekas, Dimitri P and Bertsekas, Dimitri P and Bertsekas, Dimitri P and Bertsekas, Dimitri P},
	volume={1},
	number={2},
	year={1995},
	publisher={Athena Scientific Belmont, MA}
}

@incollection{couetoux2011continuous,
	title={Continuous upper confidence trees},
	author={Cou{\"e}toux, Adrien and Hoock, Jean-Baptiste and Sokolovska, Nataliya and Teytaud, Olivier and Bonnard, Nicolas},
	booktitle={Learning and Intelligent Optimization},
	pages={433--445},
	year={2011},
	publisher={Springer}
}

@phdthesis{couetoux2013monte,
	title={Monte carlo tree search for continuous and stochastic sequential decision making problems},
	author={Couetoux, Adrien},
	year={2013},
	school={Universit{\'e} Paris Sud-Paris XI}
}

@article{tolpin2015output,
	title={Output-Sensitive Adaptive Metropolis-Hastings for Probabilistic Programs},
	author={Tolpin, David and van de Meent, Jan Willem and Paige, Brooks and Wood, Frank and Betzalel, Oded and Felner, Ariel and Shimony, Solomon Eyal and Beja, Tal and Karpas, Erez and Hay, Nicholas and others},
	journal={arXiv preprint arXiv:1501.05677},
	year={2015}
}

@book{deb2001multi,
	title={Multi-objective optimization using evolutionary algorithms},
	author={Deb, Kalyanmoy},
	volume={16},
	year={2001},
	publisher={John Wiley and Sons}
}

@book{banzhaf1998genetic,
	title={Genetic programming: an introduction},
	author={Banzhaf, Wolfgang and Nordin, Peter and Keller, Robert E and Francone, Frank D},
	volume={1},
	year={1998},
	publisher={Morgan Kaufmann San Francisco}
}

@inproceedings{johnson2006adaptor,
	title={Adaptor grammars: A framework for specifying compositional nonparametric {B}ayesian models},
	author={Johnson, Mark and Griffiths, Thomas L and Goldwater, Sharon},
	booktitle={Advances in neural information processing systems},
	pages={641--648},
	year={2006}
}

@book{back1996evolutionary,
	title={Evolutionary algorithms in theory and practice: evolution strategies, evolutionary programming, genetic algorithms},
	author={B{\"a}ck, Thomas},
	year={1996},
	publisher={Oxford university press}
}

@article{aarts1988simulated,
	title={Simulated annealing and Boltzmann machines},
	author={Aarts, Emile and Korst, Jan},
	year={1988},
	publisher={New York, NY; John Wiley and Sons Inc.}
}

@article{sugita1999replica,
	title={Replica-exchange molecular dynamics method for protein folding},
	author={Sugita, Yuji and Okamoto, Yuko},
	journal={Chemical physics letters},
	volume={314},
	number={1},
	pages={141--151},
	year={1999},
	publisher={Elsevier}
}

@article{geyer1995annealing,
	title={Annealing Markov chain Monte Carlo with applications to ancestral inference},
	author={Geyer, Charles J and Thompson, Elizabeth A},
	journal={Journal of the American Statistical Association},
	volume={90},
	number={431},
	pages={909--920},
	year={1995},
	publisher={Taylor \& Francis Group}
}

@inproceedings{ong2002hyperkernels,
	title={Hyperkernels},
	author={Ong, Cheng S and Williamson, Robert C and Smola, Alex J},
	booktitle={Advances in neural information processing systems},
	pages={478--485},
	year={2002}
}

@inproceedings{osborne2009gaussian,
	title={Gaussian processes for global optimization},
	author={Osborne, Michael A and Garnett, Roman and Roberts, Stephen J},
	booktitle={3rd international conference on learning and intelligent optimization (LION3)},
	pages={1--15},
	year={2009}
}

@book{mockus2012bayesian,
	title={{B}ayesian approach to global optimization: theory and applications},
	author={Mockus, Jonas},
	volume={37},
	year={2012},
	publisher={Springer Science \& Business Media}
}

@inproceedings{murray2010slice,
	title={Slice sampling covariance hyperparameters of latent Gaussian models},
	author={Murray, Iain and Adams, Ryan P},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1732--1740},
	year={2010}
}

@inproceedings{garnett2010bayesian,
	title={{B}ayesian optimization for sensor set selection},
	author={Garnett, Roman and Osborne, Michael A and Roberts, Stephen J},
	booktitle={Proceedings of the 9th ACM/IEEE International Conference on Information Processing in Sensor Networks},
	pages={209--219},
	year={2010},
	organization={ACM}
}

@article{brochu2010tutorial,
	title={A tutorial on {B}ayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning},
	author={Brochu, Eric and Cora, Vlad M and De Freitas, Nando},
	journal={arXiv preprint arXiv:1012.2599},
	year={2010}
}

@article{srinivas2009gaussian,
	title={Gaussian process optimization in the bandit setting: No regret and experimental design},
	author={Srinivas, Niranjan and Krause, Andreas and Kakade, Sham M and Seeger, Matthias},
	journal={arXiv preprint arXiv:0912.3995},
	year={2009}
}

@inproceedings{smola2007hilbert,
	title={A Hilbert space embedding for distributions},
	author={Smola, Alex and Gretton, Arthur and Song, Le and Sch{\"o}lkopf, Bernhard},
	booktitle={Algorithmic Learning Theory},
	pages={13--31},
	year={2007},
	organization={Springer}
}

@article{scholkopf2015computing,
	title={Computing Functions of Random Variables via Reproducing Kernel Hilbert Space Representations},
	author={Sch{\"o}lkopf, Bernhard and Muandet, Krikamol and Fukumizu, Kenji and Peters, Jonas},
	journal={arXiv preprint arXiv:1501.06794},
	year={2015}
}

@article{hutter2013kernel,
	title={A Kernel for Hierarchical Parameter Spaces},
	author={Hutter, Frank and Osborne, Michael A},
	journal={arXiv preprint arXiv:1310.5738},
	year={2013}
}

@article{swersky2014raiders,
	title={Raiders of the lost architecture: Kernels for {B}ayesian optimization in conditional parameter spaces},
	author={Swersky, Kevin and Duvenaud, David and Snoek, Jasper and Hutter, Frank and Osborne, Michael A},
	journal={arXiv preprint arXiv:1409.4011},
	year={2014}
}

@article{duvenaud2013structure,
	title={Structure discovery in nonparametric regression through compositional kernel search},
	author={Duvenaud, David and Lloyd, James Robert and Grosse, Roger and Tenenbaum, Joshua B and Ghahramani, Zoubin},
	journal={arXiv preprint arXiv:1302.4922},
	year={2013}
}

@incollection{kronberger2013evolution,
	title={Evolution of covariance functions for gaussian process regression using genetic programming},
	author={Kronberger, Gabriel and Kommenda, Michael},
	booktitle={Computer Aided Systems Theory-EUROCAST 2013},
	pages={308--315},
	year={2013},
	publisher={Springer}
}

@article{gelbart2014bayesian,
	title={{B}ayesian optimization with unknown constraints},
	author={Gelbart, Michael A and Snoek, Jasper and Adams, Ryan P},
	journal={arXiv preprint arXiv:1403.5607},
	year={2014}
}

@inproceedings{swersky2013multi,
	title={Multi-task {B}ayesian optimization},
	author={Swersky, Kevin and Snoek, Jasper and Adams, Ryan P},
	booktitle={Advances in Neural Information Processing Systems},
	pages={2004--2012},
	year={2013}
}

@article{goodman2008church,
	title={Church: a language for generative models},
	author={Goodman, Noah D and Mansinghka, Vikash K and Roy, Daniel and Bonawitz, Keith and Tenenbaum, Joshua B},
	year={2008}
}

@article{mansinghka2014venture,
	title={Venture: a higher-order probabilistic programming platform with programmable inference},
	author={Mansinghka, Vikash and Selsam, Daniel and Perov, Yura},
	journal={arXiv preprint arXiv:1404.0099},
	year={2014}
}

@article{pfeffer2009figaro,
	title={Figaro: An object-oriented probabilistic programming language},
	author={Pfeffer, Avi},
	journal={Charles River Analytics Technical Report},
	volume={137},
	year={2009}
}

@inproceedings{gordon2014probabilistic,
	title={Probabilistic programming},
	author={Gordon, Andrew D and Henzinger, Thomas A and Nori, Aditya V and Rajamani, Sriram K},
	booktitle={Proceedings of the on Future of Software Engineering},
	pages={167--181},
	year={2014},
	organization={ACM}
}

@article{paige2014compilation,
	title={A compilation target for probabilistic programming languages},
	author={Paige, Brooks and Wood, Frank},
	journal={arXiv preprint arXiv:1403.0504},
	year={2014}
}

@article{spiegelhalter1996bugs,
	title={BUGS 0.5: {B}ayesian inference using Gibbs sampling manual (version ii)},
	author={Spiegelhalter, David and Thomas, Andrew and Best, Nicky and Gilks, Wally},
	journal={MRC Biostatistics Unit, Cambridge},
	year={1996}
}

@misc{stan-software:2015,
	author = {},
	year = {2015},
	title = {Stan: A C++ Library for Probability and Sampling,
	Version 2.7.0},
}

@article{ranganath2013black,
	title={Black box variational inference},
	author={Ranganath, Rajesh and Gerrish, Sean and Blei, David M},
	journal={arXiv preprint arXiv:1401.0118},
	year={2013}
}

@article{hastings1970monte,
	title={Monte Carlo sampling methods using Markov chains and their applications},
	author={Hastings, W Keith},
	journal={Biometrika},
	volume={57},
	number={1},
	pages={97--109},
	year={1970},
	publisher={Biometrika Trust}
}

@article{neal2003slice,
	title={Slice sampling},
	author={Neal, Radford M},
	journal={Annals of statistics},
	pages={705--741},
	year={2003},
	publisher={JSTOR}
}

@article{glynn1989importance,
	title={Importance sampling for stochastic simulations},
	author={Glynn, Peter W and Iglehart, Donald L},
	journal={Management Science},
	volume={35},
	number={11},
	pages={1367--1392},
	year={1989},
	publisher={INFORMS}
}

@inproceedings{wingate2011lightweight,
	title={Lightweight implementations of probabilistic programming languages via transformational compilation},
	author={Wingate, David and Stuhlmueller, Andreas and Goodman, Noah D},
	booktitle={AISTATS},
	pages={770--778},
	year={2011}
}

@book{smith2013sequential,
	title={Sequential Monte Carlo methods in practice},
	author={Smith, Adrian and Doucet, Arnaud and de Freitas, Nando and Gordon, Neil},
	year={2013},
	publisher={Springer Science \& Business Media}
}

@inproceedings{snoek2015scalable,
	title={Scalable {B}ayesian optimization using deep neural networks},
	author={Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Mostofa and Ali, Mostofa and Adams, Ryan P and others},
	booktitle={ICML},
	year={2015}
}

@article{chapelle2006semi,
	title={Semi-supervised learning},
	author={Chapelle, Olivier and Sch{\"o}lkopf, Bernhard and Zien, Alexander and others},
	year={2006},
	publisher={MIT press Cambridge}
}

@article{cappe2007overview,
	title={An overview of existing methods and recent advances in sequential Monte Carlo},
	author={Capp{\'e}, Olivier and Godsill, Simon J and Moulines, Eric},
	journal={Proceedings of the IEEE},
	volume={95},
	number={5},
	pages={899--924},
	year={2007},
	publisher={IEEE}
}

@article{neal2011mcmc,
	title={MCMC using Hamiltonian dynamics},
	author={Neal, Radford M},
	journal={Handbook of Markov Chain Monte Carlo},
	volume={2},
	year={2011}
}

@book{stein2012interpolation,
	title={Interpolation of spatial data: some theory for kriging},
	author={Stein, Michael L},
	year={2012},
	publisher={Springer Science \& Business Media}
}

@book{pickover1995pattern,
	title={The pattern book: Fractals, art, and nature},
	author={Pickover, Clifford A},
	year={1995},
	publisher={World Scientific}
}

@article{moon1996expectation,
	title={The expectation-maximization algorithm},
	author={Moon, Tood K},
	journal={Signal processing magazine, IEEE},
	volume={13},
	number={6},
	pages={47--60},
	year={1996},
	publisher={IEEE}
}

@book{devaney1989introduction,
	title={An introduction to chaotic dynamical systems},
	author={Devaney, Robert L and Devaney, Luke and Devaney, Luke},
	volume={13046},
	year={1989},
	publisher={Addison-Wesley Reading}
}

@article{iman2008latin,
	title={Latin hypercube sampling},
	author={Iman, Ronald L},
	journal={Encyclopedia of quantitative risk analysis and assessment},
	year={2008},
	publisher={Wiley Online Library}
}

@article{branin1972method,
	title={A method for finding multiple extrema of a function of n variables},
	author={Branin, FH and Hoo, SK},
	journal={Numerical Methods},
	pages={231--237},
	year={1972}
}

@misc{keane1994bump,
	title={Bump: A Hard (?) Problem},
	author={Keane, AJ},
	year={1994}
}

@inproceedings{hernandez2014predictive,
	title={Predictive entropy search for efficient global optimization of black-box functions},
	author={Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and Hoffman, Matthew W and Ghahramani, Zoubin},
	booktitle={NIPS},
	pages={918--926},
	year={2014}
}

@article{lee2015variance,
	title={Variance estimation and allocation in the particle filter},
	author={Lee, Anthony and Whiteley, Nick},
	journal={arXiv preprint arXiv:1509.00394},
	year={2015}
}

@inproceedings{ruan2003chaotic,
	title={A chaotic secure communication scheme with extended {K}alman filter based parameter estimation},
	author={Ruan, Huawei and Zhai, Tongyan and Yaz, Edwin Engin},
	booktitle={Control Applications, 2003. CCA 2003. Proceedings of 2003 IEEE Conference on},
	volume={1},
	pages={404--408},
	year={2003},
	organization={IEEE}
}

@article{fujii2013extended,
	title={Extended {K}alman Filter},
	author={Fujii, Keisuke},
	journal={Refernce Manual},
	year={2013}
}

@inproceedings{paige2014asynchronous,
	title={Asynchronous Anytime Sequential Monte Carlo},
	author={Paige, Brooks and Wood, Frank and Doucet, Arnaud and Teh, Yee Whye},
	booktitle={NIPS},
	pages={3410--3418},
	year={2014}
}

@article{glynn1989importance,
	title={Importance sampling for stochastic simulations},
	author={Glynn, Peter W and Iglehart, Donald L},
	journal={Management Science},
	volume={35},
	number={11},
	pages={1367--1392},
	year={1989},
	publisher={INFORMS}
}



@inproceedings{milch_ijcai_2005,
	author =        {Milch, B and Marthi, B and Russell, S and
	Sontag, D and Ong, D. L. and Kolobov, A},
	booktitle =     {IJCAI},
	title =         {{BLOG : Probabilistic Models with Unknown Objects}},
	year =          {2005},
}

@article{deraedt_ijcai_2007,
	author =        {{De Raedt}, Luc and Kimmig, Angelika and
	Toivonen, Hannu},
	journal =       {IJCAI},
	pages =         {2468--2473},
	title =         {{ProbLog: A probabilistic prolog and its application
	in link discovery}},
	year =          {2007},
	abstract =      {We introduce ProbLog, a probabilistic extension of
	Prolog. A ProbLog program defines a distribution over
	logic programs by specifying for each clause the
	probability that it belongs to a randomly sampled
	program, and these probabilities are mutually
	independent. The semantics of ProbLog is then defined
	by the success probability of a query, which
	corresponds to the probability that the query
	succeeds in a randomly sampled program. The key
	contribution of this paper is the introduction of an
	effective solver for computing success probabilities.
	It essentially combines SLD-resolution with methods
	for computing the probability of Boolean formulae.
	Our implementation further employs an approximation
	algorithm that combines iterative deepening with
	binary decision diagrams. We report on experiments in
	the context of discovering links in real biological
	networks, a demonstration of the practical usefulness
	of the approach.},
}

@inproceedings{goodman_uai_2008,
	author =        {Goodman, N and Mansinghka, V and
	Roy, D M and Bonawitz, K and
	Tenenbaum, J B},
	booktitle =     {UAI},
	pages =         {220--229},
	title =         {{Church: a language for generative models}},
	year =          {2008},
}

@techreport{pfeffer_rep_2009,
	author =        {Pfeffer, Avi},
	booktitle =     {Charles River Analytics Technical Report},
	pages =         {1--9},
	title =         {{Figaro: An object-oriented probabilistic programming
	language}},
	volume =        {137},
	year =          {2009},
	abstract =      {We introduce an object - oriented paradigm for
	probabilistic programming , embodied in the Figaro
	language . Models in Figaro are objects, and may have
	properties such as conditions, constraints and
	relationships to other objects. Figaro model classes
	are ...},
	isbn =          {9781577354260},
}

@inproceedings{mccallum_nips_2009,
	author =        {McCallum, A and Schultz, K and Singh, S},
	booktitle =     {NIPS},
	pages =         {1249--1257},
	title =         {{Factorie: Probabilistic programming via imperatively
	defined factor graphs}},
	volume =        {22},
	year =          {2009},
	abstract =      {Discriminatively trained undirected graphical models
	have had wide empirical success, and there has been
	increasing interest in toolkits that ease their
	applica- tion to complex relational data. The power
	in relational models is in their repeated structure
	and tied parameters; at issue is how to define these
	structures in a pow- erful and flexible way. Rather
	than using a declarative language, such as SQL or
	first-order logic, we advocate using an imperative
	language to express various aspects of model
	structure, inference, and learning. By combining the
	traditional, declarative, statistical semantics of
	factor graphs with imperative definitions of their
	construction and operation, we allow the user to mix
	declarative and proce- dural domain knowledge, and
	also gain significant efficiencies. We have imple-
	mented such imperatively defined factor graphs in a
	system we call FACTORIE, a software library for an
	object-oriented, strongly-typed, functional language.
	In experimental comparisons to Markov Logic Networks
	on joint segmentation and coreference, we find our
	approach to be 3-15 times faster while reducing error
	by 20-25{\%}—achieving a new state of the art.},
}

@misc{minka_software_2010,
	author =        {Minka, T and Winn, J and Guiver, J and Knowles, D},
	title =         {{Infer .NET 2.4, Microsoft Research Cambridge}},
	year =          {2010},
}

@article{paige_icml_2014,
	author =        {Paige, Brooks and Wood, Frank},
	journal =       {ICML},
	title =         {{A Compilation Target for Probabilistic Programming
	Languages}},
	volume =        {32},
	year =          {2014},
}

@article{mansinghka_arxiv_2014,
	author =        {Mansinghka, Vikash and Selsam, Daniel and
	Perov, Yura},
	journal =       {arXiv},
	month =         {mar},
	pages =         {78},
	title =         {{Venture: a higher-order probabilistic programming
	platform with programmable inference}},
	year =          {2014},
	abstract =      {We describe Venture, an interactive virtual machine
	for probabilistic programming that aims to be
	sufficiently expressive, extensible, and efficient
	for general-purpose use. Like Church, probabilistic
	models and inference problems in Venture are
	specified via a Turing-complete, higher-order
	probabilistic language descended from Lisp. Unlike
	Church, Venture also provides a compositional
	language for custom inference strategies built out of
	scalable exact and approximate techniques. We also
	describe four key aspects of Venture's implementation
	that build on ideas from probabilistic graphical
	models. First, we describe the stochastic procedure
	interface (SPI) that specifies and encapsulates
	primitive random variables. The SPI supports custom
	control flow, higher-order probabilistic procedures,
	partially exchangeable sequences and
	``likelihood-free'' stochastic simulators. It also
	supports external models that do inference over
	latent variables hidden from Venture. Second, we
	describe probabilistic execution traces (PETs), which
	represent execution histories of Venture programs.
	PETs capture conditional dependencies, existential
	dependencies and exchangeable coupling. Third, we
	describe partitions of execution histories called
	scaffolds that factor global inference problems into
	coherent sub-problems. Finally, we describe a family
	of stochastic regeneration algorithms for efficiently
	modifying PET fragments contained within scaffolds.
	Stochastic regeneration linear runtime scaling in
	cases where many previous approaches scaled
	quadratically. We show how to use stochastic
	regeneration and the SPI to implement general-purpose
	inference strategies such as Metropolis-Hastings,
	Gibbs sampling, and blocked proposals based on
	particle Markov chain Monte Carlo and mean-field
	variational inference techniques.},
}

@misc{stan_software_2014,
	author =        {{Stan Development Team}},
	title =         {{Stan: A C++ Library for Probability and Sampling,
	Version 2.4}},
	year =          {2014},
}

@article{wainwright_ftml_2008,
	author =        {Wainwright, Martin J and Jordan, Michael I},
	journal =       {Foundations and Trends in Machine Learning},
	number =        {1–2},
	pages =         {1--305},
	publisher =     {now publishers Inc},
	title =         {{Graphical Models, Exponential Families, and
	Variational Inference}},
	volume =        {1},
	year =          {2008},
}

@article{wingate_arxiv_2013,
	author =        {Wingate, David and Weber, Theo},
	journal =       {arXiv preprint arXiv:1301.1299},
	pages =         {1--7},
	title =         {{Automated variational inference in probabilistic
	programming}},
	year =          {2013},
	abstract =      {We present a new algorithm for approximate inference
	in probabilistic programs, based on a stochastic
	gradient for variational programs. This method is
	efficient without restrictions on the probabilistic
	program; it is particularly practical for
	distributions which are not analytically tractable,
	including highly structured distributions that arise
	in probabilistic programs. We show how to
	automatically derive mean-field probabilistic
	programs and optimize them, and demonstrate that our
	perspective improves inference efficiency over other
	algorithms.},
}

@inproceedings{ranganath_aistats_2014,
	author =        {Ranganath, Rajesh and Gerrish, Sean and
	Blei, David M},
	booktitle =     {AISTATS},
	title =         {{Black Box Variational Inference}},
	year =          {2014},
	abstract =      {Variational inference has become a widely used method
	to approximate posteriors in complex latent variables
	models. However, deriving a variational inference
	algorithm generally requires significant
	model-specific analysis, and these efforts can hinder
	and deter us from quickly developing and exploring a
	variety of models for a problem at hand. In this
	paper, we present a "black box" variational inference
	algorithm, one that can be quickly applied to many
	models with little additional derivation. Our method
	is based on a stochastic optimization of the
	variational objective where the noisy gradient is
	computed from Monte Carlo samples from the
	variational distribution. We develop a number of
	methods to reduce the variance of the gradient,
	always maintaining the criterion that we want to
	avoid difficult model-based derivations. We evaluate
	our method against the corresponding black box
	sampling based methods. We find that our method
	reaches better predictive likelihoods much faster
	than sampling methods. Finally, we demonstrate that
	Black Box Variational Inference lets us easily
	explore a wide space of models by quickly
	constructing and evaluating several models of
	longitudinal healthcare data.},
}

@book{maritz_mono_1989,
	author =        {Maritz, J S and Lwin, T},
	booktitle =     {Monographs on statistics and applied probability},
	publisher =     {Chapman and Hall, London},
	title =         {{Empirical Bayes methods}},
	volume =        {35},
	year =          {1989},
	isbn =          {0412277603},
}

@article{vandemeent_arxiv_2015b,
	author =        {van de Meent, Jan-Willem and Tolpin, David and
	Paige, Brooks and Wood, Frank},
	pages =         {1--22},
	title =         {{Black-Box Policy Search with Probabilistic
	Programs}},
	year =          {2015},
	abstract =      {In this work, we explore how probabilistic programs
	can be used to represent policies in sequential
	decision problems. In this formulation, a
	probabilistic program is a black-box stochastic
	simulator for both the problem domain and the agent.
	We relate classic policy gradient techniques to
	recently introduced black-box variational methods
	which generalize to probabilistic program inference.
	We present case studies in the Canadian traveler
	problem, Rock Sample, and a benchmark for optimal
	diagnosis inspired by Guess Who. Each study
	illustrates how programs can efficiently represent
	policies using moderate numbers of parameters.},
}

@article{toussaint_nc_2006,
	author =        {Toussaint, Marc and Harmeling, Stefan and
	Storkey, Amos},
	journal =       {Neural Computation},
	number =        {December},
	pages =         {357--373},
	title =         {{Probabilistic inference for solving (PO)MDPs}},
	volume =        {31},
	year =          {2006},
	abstract =      {The development of probabilistic inference techniques
	has made considerable progress in recent years, in
	particular with respect to exploiting the structure
	(e.g., factored, hierarchical or relational) of
	discrete and continuous problem domains. We show that
	these techniques can be used also for solving Markov
	Decision Processes (MDPs) or partial observable MDPs
	(POMDPs) when formulated in terms of a structured
	dynamic {B}ayesian network (DBN). The approach is based
	on an equivalence between maximization of the
	expected future return in the time-unlimited MDP and
	likelihood maximization in a related mixture of
	finite-time MDPs. This allows us to use expectation
	maximization (EM) for computing optimal policies,
	using arbitrary inference techniques in the E-step.
	Unlike previous approaches we can show that this
	actually optimizes the discounted expected future
	return for arbitrary reward functions and without
	assuming an ad hoc finite total time. We first
	develop the approach for standardMDPs and demonstrate
	it using exact inference on a discrete maze and
	Gaussian belief state propagation in non-linear
	stochastic optimal control problems. Then we present
	an extension for solving POMDPs. We consider an agent
	model that includes an internal memory variable used
	for gating reactive behaviors. Using exact inference
	on the respective DBN, the EM-algorithm solves
	complex maze problems by learning appropriate
	internal memory representations.},
}

@article{botvinick_tcs_2012,
	author =        {Botvinick, Matthew and Toussaint, Marc},
	journal =       {Trends in Cognitive Sciences},
	number =        {10},
	pages =         {485--488},
	title =         {{Planning as inference}},
	volume =        {16},
	year =          {2012},
	abstract =      {Recent developments in decision-making research are
	bringing the topic of planning back to center stage
	in cognitive science. This renewed interest reopens
	an old, but still unanswered question: how exactly
	does planning happen? What are the underlying
	information processing operations and how are they
	implemented in the brain? Although a range of
	interesting possibilities exists, recent work has
	introduced a potentially transformative new idea,
	according to which planning is accomplished through
	probabilistic inference. © 2012.},
}

@article{deisenroth_ftr_2011,
	author =        {Deisenroth, Marc Peter and Nuemann, Gerhard and
	Peters, Jan},
	journal =       {Foundations and Trends in Robotics},
	number =        {2011},
	pages =         {1--142},
	title =         {{A Survey on Policy Search for Robotics}},
	volume =        {2},
	year =          {2011},
	abstract =      {Policy search is a subfield in reinforcement learning
	which focuses on finding good parameters for a given
	policy parametrization. It is well suited for
	robotics as it can cope with high-dimensional state
	and action spaces, one of the main challenges in
	robot learning. We review recent successes of both
	model-free and model-based policy search in robot
	learning. Model-free policy search is a general
	approach to learn policies based on sampled
	trajectories. We classify model-free methods based on
	their policy evaluation strategy, policy update
	strategy, and exploration strategy and present a
	unified view on existing algorithms. Learning a
	policy is often easier than learning an accurate
	forward model, and, hence, model-free methods are
	more frequently used in practice. However, for each
	sampled trajectory, it is necessary to interact with
	the robot, which can be time consuming and
	challenging in practice. Model-based policy search
	addresses this problem by first learning a simulator
	of the robot's dynamics from data. Subsequently, the
	simulator generates trajectories that are used for
	policy learning. For both model-free and model-based
	policy search methods, we review their respective
	properties and their applicability to robotic
	systems.},
}

@article{snoek2015scalable,
	title={Scalable {B}ayesian Optimization Using Deep Neural Networks},
	author={Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Md and Ali, Mostofa and Adams, Ryan P and others},
	journal={arXiv preprint arXiv:1502.05700},
	year={2015}
}

@phdthesis{osborne2010bayesian,
	title={{B}ayesian Gaussian Processes for Sequential Prediction, Optimisation and Quadrature},
	author={Osborne, Michael},
	year={2010},
	school={PhD thesis, University of Oxford}
}

@inproceedings{osborne2012active,
	title={Active learning of model evidence using {B}ayesian quadrature},
	author={Osborne, Michael and Garnett, Roman and Ghahramani, Zoubin and Duvenaud, David K and Roberts, Stephen J and Rasmussen, Carl E},
	booktitle={NIPS},
	pages={46--54},
	year={2012}
}

@article{homan2014no,
	title={The no-U-turn sampler: Adaptively setting path lengths in Hamiltonian Monte Carlo},
	author={Homan, Matthew D and Gelman, Andrew},
	journal={J of Mach. Learn. Res.},
	volume={15},
	number={1},
	pages={1593--1623},
	year={2014},
	publisher={JMLR. org}
}

@article{hutter2013kernel,
	title={A Kernel for Hierarchical Parameter Spaces},
	author={Hutter, Frank and Osborne, Michael A},
	journal={arXiv preprint arXiv:1310.5738},
	year={2013}
}

@article{swersky2014raiders,
	title={Raiders of the lost architecture: Kernels for {B}ayesian optimization in conditional parameter spaces},
	author={Swersky, Kevin and Duvenaud, David and Snoek, Jasper and Hutter, Frank and Osborne, Michael A},
	journal={arXiv preprint arXiv:1409.4011},
	year={2014}
}

@article{rainforth2016interacting,
	title={Interacting Particle Markov Chain Monte Carlo},
	author={Rainforth, Tom and Naesseth, Christian A and Lindsten, Fredrik and Paige, Brooks and van de Meent, Jan-Willem and Doucet, Arnaud and Wood, Frank},
	journal={arXiv preprint arXiv:1602.05128},
	year={2016}
}

@book{smith2013sequential,
	title={Sequential Monte Carlo methods in practice},
	author={Smith, Adrian and Doucet, Arnaud and de Freitas, Nando and Gordon, Neil},
	year={2013},
	publisher={Springer Science \& Business Media}
}

@article{andrieu2010particle,
	title={Particle {M}arkov chain {M}onte {C}arlo methods},
	author={Andrieu, Christophe and Doucet, Arnaud and Holenstein, Roman},
	journal={J Royal Stat. Soc.: Series B (Stat. Methodol.)},
	volume={72},
	number={3},
	pages={269--342},
	year={2010},
	publisher={Wiley Online Library}
}

@article{van2015particle,
	title={Particle gibbs with ancestor sampling for probabilistic programs},
	author={van de Meent, Jan-Willem and Yang, Hongseok and Mansinghka, Vikash and Wood, Frank},
	journal={arXiv preprint arXiv:1501.06769},
	year={2015}
}

@article{duane1987hybrid,
	title={Hybrid {M}onte {C}arlo},
	author={Duane, Simon and Kennedy, Anthony D and Pendleton, Brian J and Roweth, Duncan},
	journal={Physics letters B},
	year={1987},
	publisher={Elsevier}
}

@article{carpenter2015stan,
	title={Stan: a probabilistic programming language},
	author={Carpenter, B and Gelman, A and Hoffman, M and Lee, D and Goodrich, B and Betancourt, M and Brubaker, M A and Guo, J and Li, P and Riddell, A},
	journal={Journal of Statistical Software},
	year={2015}
}

@article{shahriari2016taking,
	title={Taking the human out of the loop: A review of {B}ayesian optimization},
	author={Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P and de Freitas, Nando},
	journal={Proceedings of the IEEE},
	volume={104},
	number={1},
	pages={148--175},
	year={2016},
	publisher={IEEE}
}

@inproceedings{osborne2009gaussian,
	title={Gaussian processes for global optimization},
	author={Osborne, Michael A and Garnett, Roman and Roberts, Stephen J},
	booktitle={3rd international conference on learning and intelligent optimization (LION3)},
	pages={1--15},
	year={2009},
	organization={Citeseer}
}

@inproceedings{osborne2012active,
	title={Active learning of model evidence using {B}ayesian quadrature},
	author={Osborne, Michael and Garnett, Roman and Ghahramani, Zoubin and Duvenaud, David K and Roberts, Stephen J and Rasmussen, Carl E},
	booktitle={Advances in neural information processing systems},
	pages={46--54},
	year={2012}
}

@inproceedings{gardner2014bayesian,
	title={{B}ayesian Optimization with Inequality Constraints.},
	author={Gardner, Jacob R and Kusner, Matt J and Xu, Zhixiang Eddie and Weinberger, Kilian Q and Cunningham, John},
	booktitle={ICML},
	pages={937--945},
	year={2014}
}

@article{hernandez2015predictive,
	title={Predictive entropy search for {B}ayesian optimization with unknown constraints},
	author={Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and Gelbart, Michael A and Hoffman, Matthew W and Adams, Ryan P and Ghahramani, Zoubin},
	journal={arXiv preprint arXiv:1502.05312},
	year={2015}
}

@article{neal2001annealed,
	title={Annealed importance sampling},
	author={Neal, Radford M},
	journal={Statistics and Computing},
	volume={11},
	number={2},
	pages={125--139},
	year={2001},
	publisher={Springer}
}

@article{venugopal2002simulating,
	title={Simulating quantum transport in nanoscale transistors: Real versus mode-space approaches},
	author={Venugopal, R and Ren, Z and Datta, S and Lundstrom, MS and Jovanovic, D},
	journal={J. Appl. Phys.},
	volume={92},
	number={7},
	pages={3730--3739},
	year={2002},
	publisher={AIP Publishing}
}

@article{chung2006three,
	title={Three-dimensional finite element modeling of composite girder bridges},
	author={Chung, Wonseok and Sotelino, Elisa D},
	journal={Engineering Structures},
	volume={28},
	number={1},
	pages={63--71},
	year={2006},
	publisher={Elsevier}
}

@article{csillery2010approximate,
	title={Approximate {B}ayesian {C}omputation ({ABC}) in practice},
	author={Csill{\'e}ry, Katalin and Blum, Michael GB and Gaggiotti, Oscar E and Fran{\c{c}}ois, Olivier},
	journal={Trends in Ecology \& Evolution},
	volume={25},
	number={7},
	pages={410--418},
	year={2010},
	publisher={Elsevier}
}

@article{hernandez2015general,
	author  = {Jos\'{e} Miguel Hern\'{a}ndez-Lobato and Michael A. Gelbart and Ryan P. Adams and Matthew W. Hoffman and Zoubin Ghahramani},
	title   = {A General Framework for Constrained {B}ayesian Optimization using Information-based Search},
	journal = {JMLR},
	year    = {2016},
	volume  = {17},
	number  = {160},
	pages   = {1-53},
	url     = {http://jmlr.org/papers/v17/15-616.html}
}

@book{murphy2012machine,
	title={Machine learning: a probabilistic perspective},
	author={Murphy, Kevin P},
	year={2012},
	publisher={MIT press}
}

@article{swersky2014raiders,
	title={Raiders of the lost architecture: Kernels for {B}ayesian optimization in conditional parameter spaces},
	author={Swersky, Kevin and Duvenaud, David and Snoek, Jasper and Hutter, Frank and Osborne, Michael A},
	journal={arXiv preprint arXiv:1409.4011},
	year={2014}
}

@article{hutter2013kernel,
	title={A Kernel for Hierarchical Parameter Spaces},
	author={Hutter, Frank and Osborne, Michael A},
	journal={arXiv preprint arXiv:1310.5738},
	year={2013}
}

@article{zinkov2016composing,
	title={Composing inference algorithms as program transformations},
	author={Zinkov, Robert and Shan, Chung-{C}hieh},
	journal={arXiv preprint arXiv:1603.01882},
	year={2016}
}

@article{shahriari2016unbounded,
	author={Shahriari, Bobak and Bouchard-C{\^o}t{\'e}, Alexandre and de Freitas, Nando},
	journal =     {AISTATS},
	title={Unbounded {B}ayesian Optimization via Regularization},
	year={2016}
}

@book{deb2012optimization,
	title={Optimization for engineering design: Algorithms and examples},
	author={Deb, Kalyanmoy},
	year={2012},
	publisher={PHI Learning}
}

@inproceedings{van2015black,
	title={Black-Box Policy Search with Probabilistic Programs},
	author={van de {M}eent, Jan-Willem and Paige, Brooks and Tolpin, David and Wood, Frank},
	booktitle={AISTATS},
	pages={1195--1204},
	year={2016}
}

@inproceedings{eggensperger2013towards,
	title={Towards an empirical foundation for assessing {B}ayesian optimization of hyperparameters},
	author={Eggensperger, Katharina and Feurer, Matthias and Hutter, Frank and Bergstra, James and Snoek, Jasper and Hoos, Holger and Leyton-Brown, Kevin},
	booktitle={NIPS workshop on {B}ayesian Optimization in Theory and Practice},
	pages={1--5},
	year={2013}
}

@article{paul2016alternating,
	title={Alternating Optimisation and Quadrature for Robust Reinforcement Learning},
	author={Paul, Supratik and Ciosek, Kamil and Osborne, Michael A and Whiteson, Shimon},
	journal={arXiv preprint arXiv:1605.07496},
	year={2016}
}


@incollection{tolpin2015probabilistic,
	title = {Probabilistic Programming in {A}nglican},
	url = {http://dx.doi.org/10.1007/978-3-319-23461-8_36},
	publisher = {Springer International Publishing},
	keywords = {Probabilistic programming},
	author = {Tolpin, David and van de Meent, Jan-Willem and Wood, Frank},
	year = {2015}
}

@article{broyden1970convergence,
	title={The convergence of a class of double-rank minimization algorithms 1. general considerations},
	author={Broyden, Charles George},
	journal={IMA Journal of Applied Mathematics},
	volume={6},
	number={1},
	pages={76--90},
	year={1970},
	publisher={IMA}
}

@article{gutmann2016bayesian,
	title={Bayesian Optimization for Likelihood-Free Inference of Simulator-Based Statistical Models},
	author={Gutmann, Michael U and Corander, Jukka},
	journal={JMLR},
	volume={17},
	pages={1--47},
	year={2016}
}

@inproceedings{rainforth2016bayesian,
	title={Bayesian optimization for probabilistic programs},
	author={Rainforth, Tom and Le, Tuan-Anh and van de Meent, Jan-Willem and Osborne, Michael A and Wood, Frank},
	booktitle={Advances in Neural Information Processing Systems},
	pages={280--288},
	year={2016}
}

@book{bellman2013dynamic,
	title={Dynamic programming},
	author={Bellman, Richard},
	year={2013},
	publisher={Courier Corporation}
}

@book{back1996evolutionary,
	title={Evolutionary algorithms in theory and practice: evolution strategies, evolutionary programming, genetic algorithms},
	author={Back, Thomas},
	year={1996},
	publisher={Oxford university press}
}

@book{papadimitriou1982combinatorial,
	title={Combinatorial optimization: algorithms and complexity},
	author={Papadimitriou, Christos H and Steiglitz, Kenneth},
	year={1982},
	publisher={Courier Corporation}
}

@misc{boyd2004convex,
	title={Convex Optimization},
	author={Boyd, Stephen and Vandenberghe, Lieven},
	year={2004},
	publisher={Cambridge University Press}
}

@book{robert2004monte,
	title={Monte carlo methods},
	author={Robert, Christian P},
	year={2004},
	publisher={Wiley Online Library}
}

@book{hastie01statisticallearning,
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	publisher = {Springer New York Inc.},
	series = {Springer Series in Statistics},
	title = {The Elements of Statistical Learning},
	year = 2001
}

@book{bishop2006pattern,
	title={Pattern recognition and machine learning},
	author={Bishop, Christopher M},
	year={2006},
	publisher={springer}
}