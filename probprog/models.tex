% !TEX root = ../main.tex

\section{Bayesian Models as Program Code}
\label{sec:probprog:models}

In Section~\ref{sec:probprog:inv} we showed how one can think of PPS as inverting simulators, 
predicting internal variables given the outputs.  In this section we will take a 
different perspective and
show how we can translate Bayesian modeling into the framework of program code.   
In Chapter~\ref{chp:bayes} we showed how a Bayesian model is defined by a prior over
parameters and a likelihood function for those parameters given the data.  This viewpoint will
mostly translate into the probabilistic programming setting by equating between the prior
and sampling statements and between the likelihood and conditioning statements, though as
we explain in Section~\ref{sec:probprog:models:general}, this is not always true.
%At the end
%of the section we will explain why this is actually a slight approximation (in short because we
%might condition on internally sampled variables) but for most purposes this viewpoint will suffice.
%We will keep things predominantly high-level for now, giving a more detailed look in
%Section~\ref{sec:probprog:anglican} by introducing a particular PPS, namely Anglican, in detail.

A key point to note throughout this section is that probabilistic programs define
models rather than procedures.  We refer to these models as \emph{queries} which are analogous
to functions in a ordinary language.
In a standard programming language, functions take in inputs
and then run through a series of commands in order until termination is reached.\footnote{In functional
	programming languages operations are not necessary carried out in the order they are defined,
	but it still holds that the function takes inputs carries out a series of actions until the desired output
	is (perhaps lazily) calculated.}  Likewise, random sampling statements like \texttt{rand}, \texttt{randn}
etc, make a single independent draw from the same distribution each time they appear in the execution trace.
Neither is the case for a probabilistic program query.  Instead a  query defines a model
which is compiled to a form that can be interpreted by an inference engine which then
outputs some characterization of the posterior such as a series of samples.  Perhaps the easiest way to think
about how a probabilistic program language works (though not necessarily what happens for all systems) is that
the query is, or sometimes parts of the query are, run many (and potentially millions of) times and the exact behavior
of this running is control by the inference engine.  For example, the inference engine 
might sample from a different distribution then specified by the original sampling statement or it
might run lots of instances of the query in parallel and then terminate some of the instances
performing poorly, while duplicating instances doing well.

\subsection{A Simplified Probabilistic Programming Setup}
\label{sec:probprog:models:first}

We first consider the case of constructing a restricted example PPL.  We emphasize that
this is by no means the only setup one can use, with design choices made in the interest of exposition.
We will presume that our PPL
has no branching (i.e. there are no \texttt{if} statements or equivalent), recursion, or memoization
(i.e. functions are always re-evaluated from scratch when called); is first order
(i.e. variables cannot be functions); and that it does not allow 
any conditioning on internally sampled variables.  
We will give our language
two special constructs, \sample and \observe, between which the distribution of the
query is defined.  We will presume here and throughout that, other than the effects of \sample and \observe,
functions in our PPL are \emph{pure} such that they always provide the same outputs when
called with the same inputs.  This restriction naturally means that queries should not have
any random components other than dictated by \sample and \observe, but also suggests that
they should be free from side effects such as modifications of global variables.
Informally, \sample will be used to specify terms in the prior and \observe terms in the
likelihood.  More precisely, \sample will be used to make random draws $x_t \sim f_t(x_t | \Xi_t)$,
where $\Xi_t$ is a subset the other variables in scope at the point of sampling, and \observe will use to condition on
data $g_s(y_s|\Lambda_s)$ with $\Lambda_s$ defined in the same way as $\Xi_t$.  
For our inference, it will be necessary to control the sampling and so we define
the syntax of \sample to take a \emph{distribution object} as its only input and for \observe
to take a distribution object and an observation as input.  We further define each distribution
object as containing a sampling procedure and a density function that can be evaluated
exactly.\footnote{It will actually often be possible to use incomplete distribution objects for
	both \sample and \observe that only contain the sampler and the density function respectively.
	This former can be permitted by using inference algorithms that use the prior as the proposal, such
	that only the sampler will be required.  The latter is sufficient in the vast majority of scenarios as, unless
	one is carrying out amortization~\citep{paige2016inference,le2017inference}, the data is fixed and does
	not need to be sampled.}  Our language will be provided with a number of \emph{elementary random
	procedures} in
the form of distribution classes for common sampling distributions such as the normal and Poisson
distributions, but will also provide the ability for users to define their own distribution classes.   These
classes allow a distribution object to be constructed when provided with the required parameters, such that
the distribution is fully defined before being passed to a \sample or \observe.
We complete our syntactic definition of \sample and \observe by defining them to return a sample and \texttt{nil}
respectively.

\begin{figure}[p]
	\centering
	\begin{subfigure}[t]{\textwidth}
		\centering	
		\begin{minipage}[t]{0.48\textwidth}
		\begin{algorithmic}[1]
			\renewcommand{\algorithmicrequire}{\textbf{Inputs:}}
			\renewcommand{\algorithmicensure}{\textbf{Outputs:}}			 
			\Require Student-t degrees of freedom $\nu$, error
			scale $\sigma$, data $y_{1:S} = \{u_s,v_s\}_{s=1}^S$
			%\Ensure weighted samples $\left\{x_{1:T}^i,w_T^i\right\}_{i=1}^N$
%			\State \texttt{m\_dist} $\leftarrow$ 
%			\State \texttt{c\_dist} $\leftarrow$ \normal(0,1)
			\State $m\leftarrow$\sample(\normal(0,1))
			\State $c\leftarrow$\sample(\normal(0,1))
			\State \lstinline$obs-dist$\xspace $\leftarrow$ \studentt $(\nu)$
			\For{$s=1,\dots,S$}	
			\State $d \leftarrow (v_s-m u_s - c)/\sigma$
			\State \observe(\lstinline$obs-dist$\xspace,~$d$)
			\EndFor
			\State \Return $m, \; c$
		\end{algorithmic}
		\end{minipage}
		~~
		\begin{minipage}[t]{0.48\textwidth}
			\vfill
			\resizebox{\textwidth}{!}{
				\input{probprog/figures/linear-reg.tex}}
			{\small
			\begin{align*}
			p(m,c&, y_{1:S} | \nu, \sigma)= \mathcal{N}(m;0,1) \; \mathcal{N}(c;0,1) \\
										&\prod_{s=1}^{S} \textsc{Student-T} \left(\frac{v_s-mu_s-c}{\sigma} ; \nu \right)
			\end{align*}}
		\end{minipage}
		\caption{Bayesian linear regression model with student-t likelihood, namely
			$v_s = m u_s + c + \sigma \epsilon_s$ where $\epsilon_t \sim \textsc{Student-T}(\nu)$.
			We presume that the scaling of the error $\sigma$ and the number of degrees of freedom $\nu$
			are fixed input parameters (i.e. $\theta=\{\nu,\sigma\}$), that our fixed data is $y_{1:S} = \{u_s,v_s\}_{t=1}^S$,
		 and that we are trying to infer the slope $m$ and intercept $c$ (we thus have $x_1=m$, $x_2=c$ in our
		 general notation), both of which are assigned a unit Gaussian as a prior.  Our query
			first samples $m$ and $c$ (note that \normal(0,1) generates a unit Gaussian distribution object)
			and constructs a student-t distribution object \lstinline$obs-dist$.  It then cycles
		  over each datapoint and observes $(v_t-m u_t -c)/\sigma$ using \lstinline$obs-dist$,
		  before finally returning $m$ and $c$ as outputs.  
%		  The query corresponds to the graphical model
%		  shown in the top right and induces the joint distribution shown bottom right.  
		  Note that if we instead
		  wished to directly predict the outputs at some untested inputs points $u_{S+1:S+n}$ then we could
		  predict these anywhere in the query (after $m$ and $c$ have been defined) and return these
		  as outputs along with, or instead of, $m$ and $c$.
		  \label{fig:probprog:linear-reg}
		  }
	\end{subfigure}
		\begin{subfigure}[t]{\textwidth}
			\vspace{10pt}
\centering	
\begin{minipage}[t]{0.45\textwidth}
	\begin{algorithmic}[1]
		\renewcommand{\algorithmicrequire}{\textbf{Inputs:}}
		\renewcommand{\algorithmicensure}{\textbf{Outputs:}}			 
		\Require Transition std-dev $\sigma$, output shape $\alpha$,
		output rate $\beta$, data $y_{1:T}$
		%\Ensure weighted samples $\left\{x_{1:T}^i,w_T^i\right\}_{i=1}^N$
		%			\State \texttt{m\_dist} $\leftarrow$ 
		%			\State \texttt{c\_dist} $\leftarrow$ \normal(0,1)
		\State $x_0\leftarrow0$
		\State \lstinline$tr-dist$\xspace $\leftarrow$ \normal $(0,\sigma)$
		\State \lstinline$obs-dist$\xspace $\leftarrow$ \lstinline$gamma$\xspace $(\alpha,\beta)$
		\For{$t=1,\dots,T$}	
		\State $x_t \leftarrow x_{t\text{-}1}+$\sample(\lstinline$tr-dist$\xspace)
		\State \observe(\lstinline$obs-dist$\xspace,~$y_t-x_t$)
		\State $z_t \leftarrow \mathbb{I}(x_t>4)$
		\EndFor
		\State \Return $z_{1:T}$
	\end{algorithmic}
\end{minipage}
~~
\begin{minipage}[t]{0.52\textwidth}
	\vspace{-6pt}
	~~~\resizebox{0.96\textwidth}{!}{
		\input{probprog/figures/state-space.tex}}
	{\small
	\begin{align*}
	p&(x_{1:T}, y_{1:T} | \sigma,\alpha,\beta)= \\
	&\mathcal{N}(x_1;0,\sigma^2) \; \textsc{Gamma}(y_1-x_1;\alpha,\beta)\\
	&\prod_{t=2}^{T} \mathcal{N}(x_t-x_{t-1};0,\sigma^2) \; \textsc{Gamma} (y_t-x_t;\alpha,\beta)
	\end{align*}}
\end{minipage}
			\caption{State-space model with Gaussian transition and Gamma emission distributions.
				It is a form of the HMM model given in~\eqref{eq:bayes:hmm} with
				$p(x_1)=\mathcal{N}(x_1;0,\sigma^2)$, $p(x_t | x_{t-1}) = \mathcal{N}(x_t-x_{t-1}; 0,\sigma^2)$,
				and Gamma likelihood model $p(y_t | x_t) = \textsc{Gamma}(y_t-x_t ; \alpha, \beta)$ with
				shape parameter $\alpha$ and scale parameter $\beta$.  We assume that the input
				parameters $\theta = \{\sigma,\alpha,\beta\}$ are fixed and we want
				to sample from $p(z_{1:T} | y_{1:T}, \theta)$ given data $y_{1:T}$ where each 
				$z_t$ is an indicator for if $x_{t}$ exceeds a threshold of $4$. Our query, exploiting the
				equivalence between $p(x_1)$ and $p(x_t|x_{t-1}=0)$, first initializes $x_0=0$ and creates
				distribution objects for the transitions \lstinline$tr-dist$\xspace and emissions
				\lstinline$obs-dist$\xspace.  It then loops over time steps, sampling each $x_t$ given
				$x_{t-1}$, observing $y_t$ given $x_t$, and deterministically calculating $z_t$.  Finally
				the $z_{1:T}$ are returned as the desired output.
				\label{fig:probprog:LGSSM}
				}
		\end{subfigure}
\caption{Example pseudo-queries for our simplified probabilistic programming setup with
	corresponding graphical models and joint distributions.\label{fig:probprog:example-progs}}
\end{figure}

We distinguish between two types of inputs to our queries: external parameters $\theta$ and data $y_{1:S}$.
The external parameters are defined as the inputs that are 
not ``observed'' at any point but can effect the conditioning through $\Xi_t$ and $\Lambda_s$.
We presume for our simplified setup that the data terms, defined as the inputs we are observed, 
appear in neither $\Xi_t$ or $\Lambda_s$.
We now define both \sample and \observe from the probability model perspective
as adding a factor to the joint distribution which is therefore given by
\begin{align}
\label{eq:probprog:simple-joint}
p(x_{1:T},y_{1:S} | \theta) = \prod_{t=1}^{T} f_t(x_t | \Xi_t) \prod_{s=1}^{S} g_s(y_s|\Lambda_s).
\end{align}
The two vary in whether they define a new random variable or effect the probability of the
query given particular instances of the other random variables.
Our presumptions for this simplified setup that no $y_{s}$ terms are present in the $\Xi_t$ or $\Lambda_s$
and that we do not condition on internally sampled variables, means that the product of the \sample terms
correspond exactly to our prior $\prod_{t=1}^{T} g_t(x_t | \Xi_t) =: p(x_{1:T} | \theta)$ and that the
product of the \observe terms corresponds exactly to our likelihood
$\prod_{s=1}^{S} g_s(y_s|\Lambda_s) =: p(y_{1:S} | x_{1:T}, \theta)$.  Consequently, for our simplified setup,
each query defines a finite directed acyclic graphical model (see Section~\ref{sec:bayes:paradigm:graph})
where the conditional relationships are defined through the definitions of $f_t$ and $g_s$.
This breakdown into a prior and likelihood and the equivalence to graphical models
will not hold in the more general cases we consider later.  Our aim will be to perform inference
to provide a characterization of $p(x_{1:T} | y_{1:S}, \theta)$ (or the posterior for some deterministic
mapping of $x_{1:T}$), typically in the form of (approximate)
samples.  Figure~\ref{fig:probprog:example-progs} shows two example queries
along with the corresponding graphical models and joint distributions they define.

Other than \sample and \observe statements, the rest of our query is by construction totally deterministic.  Therefore,
though it may contain random variables other than $x_{1:T}$, these random variables are deterministic
functions of the ``raw'' random draws $x_{1:T}$ and inputs $\theta$ and $y_{1:S}$.  We can therefore 
define the outputs of our query as $z := h(x_{1:T},y_{1:S},\theta)$ for some deterministic function $h$.
As we explained in Section~\ref{sec:prob:measure}, the change of variables means that the density function on $z$,
$p(z | y_{1:S}, \theta) $
can have a different form to the posterior implied by our query, namely $p(x_{1:T} | y_{1:S}, \theta)$.
  Though this is a serious complication in the
context of optimization (we may not in general be able to find $\argmax_z p(z|y_{1:S},\theta)$
or even evaluate $p(z | y_{1:S}, \theta)$ exactly), it
is perfectly acceptable in the context of calculating expectations as
\begin{align}
\int f(z) p(z | y_{1:S}, \theta) dz = \int f(h(x_{1:T}, y_{1:S}, \theta)) p(x_{1:T} | y_{1:S}, \theta) dx_{1:T}
\end{align}
for implicitly defined measures $dz$ and $dx_{1:T}$.  One consequence of this is that
we can express any expectations calculated by our query as expectations over $p(x_{1:T} | y_{1:S}, \theta)$
which was fully defined by the joint~\eqref{eq:probprog:simple-joint}.  Another is that, provided we are not worried
about carrying out optimizations, we do not need to explicitly worry about the implicit measures defined
by the definition of our query, other than any potential effects on the inference scheme.  In particular,
if our aim is to generate samples from $p(z | y_{1:S}, \theta)$ then we can simply generate samples then
we can simply generate samples from $p(x_{1:T} | y_{1:S}, \theta)$ and then deterministically convert each
sample to the space of $z$.  In other words, our inference engine does not need to worry about
the consequences of changes of variables if our intended output is just a sequence of samples.

An important point to note is that~\eqref{eq:probprog:simple-joint} shows that all of our \sample
and \observe statements are exchangeable, in the sense that their order can be moved around and
still define the same joint distribution, up to restrictions about all the required variables (namely the
distribution object and, if required, observation in our current setup) existing and being in scope.  
For example, if all variables remain in scope
and are not redefined, we can generally move all our \observe statements to the end of the query
without changing the joint distribution.  Therefore the query given in Figure~\ref{fig:probprog:LGSSM}
would define the same model if all the $x_t$ were sampled upfront before making any observations.
Nonetheless, the position of the \observe statements
can often be important from the perspective of the performance of the inference engine.  This exchangeability
result will carry over to the non-simplified cases.

%
%Because of the assumptions we have made for our language, the latent
%variables we wish to do inference for are statically determined as $x_{1:T} = x_1,\dots,x_T$ 
%such that the posterior of interest is $p_{\theta} (x_{1:T} | y_{1:S})$ (or some marginal of this for
%which we can still using Monte Carlo inference on the joint).
%
%Our implied target posterior
%is proportional to this joint in the standard way $p_{\theta}(x_{1:T}|y_{1:S}) \propto p_{\theta}(x_{1:T},y_{1:S})$.

\subsection{A General Probabilistic Programming Setup}
\label{sec:probprog:models:general}

Perhaps surprisingly, we do not need to do anything to our language to extend it to a universal
PPL other than to relax a number of the restrictions made for our simplified case.  Namely,
we will allow branching, higher order functions, (potentially infinite) recursion, memoization, conditioning on internally sampled
variables, and the use of the ``data'' inputs $y_{1:T}$ in the definition of our generate model (instead of
just allowing them to be observed).  We will maintain the syntax of our simplified
setup, along with the assumption that functions are pure other than the effect of \sample and \observe.
An important point to note though for why such a language is universal is that arbitrary distributions
with finite\todo{countable?} parameters can be defined through a series of uniform $[0,1]$ draws followed
by an arbitrary deterministic mapping -- after all, this is effectively how all probability distributions are
defined from a measure theoretic point of view.\footnote{Interesting, this viewpoint breaks down for
	distributions over functions for which measure theory itself somewhat breaks down~\cite{heunen2017convenient}.
	As such, universal PPSs actually go beyond the standard measure-theoretic view of probability.}

However, these generalization will have a substantial effect on the intuitions relating our universal
PPL to the Bayesian framework, the range of models we can define, and the difficulty of performing
general purpose inference.  For example, as $y_s$ terms can appear in the $\Xi_t$ terms,
it can be the case that $p(x_{1:T} | \theta) \neq \prod_{t=1}^{T} p(x_t | \Xi_t)$ such that the latter no
longer explicitly corresponds to a conventional definition of a prior.  Some variables may change type (e.g.
between continuous and discrete) or even not exist depending on the value of other variables.  The number
of variables may change from one execution to the next and it could even be the case that the number
of latent variables could be unbounded provided that either the probability that any execution has a 
finite number of variables is $1$ or that only a finite number need to be evaluated to calculate the density, such
as is the case for Bayesian non-parametric models such as the Dirichlet process~\citep{ferguson1973bayesian,teh2011dirichlet}.
Note that the number \sample and \observe statements lexically defined within our query must,
for obvious reasons, be finite, but recursion or looping may mean that they are evaluated an uncountable
number of times.  It is also possible for a variable within a query to itself encode an
infinite number of parameters, for example, one might include a Gaussian process within the query (see Section~\ref{sec:opt:GPs}).
These complications make it difficult to mathematically reason about the joint distribution defined by a query in a
universal PPS, let alone reason about its breakdown into a prior and a likelihood or represent the query
using a graphical model (which might actually not even be possible).

One way to conceptually overcome these difficulties is to reason in terms of \emph{execution paths}.
Even though we might not know upfront which \sample and \observe statements are invoked by
a particular query output, if we execute the query in order, the draws of the \sample statements made
thus far in an \emph{execution trace} uniquely identify which \sample statement will be invoked next, the value of all the variables up
to that \sample statement, and all \observe calls prior to the next \sample statement in the path.  
In other words, given the outcome of $t$ evaluated \sample statements, which \sample statement corresponds
to the $(t+1)$-th to be evaluated is uniquely defined and the query up to that \sample statement is
completely deterministic, including which path to take at each \texttt{if} statement, which variables are defined
and their values, and the probability arising from the \observe conditioning statements.
Thus although the distribution of the query is not necessarily statically
determinable, it can still be \emph{evaluated through execution} as each \sample statement provides
the information we require, in addition to the information from the previous \sample statements, to deterministically evaluate
up to the next \sample statement.
Consequently, we can evaluate the probability of any particular trace as we run it, even though it might
be challenging to evaluate the probability of a predefined configuration of the variables.

Using this idea of execution paths, we can define an expression for the joint probability a query defines,
albeit in a complex and somewhat abstract manner that only really retains meaning in our probability calculation through
evaluation mindset, by define the probability of a particular trace.  First let $\lambda$ denote all the 
inputs to the query (including both parameters and
data as we will now have no explicit distinction between the two).  Further let
$n_x$ and $n_y$ as the number of \sample and \observe statements
respectively invoked by the trace, noting that $n_x$ and $n_y$ are themselves random variables.
We can now define $x_{1:n_x} = x_1,\dots,x_{n_x}$ and $y_{1:n_y} = y_1,\dots,y_{n_y}$ respectively as the
outputs of our $n_x$ \sample statements and observation inputs for our $n_y$ \observe statements.
Each $x_{i}$ is obvious a random variable, but we note that each $y_i$ might also be a random variable.  However,
for the reasons explained in the last paragraph, each $y_{1:n_y}$ is deterministically calculable given $x_{1:n_x}$ and
$\lambda$.
We continue by defining $f_{1},\dots,f_{n_s}$ and $g_{1},\dots,g_{n_o}$ respectively as the $n_s$ \sample 
and $n_o$ \observe statements defined lexically within a raw program code (i.e. the distinct \sample and \observe
statements defined anywhere within the query), noting that $n_s$ and $n_o$ are \emph{not} random variables.
We will further use the notation $f_i(x_j|\phi_j)$  to denote the probability density functions
(with implicit measure) associated with lexical \sample statement $i$ returning outputs $x_j$ when provided
with distribution object $\phi_j$, which is itself a random variable but one which is fully determined by
$x_{1:j-1}$ and $\lambda$.  Similarly, we use the notation $g_i(y_k|\psi_k)$ to express the density of
using lexical \observe $g_i$ to observe output $y_k$ with distribution object $\psi_k$, which is a random
variable fully determined by $x_{1:n_x}$ and $\lambda$.  Finally we define $a_j \in \{1,\dots,n_x\}, \; 
\forall j\in\{1,\dots,n_x\}$ and $b_k \in \{1,\dots,n_x\}, \; \forall k\in\{1,\dots,n_y\}$ as the
random variables respectively used to index which lexical \sample and lexical \observe statements
correspond to the $j^{\text{th}}$ and $k^{\text{th}}$ execution trace \sample and \observe statement.
We can now finally define the conditional distribution implied by our query up to a normalization constant
as
\begin{align}
\label{eq:probprog:universal-cond}
p(x_{1:n_x} | \lambda)
&\propto
\prod_{j=1}^{n_x} 
f_{a_j}(x_j | \phi_j)
\prod_{k=1}^{n_y}
g_{b_k}(y_k | \psi_k)
\end{align}
noting that although the $a_j$, $\phi_j$, etc are random variables, they are all deterministically
calculable given $x_{1:n_x}$, $\lambda$, and our query.  As a consequence, our unnormalized
target distribution is well defined and implies a ``posterior'' simply through its normalization.
 \todo[inline]{Give an example program}

Note that the right hand side of~\eqref{eq:probprog:universal-cond} does not necessarily
correspond to a valid joint distribution because the ability to observe sampled variables and
condition the \sample statements on the observations.  Therefore, as a simple example, our model
might consist of a $x_1 \leftarrow$\sample(\normal(0,1)) term followed by an \observe(\normal(-1,2),~$x_1$)
term.  This does not directly define any properly normalized joint distribution on any particular variables
(noting $\mathcal{N}(x_1;0,1) \mathcal{N}(x_1;0,2)$ is an unnormalized distribution with only the variable
$x_1$).  Consequently, there is no means of writing down a normalized joint distribution for a general
query in our universal PPL setup in closed form -- we might actually need to empirically estimate
the normalization constant to evaluate the joint.  This actually steps outside the conventional Bayesian
modeling framework and raises a number of interesting theoretical questions.  However, from a
practical perspective, we can note that provided the implicitly define normalization constant is finite,
the query also implicitly defines a correctly normalized conditional distribution (noting that the right
hand side of ~\eqref{eq:probprog:universal-cond} is always $\ge0$).
This is analogous to knowing the joint but not the posterior in Bayesian inference, but not exactly
equivalent because the normalization constant is no longer the marginal likelihood.

As simple example of why it is important to be able to define models up to an unnormalized joint
distribution, consider an example where $a$ and $b$ are each sampled from discrete distributions
and we want to condition on the value of $a$ and $b$ being equal (see for example the Schelling
coordination example at {\small \url{http://www.robots.ox.ac.uk/~fwood/anglican/examples/}}).  Here
the combination of the sample statements and the observation that the two are equal clearly
does not lead to a correctly normalized joint (we do not even really have a conventional notion
of a likelihood), but it clearly defines an unnormalized conditional distribution as
\[
P(a,b | \mathbb{I}(a=b)) = \frac{P(a)P(b|a)\mathbb{I}(a=b)}{\sum_a \sum_b P(a)P(b|a) \mathbb{I}(a=b)}.
\]
In such cases where our observation is a hard constraint, we can view the normalizing constant for
the conditional defined by the query as the probability of our constraint being satisfied.  
For more general queries of discrete variables we might have, for example,
\[
P(x|\lambda) \propto f(x|\lambda)g(y=\eta(x,\lambda)|x,\lambda)
\]
for some deterministic function $\eta$.  Here we
can view the marginalization as being the probability of the event $y=\eta(x,\lambda)$ under the joint $P(x,y)=f(x|\lambda)g(y|x,\lambda)$.
For our previous example we have $x:=a$, $y:=b$, $\eta(a,\lambda):=a$, $f(a):=p(a)$, and $g(b=a):=p(b=a|a)$.
The same intuition applies to continuous cases where we now have the density of the event $y=\eta(x,\lambda)$.
We can also think of $f(x|\lambda)g(\eta(x,\lambda)|x,\lambda)$ as defining a unnormalized distribution on $x$ whose
normalization constant is of course $\int f(x|\lambda)g(\eta(x,\lambda)|x,\lambda) dx$.  In general, our normalization
constant will be a combination of conventional marginal likelihood terms and terms from these ``doubly defined''
terms. We coin this normalization constant the \emph{marginal observation density}\footnote{Note this is not a
	term that has previously appeared in the literature, where it is dubiously usually just referred to as a marginal
	likelihood, while the right hand side of~\eqref{eq:probprog:universal-cond} is similarly questionably
	referred to as the joint distribution defined by the query.} and note that it is given by
\begin{align}
\label{eq:probprog:mod}
Z(\lambda) = \E \left[ \prod_{k=1}^{n_y} g_{b_k}(y_k | \psi_k) | \lambda \right]
= \iint \prod_{j=1}^{n_x} f_{a_j}(x_j | \phi_j) \prod_{k=1}^{n_y} g_{b_k}(y_k | \psi_k) dx_{1:n_x} dn_x
\end{align}
where the expectation is under running the query forwards (i.e. the distribution implied by simulating
from an equivalent query with all the \observe statements removed) and 
all terms in the integral are deterministically calculable for the query given $\lambda$ and $x_{1:n_x}$.

We now see that we can draw a direct analogy to the Bayesian framework whereby the product of the
\sample terms is analogous to the prior, the product of the \observe terms is analogous to the
likelihood, and the marginal observation density is analogous to the marginal likelihood.  If observed variables
are not sampled within or used elsewhere in the query (e.g. being used a parameters in distribution objects
later used for sampling), then this analogy becomes exact as per our simplified setup.\footnote{Note that the
	observed variables should not be used in deterministic elements of the code for this to hold so that they
	cannot implicitly effect the sampling.}  However, as we have explained, it will often be desirable to go
beyond this framework to specify some models.  When we do, we still have an implicit Bayesian model, in the
same way that Bayes' rule means that a prior and a likelihood implicitly define a posterior, but we may not
actually have access to our implicitly defined prior and likelihood.

\todo[inline]{Don't forget
	to add comments to the BOPP stuff etc about this as the marginal likelihood isn't really the marginal
	likelihood...}  