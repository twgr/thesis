% !TEX root =  ../main.tex

\subsection{Optimizing the Acquisition Function}
\label{sec:optacqfunc}

As we previously alluded to, BOPP presents the issue that the query contains implicit constraints that are unknown to the surrogate function.  As we discussed in 
Section~\ref{sec:opt:BO:exten:constraints}, constraints have previously been considered
in the BO literature using a second surrogate model or an appropriate adaptation to the
existing surrogate.  Along with the potentially significant expense such a method incurs, this approach is inappropriate for \emph{equality} constraints or when the target variables are potentially discrete.  We, therefore, take an alternative approach based on directly using the program to optimize the acquisition function.  To do so we consider a transformed program \lsi{q-acq} that is identical to \lsi{q-prior} (see Section \ref{sec:bopp:domain}), but adds an additional \observe statement that assigns a weight $\zeta(\theta)$ to the execution such that the unnormalized joint distribution is now 
\begin{align}
\label{eq:bopp:qacq}
\gamma_{\text{acq}}(\theta,x_{1:n_{\theta}},\lambda) = \gamma_{\text{prior}}(\theta,x_{1:n_{\theta}},\lambda) \zeta(\theta)
\end{align}
By setting $\zeta(\theta)$ to the acquisition function, the maximum likelihood solution 
of $\gamma_{\text{acq}}(\theta,x_{1:n_{\theta}},\lambda)$ corresponds to the optimum of the acquisition function 
subject to the implicit program constraints.  More precisely, we maximize $\zeta(\theta)$ subject to
the constraint that
\[
\theta \in \vartheta(\lambda) := \left\{\theta : \left\{\exists x_{1:n_{\theta}} :
 \gamma_{\text{prior}}(\theta,x_{1:n_{\theta}},\lambda)>0\right\} \right\}.
\]
%Critically, this evaluation does not require inference and so can be evaluated cheaply.
Such an estimate is achieved by running on \qacq a variant of the simulated annealing algorithm 
discussed in Section~\ref{sec:bopp:related} in which RMH (see Section~\ref{sec:proginf:str:lmh}) is used for
the transition kernel.  Using an RMH, rather than LMH, transition kernel here is important as it will often
be the case that the optimum of the transition function is in a position of very low prior mass (see e.g. Figure~\ref{fig:domainAdpat}),
such that LMH could take an unreasonably long time to propose an appropriate set of parameters.
%The latter of these, which we refer to as random-walk Metropolis Hastings (RMH), is made possible by examining the type of the relevant distribution object at runtime to generate an appropriate local proposal kernel given the distribution type.

%Our final transformation generates a program, \qacq, which is identical to \qprior, except for adding an additional \observe statement that assigns a weight $\zeta(\theta)$ to the execution, where $\zeta$ is a function provided as an input.  By setting $\zeta(\theta)$ to the acquisition function and using a maximum likelihood algorithm to optimize the program, the optimum of the acquisition function subject to the implicit program constraints can be found as detailed in Section \ref{sec:optacqfunc}.