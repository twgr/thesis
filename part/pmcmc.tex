% !TEX root = ../main.tex

\section{Particle Markov Chain Monte Carlo Methods}
\label{sec:part:pmcmc}

Particle Markov chain Monte Carlo (\pmcmc) methods, introduced by \citet{andrieuDH2010}, make use of 
sequential Monte Carlo (\smc) algorithms \citep{gordon1993novel,doucet2001sequential} to construct 
efficient proposals for an \mcmc sampler. The core reason for wanting to do this is that
one is typically memory restricted in the number of particles that can be run $N$.  Though as we explained
before, we can run multiple sweeps and combine these using the marginal likelihood estimates, if $N$ is
not large enough, this typically results it widely varying estimates.  Although these estimates are unbiased,
they are typically extremely skew, often following a roughly Gaussian distribution in their \emph{log} marginal
likelihood CITE SOMETHING.  As such, it usually happens if $N$ is not large enough that one sweep dominates the others because
its marginal likelihood is many orders of magnitude larger than the others and our estimate is
effectively just the particle sweep with the highest marginal likelihood.  We therefore desire a more principled
means of transferring the information of one iteration to the next which we can do by constructing an appropriate MCMC
sampler.  We can then combine the advantages of SMC in its exploitation of the structure of the target with
the local updating advantages of MCMC methods.  Naturally this will come with the drawbacks of MCMC samplers
discussed in Section~\ref{sec:inf:foundation:mcmc}, in particular the loss of unbiasedness or marginal likelihood estimates.
However, the advantages will generally outweigh these drawbacks.  PMCMC methods will also allow us to explicitly
treat global parameters of our system differently to the latent states in a manner that can substantially improve
the performance of the model.
Though PMCMC can be applied to models with arbitrary series of targets in the same manner as SMC, we will stick
to the NMSSM case in this section for notational simplicity.

\subsection{Particle Independent Metropolis Hastings}
\label{sec:part:pmcmc:pimh}

Particle independent Metropolis Hastings (PIMH) is the simplest PMCMC algorithm.  Although it isolation it is
predominantly useless (as it strictly worse than running independent SMC sweeps and combining 
them),\footnote{There is though use when also including MCMC steps on global parameters, see~\cite{andrieu2010particle}.}
 it is an
importance theoretical stepping stone to more advanced approaches.  The idea from a practical perspective 
is very simple: use an SMC sweep as an independent proposal for an MCMC algorithm targeting $p(x_{1:T}|y_{1:T})$.
From a theoretical perspective, the approach is rather more profound as it can be viewed as a sampler on 
an \emph{extended space} whose marginal on the returned particles is the target.  We will then be able to use
this to construct more powerful samplers.

\begin{algorithm}[tb]
	\caption{Particle Independent Metropolis Hastings}
	\label{alg:part:pimh}
	\begin{spacing}{1.2}
		\begin{algorithmic}[1]
			\renewcommand{\algorithmicrequire}{\textbf{Inputs:}}
			\renewcommand{\algorithmicensure}{\textbf{Outputs:}}				 
			\Require data $y_{1:T}$, number of particles $N$, proposals $q_t$, number of MCMC iterations R
			\Ensure MCMC samples $\{\hat{x}_{1:T}^r\}_{r=1}^R$
			\State Run SMC giving a weighted particle set $X_{1:T}^0 = \{x_{1:T}^{i,0},w_T^{i,0}\}_{i=1}^N$ and marginal likelihood $\hat{Z}^0$
			\State Sample an single sample from the particle set $\hat{x}_{1:T}^0 \sim X_{1:T}^0$ in proportion to the particle weights
			\For{$r=2:R$}
			\State Run SMC giving new candidate particle set $\tilde{X}_{1:T}^r = \{x_{1:T}^{i,r},w_T^{i,r}\}_{i=1}^N$
				 and marginal likelihood $\tilde{Z}^r$
			\If{$u\le \min \left(1,\frac{\tilde{Z}^r}{\hat{Z}^{r-1}}\right)$ where $u\sim \textsc{Uniform}(0,1)$}
			\State $\hat{x}_{1:T}^r \sim \tilde{X}_{1:T}^r$
			\State $\hat{Z}^{r} \leftarrow \tilde{Z}^r$
			\Else
			\State $\hat{x}_{1:T}^r \leftarrow \hat{x}_{1:T}^{r-1}$
			\State $\hat{Z}^{r} \leftarrow \hat{Z}^{r-1}$
			\EndIf
			\EndFor
		\end{algorithmic}
	\end{spacing}
\end{algorithm}

The PIMH algorithm is given in Algorithm~\ref{alg:part:pimh}.  We see that PIMH is an MCMC
algorithm where our proposal involves proposing a new sample by running an independent SMC
sweep and then sampling one of the particles from this this particle set in proportion to
the weight of the particle.  This sample is then accepted or rejected using a MH accept-reject
step that  uses the marginal likelihoods of the sweep.  It might sweep wasteful to only use
one particle from each sweep, but we will be able to Rao-Blackwellize this step to actual
return all the particles at each step as we explain in Section INSERT.  Because our proposal
is independent of our current point, this is strictly worse than just running independent SMC sweeps
(which can also be thought of as applying waste recycling to PIMH CITE SOMETHING).  

Imagine that we were able to exactly calculate the posterior probability of the of samples
generated by an SMC sweep up to a normalization constant $\gamma(X_{1:T} |y_{1:T})$.  It would
now be straightforward to construct a valid sampler on this distribution by constructing an independent
MH proposal and accept/reject the particle sets in the standard way.  
The key components of proving the correctness of the PIMH algorithm is in showing that it is a valid
MH sampler on an extended target whose marginal is the distribution of interest.
%The two key components of proving
%the correctness of the PIMH algorithm are in showing that running and SMC sweep then sampling
%one of the samples produced an extended target distribution whose normalized marginal distribution is
%the posterior of interest $\pi(x_{1:T}|y_{1:T})$ and that our MH algorithm remains valid when
%provided with an \emph{unbiased estimate} of the target distribution rather than an exact calculation.

Let $\xib \eqdef \{x_{t}^i\}_{\substack{i=1:N\\t=1:T}} \bigcup \{a_{t}^i\}_{\substack{i=1:N\\t=1:T-1}}$
denote all generated particles and ancestor variables of a \smc sampler.  The distribution induced
by running a SMC sweep is now given by
\begin{align}
\label{eq:part:smc:proposal}
q_{\text{SMC}}(\xib) &= \prod_{i=1}^N q_1(x_{1}^i) \cdot \prod_{t=2}^T \prod_{i=1}^N \left[ 
\nw_{t-1}^{a_{t-1}^i}
%\frac{w_{t-1}^{a_{t-1}^i}}{\sum_\ell w_{t-1}^{\ell}}
q_t(x_{t}^i|x_{1:t-1}^{a_{t-1}^i}) \right]
\end{align}
and the distribution induced by running an SMC sweep and then sampling particle $b$ from the
sample set is 
\begin{align}
q_{\text{PIMH}}(b,\xib) = \bar{w}_T^b q_{\text{SMC}}(\xib) \quad \mathrm{where} \frac{\bar{w}_t^i}{\sum_{\ell=1}^{N}w_t^{\ell}} .
\end{align}
Let $\xb^i = x_{1:T,m}^i$ denote one of the final particles and let the trajectory associated
with the particle we sample be $\{\xb^{b},\bb\}$, with $\bb = (\beta_{1,},\ldots,\beta_{T})$,
$\beta_{T} = b$ and $\beta_{t} = a_{t}^{\beta_{t+1}}$. The proof for the validity of the PIMH
algorithm is now demonstrated by showing that it targets the distribution
\begin{align}
\label{eq:part:pimh-target}
\tilde{\pi}(b,\xi) = \frac{\pi(\xb^{b})}{N^T} \frac{q_{\text{SMC}}(\xib)}{q_1(x_1^{\beta_1}) \prod_{t=2}^{T} \bar{w}_{t-1}^{\beta_{t-1}}
	 q_t(x_t^{\beta_t} | x_{t-1}^{\beta_{t-1}})}
\end{align}
which has the marginal distribution on the samples we return $\pi(\xb^{b})$, i.e. the
distribution of interest.  To see this, we can substitute~\eqref{eq:part:smc:proposal} into
\eqref{eq:part:pimh-target} to give
\begin{align}
\tilde{\pi}(b,\xi) = \frac{\pi(\xb^{b})}{N^T} \prod_{i=1, i\neq\beta_1}^N q_1(x_{1}^i) \cdot \prod_{t=2}^T \prod_{i=1, i\neq\beta_t}^N \left[ 
\nw_{t-1}^{a_{t-1}^i}
%\frac{w_{t-1}^{a_{t-1}^i}}{\sum_\ell w_{t-1}^{\ell}}
q_t(x_{t}^i|x_{1:t-1}^{a_{t-1}^i}) \right]
\end{align}
where we see that terms of $\xb^{b}$ only appear in $\pi(\xb^{b})$, which must thus
have the correct marginal.  Now we note that
\begin{align}
\frac{\tilde{\pi}(b,\xi)}{q_{\text{PIMH}}(b,\xib)} &= \frac{\pi(\xb^{b})}{N^T \bar{w}_T^b q_1(x_1^{\beta_1}) \prod_{t=2}^{T} \bar{w}_{t-1}^{\beta_{t-1}} q_t(x_t^{\beta_t} | x_{t-1}^{\beta_{t-1}})} \nonumber \\
&= \frac{\gamma(\xb^{b})}{
	Z \left(q_1(x_1^{\beta_1}) \prod_{t=2}^{T} q_t(x_t^{\beta_t} | x_{t-1}^{\beta_{t-1}})\right)
	 \left(N^T \bar{w}_T^b\prod_{t=2}^{T} \bar{w}_{t-1}^{\beta_{t-1}}\right)} \nonumber \\
&= \frac{
	w_T^b \prod_{t=2}^{T} w_{t-1}^{\beta_{t-1}}
	}{
	Z N^T \bar{w}_T^b \prod_{t=2}^{T} \bar{w}_{t-1}^{\beta_{t-1}}} \nonumber \\
&= \frac{1}{Z} \prod_{t=1}^T \frac{1}{N} \sum_{\ell=1}^N w_{t}^{\ell} \nonumber \\
& = \frac{\hat{Z}}{Z}
\end{align}
and therefore $\hat{Z}$ is, up to a normalization constant, the importance weight for our sampling.
Thus we can use $\hat{Z}$ in our accept-reject step to get a valid sampler MH sampler.  Note that
as an aside, this also shows the unbiasedness of SMC as we see that
\begin{align}
\E_{q_{\text{PIMH}}(b,\xib)} \left[\hat{Z}\right]=\E_{\tilde{\pi}(b,\xi)} \left[Z\right]=Z.
\end{align}

\subsection{Particle Gibbs}
\label{sec:part:pmcmc:pgibbs}

One particularly widely used \pmcmc algorithm is particle Gibbs (\pg). The \pg algorithm modifies the \smc step in the \pmcmc algorithm to sample the latent variables conditioned on an existing particle trajectory, resulting in what is called a conditional sequential Monte Carlo (\csmc) step. The \pg method was first introduced as an efficient Gibbs sampler for latent variable models with static parameters \citep{andrieuDH2010}. Since then, the \pg algorithm and the extension by \citet{lindstenJS2014} have found numerous applications in \eg Bayesian non-parametrics \citep{ValeraFSPC2015,tripuraneni2015}, probabilistic programming \citep{wood2014new,vandemeent_aistats_2015} and graphical models \citep{everitt2012,naessethLS2014,naessethLS2015nested}.  

The \pg algorithm \citep{andrieuDH2010} is a Gibbs sampler on the extended space composed of all random variables generated at one iteration, which still retains the original target distribution as a marginal. Though \pg allows for inference over both latent variables and static parameters, we will in this paper focus on sampling of the former.  The core idea of \pg is to iteratively run \emph{conditional} sequential Monte Carlo (\csmc) sweeps as shown in Algorithm~\ref{alg:csmc}, whereby each conditional trajectory is sampled from the surviving trajectories of the previous sweep.  This \emph{retained particle} index, $b$, is sampled with probability proportional to the final particle weights $\bar{w}^i_T$. 

\begin{algorithm}[tb]
	\caption{Conditional sequential Monte Carlo}
	\label{alg:csmc}
	\begin{spacing}{1.2}
		\begin{algorithmic}[1]
			\renewcommand{\algorithmicrequire}{\textbf{Inputs:}}
			\renewcommand{\algorithmicensure}{\textbf{Outputs:}}				 
			\Require data $y_{1:T}$, number of particles $N$, proposals $q_t$, conditional trajectory $x_{1:T}'$
			\State $x_1^i \sim q_1(x_1), ~i=1,\ldots,N-1$ and set $x_1^N = x_1'$
			\State $w_1^i = \frac{g_1(y_1|x_1^i) \mu(x_1^i)}{q_1(x_1^i)}, ~i=1,\ldots,N$
			\For{$t = 2$ {\bfseries to} $T$}
			\State $a_{t-1}^i \sim \Discrete\left(\left\{\nw_{t-1}^\ell\right\}_{\ell=1}^N\right), ~i=1,\ldots,N-1$
			\State $x_t^i \sim q_t(x_t | x_{1:t-1}^{a_{t-1}^i}), ~i=1,\ldots,N-1$
			\State Set $a_{t-1}^N = N$ and $x_t^N = x_t'$
			\State Set $x_{1:t}^i = (x_{1:t-1}^{a_{t-1}^i},x_t^i), ~i=1,\ldots,N$
			\State $w_t^i = \frac{g_t(y_t|x_{1:t}^i) f_t(x_t^i | x_{1:t-1}^{a_{t-1}^i})}{q_t(x_t^i|x_{1:t-1}^{a_{t-1}^i})}, ~i=1,\ldots,N$
			\EndFor
		\end{algorithmic}
	\end{spacing}
\end{algorithm}

A drawback of PG is that it can be particularly adversely affected by \emph{path degeneracy} in the CSMC step.  Conditioning on an existing trajectory means that whenever resampling of the trajectories results in a common ancestor, this ancestor must correspond to this trajectory.  Consequently, the mixing of the Markov chain for the early steps in the state sequence can become very slow when the particle set typically coalesces to a single ancestor during the CSMC sweep.
We address this next with the iPMCMC algorithm.

%In the same way as above for the standard \smc algorithm we can define a joint probability distribution induced by running Algorithm~\ref{alg:csmc} %$q_{\text{CSMC}}(\xb^{1:N},\ab^{1:N}\backslash\{\xb^N,\bb^N\} | \xb^N,\bb^N)$, induced by running Algorithm~\ref{alg:csmc}, where $\xb^N, \bb^N$ is the retained (conditioning) particle. 
%\begin{align}
%&q_{\text{CSMC}}\left(\xb^{1:N},\ab^{1:N} \backslash \{\xb^N, \bb^N\} \mid \xb^N, \bb^N, k \right) = \nonumber \\
%&\prod_{\substack{i=1\\i\neq b_{1}}}^N \left[ q_1(x_{1}^i) \right] \prod_{t=2}^T \prod_{\substack{i=1\\i\neq b_{t}}}^N \left[\frac{W_{t-1}^{a_{t-1}^i}}{\sum_\ell W_{t-1}^\ell} q_t(x_{t}^i|x_{1:t-1}^{a_{t-1}^i})\right],
%\end{align}
%where $\xb^N, \bb^N$ is the retained (conditioning) particle.
%\brooks{doesn't make sense --- if the retained particle is $N$, why is it $\xb_m^k, \bb_m^k$ in the above equation? shouldn't $\xb_m^{1:N},\ab_m^{1:N} \backslash \{\xb_m^k, \bb_m^k\}$ actually be $\xb_m^{1:N-1},\ab_m^{1:N-1}$?}


%
%   Limitations
%
%\subsection{Parallelisation and Limitations}
%\label{sec:limitations}
%Our main goal is to increase the efficiency of particle \mcmc, particle Gibbs especially, by coupling independent \smc methods with \csmc algorithms, perhaps running on different workers or threads. The method we propose, interacting particle Markov chain Monte Carlo (\ipmc), makes efficient use of multi-core and distributed computing architectures to increase accuracy of the Monte Carlo sampler.

%The basic \pg typically suffers from the \emph{path degeneracy} effect of \smc samplers, \ie sample impoverishment due to frequent resampling, which leads to bad mixing of the Markov chain. Since we force one trajectory, the conditional part, to survive to the end it means that for early time steps we will almost always pick the corresponding sample from last iteration. To counteract this we might need a very high number of particles to get good mixing for all latent variables $x_{1:T}$, which can be infeasible due to e.g.~limited available memory. The \ipmc can alleviate this issue by a non-standard coupling of several conditional and unconditional (standard) \smc algorithms. The algorithm lets us, from time to time, completely switch out a \csmc particle system with a completely independent \smc one, resulting in improved mixing of the Markov chain.
