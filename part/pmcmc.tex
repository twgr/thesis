% !TEX root = ../main.tex

\section{Particle Markov Chain Monte Carlo Methods}
\label{sec:part:pmcmc}

Particle Markov chain Monte Carlo (\pmcmc) methods, introduced by \citet{andrieu2010particle}, make use of 
sequential Monte Carlo (\smc) algorithms \citep{gordon1993novel,doucet2001sequential} to construct 
efficient proposals for an \mcmc sampler. This allows them to both utilize the ability of SMC to
exploit the structure of the target problem and the hill climbing behavior of MCMC methods.
The critical difference from running independent SMC sweeps, is that information can be transferred
from one sweep to the next. 
%The core reason for wanting to do this is that
%one is typically memory restricted in the number of particles that can be run $N$.  Though as we explained
%before, we can run multiple sweeps and combine these using the marginal likelihood estimates, if $N$ is
%not large enough, this typically results it widely varying estimates.  Although these estimates are unbiased,
%they are typically extremely skew, often following a roughly Gaussian distribution in their \emph{log} marginal
%likelihood CITE SOMETHING.  As such, it usually happens if $N$ is not large enough that one sweep dominates the others because
%its marginal likelihood is many orders of magnitude larger than the others and our estimate is
%effectively just the particle sweep with the highest marginal likelihood.  We therefore desire a more principled
%means of transferring the information of one iteration to the next which we can do by constructing an appropriate MCMC
%sampler.  We can then combine the advantages of SMC in its exploitation of the structure of the target with
%the local updating advantages of MCMC methods.  
Naturally, this will come with the drawbacks of MCMC samplers
discussed in Section~\ref{sec:inf:foundation:mcmc}, such as the loss of an unbiased marginal likelihood estimate.
However, the advantages will generally outweigh these drawbacks.  PMCMC methods will also allow us to explicitly
treat global parameters of our system differently to the latent states in a manner that can substantially improve
the performance of the model.
Though PMCMC methods can be applied to models with arbitrary series of targets in the same manner as SMC, we will stick
to the NMSSM case in this section and the next for notational simplicity.

\subsection{Particle Independent Metropolis Hastings}
\label{sec:part:pmcmc:pimh}

Particle independent Metropolis Hastings (PIMH) is the simplest PMCMC algorithm.  Although in isolation it is
not especially useful (as it strictly worse than running independent SMC sweeps and combining 
them),\footnote{There is, though, utility in doing this when including MCMC steps on global parameters~\cite{andrieu2010particle}.}
 it is an
important theoretical stepping stone to more advanced approaches.  The idea from a practical perspective 
is very simple: use an SMC sweep as an \emph{independent} proposal for an MCMC algorithm targeting $\pi(x_{1:T}) = p(x_{1:T}|y_{1:T})$.
From a theoretical perspective, the approach is rather more profound as it can be viewed as a sampler on 
an \emph{extended space} whose marginal on the returned particles is the target.  
%We will then be able to use
%this to construct more powerful samplers.

\begin{algorithm}[tb]
	\caption{Particle Independent Metropolis Hastings}
	\label{alg:part:pimh}
	\begin{spacing}{1.2}
		\begin{algorithmic}[1]
			\renewcommand{\algorithmicrequire}{\textbf{Inputs:}}
			\renewcommand{\algorithmicensure}{\textbf{Outputs:}}				 
			\Require number of MCMC iterations R, initial output particle $\xb'[0]$ and marginal likelihood
			$\mathbf{Z}'[0]$ (typically both generated from an \smc sweep)
			\Ensure MCMC samples $\{\xb'[r]\}_{r=1}^R$ where each $\xb'[r] \in \mathbb{X}_T$
%			\State Run SMC giving particle set $X_{1:T} = \{x_{1:T}^{i},\nw_T^{i}\}_{i=1}^N$ and marginal likelihood $\hat{Z}$
%			\State Sample retained particle index $b$ using weights as per~\eqref{eq:part:b}
%			\State Initialize output particle $\xb'[0] \leftarrow x_{1:T}^b$ and marginal likelihood $\mathbf{Z}'[0] \leftarrow \hat{Z}$
			\For{$r=1:R$}
			\State Run Algorithm~\ref{alg:part:smc} (\smc) giving candidate $X_{1:T} = \{x_{1:T}^{i},\nw_T^{i}\}_{i=1}^N$
				 and $\hat{Z}$
			\If{$u\le \min \left(1,\hat{Z}/\mathbf{Z}'[r-1]\right)$ where $u\sim \textsc{Uniform}(0,1)$}
			\State Sample output particle index $b$ in proportion to weights as per~\eqref{eq:part:b}
			\State $\xb'[r] \leftarrow x_{1:T}^b \quad \mathbf{Z}'[r] \leftarrow \hat{Z}$  \Comment New sweep accepted
			\Else
			\State $\xb'[r]\leftarrow \xb'[r-1], \quad \mathbf{Z}'[r] \leftarrow \mathbf{Z}'[r-1]$ \Comment New sweep rejected
			\EndIf
			\EndFor
		\end{algorithmic}
	\end{spacing}
\end{algorithm}

The PIMH algorithm is described in Algorithm~\ref{alg:part:pimh}.  We see that PIMH is an MCMC
algorithm where our proposal involves running an independent SMC
sweep and then sampling one of the particles from this set in proportion to
the weight of the particle.
  This sample is then accepted or rejected using a MH accept-reject
step that  utilizes the marginal likelihoods of the sweeps.  
To be more precise, let $\xib \eqdef \{x_{t}^i\}_{\substack{i=1:N\\t=1:T}} \bigcup \{a_{t}^i\}_{\substack{i=1:N\\t=1:T-1}}$
denote all generated particles and ancestor variables of a \smc sampler, and let the associated
marginal likelihood estimate be denoted as $\hat{Z}$ which is calculated as per~\eqref{eq:part:ML}.
Let $\xb^i = x_{1:T}^i$ denote one of the final particles and let the index of the final
particle we sample be denote as $b$ which is sampled according to
\begin{align}
\label{eq:part:b}
b \sim \Discrete\left(\left\{\nw_{T}^\ell\right\}_{\ell=1}^N\right).
\end{align}
Sampling a particle also indicates an ancestral path
which we denote as $\bb = (\beta_{1,},\ldots,\beta_{T})$, with
$\beta_{T} = b$ and $\beta_{t} = a_{t}^{\beta_{t+1}}$.  The result of running a \smc sweep
and sampling $b$ thus proposes a $\{\xb^{b},\bb\}$, though in the context of PIMH we only care about the particle
$\xb^b$.  Given this proposal, the acceptance ratio used for PIMH is
given by the ratio of the marginal likelihood estimates for the current point and the \smc used
to propose the candidate particle.  If we denote the MCMC particle sample at iteration $r$ as $\xb'[r]$ and
associated marginal likelihood as $\mathbf{Z}'[r]$, then our proposed sample $\{\xb^b,\hat{Z}\}$ 
is accepted with probability
\begin{align}
\label{eq:part:pimh-acc}
P(\text{Accept}) = \min \left(1,\frac{\hat{Z}}{\mathbf{Z}'[r-1]}\right)
\end{align}
forming a MH sampler.
Given our MCMC samples, the resulting Monte Carlo estimator is defined in the normal way as
\begin{align}
\label{eq:part:pimh-est}
\E_{\pi (x_{1:T})} \left[f(x_{1:T})\right] \approx \frac{1}{R} \sum_{r=1}^{R} f(\xb'[r]).
\end{align}
Because our proposal
is independent of our current point, this is strictly worse than just running independent SMC sweeps
(which can also be thought of as applying waste recycling~\citep{frenkel2006waste} to PIMH).  
It might seem particularly wasteful to only use
one particle from each sweep, but we will be able to use Rao-Blackwellization to justify
returning all the particles at each step as we explain in Section~\ref{sec:part:pmcmc:all}. 

%Imagine that we were able to exactly calculate the posterior probability of the of samples
%generated by an SMC sweep up to a normalization constant $\gamma(X_{1:T} |y_{1:T})$.  It would
%now be straightforward to construct a valid sampler on this distribution by constructing an independent
%MH proposal and accept/reject the particle sets in the standard way.
The key component of proving the correctness of the PIMH algorithm is in showing that it is a valid
MH sampler on an \emph{extended target distribution} whose marginal distribution on $\xb^b$ is the distribution of interest $\pi(\xb)$.
%The two key components of proving
%the correctness of the PIMH algorithm are in showing that running and SMC sweep then sampling
%one of the samples produced an extended target distribution whose normalized marginal distribution is
%the posterior of interest $\pi(x_{1:T}|y_{1:T})$ and that our MH algorithm remains valid when
%provided with an \emph{unbiased estimate} of the target distribution rather than an exact calculation.
The density of the distribution induced by running an SMC sweep is given by
\begin{align}
\label{eq:part:smc:proposal}
q_{\text{SMC}}(\xib) &= \prod_{i=1}^N q_1(x_{1}^i) \cdot \prod_{t=2}^T \prod_{i=1}^N \left[ 
\nw_{t-1}^{a_{t-1}^i}
%\frac{w_{t-1}^{a_{t-1}^i}}{\sum_\ell w_{t-1}^{\ell}}
q_t(x_{t}^i|x_{1:t-1}^{a_{t-1}^i}) \right]  \quad \text{where} \quad \bar{w}_t^i = \frac{{w}_t^i}{\sum_{\ell=1}^{N}w_t^{\ell}}
\end{align}
and the distribution induced by running an SMC sweep and then choosing particle $b$
\begin{align}
q_{\text{PIMH}}(\xib,b) = \bar{w}_T^b q_{\text{SMC}}(\xib)
\end{align}
Our extended target distribution is now constructed using the following hypothetical process
\begin{enumerate}
	\setlength\itemsep{-0.1em}
	\item Sample a particle exactly from the target $\xb^b \sim \pi(\xb)$.
	\item Sample an ancestral path for the retained particle uniformly at random by independently sampling each $\beta_t \sim \textsc{UniformDiscrete}(1,N)$ and setting $\bb = (\beta_1,\dots,\beta_T)$.
	\item Sample all of the other particles and ancestor indices conditioned on $\{\xb^{b},\bb\}$ using
		\begin{align}
	\label{eq:part:csmc}
	q_{\text{CSMC}}\left(\xib \backslash \{\xb^b, \bb\} \mid \xb^b, \bb \right) = 
	\prod_{i=1, i\neq\beta_1}^N  q_1(x_{1}^i) \cdot \prod_{t=2}^T \prod_{i=1,i\neq b_{t}}^N \left[
	\nw_{t-1}^{a_{t-1}^i}q_t(x_{t}^i|x_{1:t-1}^{a_{t-1}^i})\right],
	\end{align}
	which corresponds to $q_{\text{SMC}}(\xib)$ as per~\eqref{eq:part:smc:proposal},
	except for having one particle and path, $\{\xb^{b},\bb\}$, predefined, such that we can think
	of the sweep as being \emph{conditioned} on $\{\xb^{b},\bb\}$.
\end{enumerate}
We can informally think of this as doing the PIMH process in reverse.  Rather than
running an SMC sweep and sampling one of the produced particles to give $\{\xb^{b},\bb\}$, it
first samples $\{\xb^{b},\bb\}$ and then the rest of the variables in the SMC sweep conditioned
on this particle and accompanying ancestral path.
Together these steps induce the distribution
\begin{align}
\label{eq:part:pimh-target}
\tilde{\pi}(\xi,b) = \frac{\pi(\xb^{b})}{N^T} \; q_{\text{CSMC}}\left(\xib \backslash \{\xb^b, \bb\} \mid \xb^b, \bb \right)
\end{align}
remembering that as $\xi$ includes all the particles and ancestral paths, sampling $\xi$
and $b$ implies a particular $\{\xb^{b},\bb\}$.
By construction (i.e the first step of our hypothetical process), the marginal of this distribution is $\pi(\xb^{b})$.
Therefore, although it is not possible to actually
sample from $\tilde{\pi}(\xi,b)$ directly (we started the definition by sampling exactly
from the distribution of interest), if we can
construct a consistent MCMC estimator on~\eqref{eq:part:pimh-target} then this by proxy
produces a consistent estimator for $\pi(\xb^{b})$, remembering that Monte Carlo samples
from a joint distribution have the correct marginal distributions.
We can now show that this is exactly what the
PIMH algorithm does by explicitly calculating the importance weight implied by
targeting $\tilde{\pi}(\xi,b)$ using the proposal $q_{\text{PIMH}}(\xib,b)$
\begin{align}
&\frac{\tilde{\pi}(\xi,b)}{q_{\text{PIMH}}(\xib,b)} = \frac{\pi(\xb^{b}) q_{\text{CSMC}}\left(\xib \backslash \{\xb^b, \bb\} \mid \xb^b, \bb \right)}
{N^T \bar{w}_T^b q_{\text{SMC}}(\xib)} = \frac{\pi(\xb^{b})}{N^T \bar{w}_T^b q_1(x_1^{\beta_1}) \prod_{t=2}^{T} \bar{w}_{t-1}^{\beta_{t-1}} q_t(x_t^{\beta_t} | x_{t-1}^{\beta_{t-1}})} \nonumber \\
&\quad = \left(\frac{\gamma(\xb^{b})/Z}{
	q_1(x_1^{\beta_1}) \prod_{t=2}^{T} q_t(x_t^{\beta_t} | x_{t-1}^{\beta_{t-1}})}\right) \cdot
	\left( \frac{1}{N^T \bar{w}_T^b\prod_{t=2}^{T} \bar{w}_{t-1}^{\beta_{t-1}}} \right) 
	= \left(\frac{1}{Z}
	 \prod_{t=1}^{T} w_{t}^{\beta_{t}}\right)\cdot\left(
	\frac{1}{N^T \prod_{t=1}^{T} \bar{w}_{t}^{\beta_{t}}}\right) \nonumber \\
&\quad = \left(\frac{1}{Z}
\prod_{t=1}^{T} w_{t}^{\beta_{t}}\right)\cdot\left(
	\frac{\prod_{t=1}^T \frac{1}{N} \sum_{\ell=1}^N w_{t}^{\ell}}{\prod_{t=1}^{T} w_{t}^{\beta_{t}}}\right) 
	= \frac{1}{Z} \prod_{t=1}^T \frac{1}{N} \sum_{\ell=1}^N w_{t}^{\ell}
= \frac{\hat{Z}}{Z}. \label{eq:part:pimh-w}
\end{align}
We thus have that $\hat{Z}$ is the importance weight for sampling the unnormalized
version of the target $\tilde{\gamma}(\xi,b) = Z \tilde{\pi}(\xi,b)$ and so using the
ratio of marginal likelihood estimates is exactly the acceptance ratio required for
the MH sampler.  We
have therefore proven that the PIMH algorithm induces a convergent Markov chain for
the target $\pi(x_{1:T})$ and therefore that our estimator given in~\eqref{eq:part:pimh-est} is
consistent.
Note that as an aside, this also shows the unbiasedness of the SMC marginal likelihood estimate
as we see that
\begin{align}
\E_{q_{\text{SMC}}(\xib)} \left[\hat{Z}\right] = \E_{q_{\text{PIMH}}(\xib,b)} 
\left[\hat{Z}\right]=\E_{\tilde{\pi}(\xi,b)} \left[Z\right]=Z.
\end{align}

\subsection{Particle Gibbs}
\label{sec:part:pmcmc:pgibbs}

One particularly widely used \pmcmc algorithm is particle Gibbs (\pg). The \pg algorithm modifies the 
\smc step in the \pmcmc algorithm to sample the latent variables conditioned on an existing particle
 trajectory, resulting in what is called a \emph{conditional sequential Monte Carlo} (\csmc) step. The \pg method
  was first introduced as an efficient Gibbs sampler for latent variable models with static parameters 
  \citep{andrieu2010particle}. Since then, the \pg algorithm and the extension by \citet{lindstenJS2014} have 
  found numerous applications in \eg Bayesian non-parametrics \citep{ValeraFSPC2015,tripuraneni2015}, 
  probabilistic programming \citep{wood2014new,vandemeent_aistats_2015} and graphical models 
  \citep{everitt2012,naessethLS2014,naessethLS2015nested}.  Whereas PIMH used independent proposals, 
  \pg transfers information from one MCMC iteration to the next by using \emph{retained particles}.  It, therefore,
  introduces, typically desirable, hill-climbing behavior, often resulting in improved performance
  compared with running independent SMC sweeps, particularly for the latter states in the state sequence.

The \pg algorithm targets the same extended target $\tilde{\pi}(\xib,b)$ as the PIMH algorithm defined
in~\eqref{eq:part:pimh-target}, but rather than constructing a MH sampler with independent proposals for
this target, it constructs a Gibbs sampler.  This is done by iteratively 
running \csmc sweeps. As described in Algorithm~\ref{alg:csmc},
a \csmc sweep is similar to a standard, unconditional \smc sweep, except that it starts
with an existing \emph{conditional trajectory} $x_{1:T}'$, known as a \emph{retained particle} in the \pg
context, and runs the sweep conditioned on this conditional trajectory being present in the final sample
set.  One can think of this as running an SMC sweep conditioned on the predefined particle surviving each
of the resampling steps.  In other words, the other particles can sample the retained particle as an
ancestor but not vice versa, with the values and ancestral path of the retained particle prefixed. 
Note that running Algorithm~\ref{alg:csmc} corresponds to using a fixed
choice for the index variables $\bb = (N\,\ldots,N)$. While these indices are used to facilitate the
proof of validity of the proposed method, they have no practical relevance (all paths are marginally equivalent
by symmetry), and can thus be set to arbitrary
values, as is done in Algorithm~\ref{alg:csmc}, in a practical implementation.
\begin{algorithm}[tb]
	\caption{Conditional sequential Monte Carlo}
	\label{alg:csmc}
	\begin{spacing}{1.2}
		\begin{algorithmic}[1]
			\renewcommand{\algorithmicrequire}{\textbf{Inputs:}}
			\renewcommand{\algorithmicensure}{\textbf{Outputs:}}				 
			\Require data $y_{1:T}$, number of particles $N$, proposals $q_t$, conditional trajectory $x_{1:T}'$
			\State $x_1^i \sim q_1(x_1), ~i=1,\ldots,N-1$ and set $x_1^N = x_1'$
			\State $w_1^i = \frac{g_1(y_1|x_1^i) \mu(x_1^i)}{q_1(x_1^i)}, ~i=1,\ldots,N$
			\For{$t = 2$ {\bfseries to} $T$}
			\State $a_{t-1}^i \sim \Discrete\big(\left\{\nw_{t-1}^\ell\right\}_{\ell=1}^N\big), ~i=1,\ldots,N-1$
			\State $x_t^i \sim q_t(x_t | x_{1:t-1}^{a_{t-1}^i}), ~i=1,\ldots,N-1$
			\State Set $a_{t-1}^N = N$ and $x_t^N = x_t'$
			\State Set $x_{1:t}^i = (x_{1:t-1}^{a_{t-1}^i},x_t^i), ~i=1,\ldots,N$
			\State $w_t^i = \frac{g_t(y_t|x_{1:t}^i) f_t(x_t^i | x_{1:t-1}^{a_{t-1}^i})}{q_t(x_t^i|x_{1:t-1}^{a_{t-1}^i})}, ~i=1,\ldots,N$
			\EndFor
		\end{algorithmic}
	\end{spacing}
\end{algorithm}

Unlike \smc sweeps, \csmc sweeps can be linked together by conditioning each sweep using a retained particle
sampled from the previous sweep with probability proportional to the final particle weights $\bar{w}^i_T$.
Therefore, once initialized, say using a standard \smc sweep, one can iterate between sampling a retained
particle in the same manner ancestor indices are sampled and running \csmc sweeps conditioned on this
retained particle.  This is known as iterated \csmc (ICSMC) and, considerations about global parameters 
aside (see Section~\ref{sec:part:pmcmc:global}),  constitutes the \pg algorithm.
Note that the resampling step must always be done for \csmc sweeps (i.e. the techniques introduced in
Section~\ref{sec:part:smc:prat:ad-re} cannot be used), as, unlike in an \smc sweep, the resampling for
a \csmc sweep does not maintain the target distribution.  Another
important difference is that, unlike \smc, a \csmc sweep does not provide an unbiased estimate for the
marginal likelihood (expect in the limit $N\rightarrow\infty$).

The theoretical justification for the \pg algorithm can be shown in a similar manner as the PIMH algorithm.
The sampled index $b$ now corresponds the index of the retained particle and we can think of the
approach as alternating between Gibbs updates on $b$ and $\xib \backslash \{\xb^b,\bb\}$.    In other
words, we alternate between sampling 
\begin{subequations}
	\label{eq:part:pg-updates}
	\begin{align}
	b &\sim \tilde{\pi}(b | \xib) = \frac{\tilde{\pi}(\xi,b)}{\int \tilde{\pi}(\xi,b) db} \label{eq:part:pg-updates1}\\
	\xib \backslash \{\xb^b,\bb\} & \sim \tilde{\pi}(\xib \backslash \{\xb^b,\bb\}  | \xb^b,\bb) =
	\frac{\tilde{\pi}(\xi,b)}{\iint \tilde{\pi}(\xi,b) d\xib \backslash \{\xb^b,\bb\}}. \label{eq:part:pg-updates2}
		\end{align}
\end{subequations} 
The key step to seeing that the \pg
algorithm samples from these distributions is noting that~\eqref{eq:part:csmc} corresponds to the distribution
induced by running a \csmc sweep with retained particle $\{\xb^b,\bb\}$.  By construction
then $\tilde{\pi}(\xib \backslash \{\xb^b,\bb\}  | \xb^b,\bb) = q_{\text{CSMC}}(\xib \backslash \{\xb^b,\bb\}  | \xb^b,\bb)$
and so each \csmc sweep samples exactly from~\eqref{eq:part:pg-updates2}.  To complete the derivation
we need to show that $\tilde{\pi}(b | \xib) = \bar{w}_T^b$ so that choosing the retained particle corresponds
exactly to sampling from~\eqref{eq:part:pg-updates1}.    This can be done by noting that
\begin{align*}
\int \tilde{\pi}(\xi,b) db = \int q_{\text{PIMH}}(\xib,b) \frac{\hat{Z}}{Z} db
= \int \bar{w}_T^b q_{\text{SMC}}(\xib) \frac{\hat{Z}}{Z} db
= q_{\text{SMC}}(\xib) \frac{\hat{Z}}{Z} \int \bar{w}_T^b  db = q_{\text{SMC}}(\xib) \frac{\hat{Z}}{Z}
\end{align*}
and therefore
\begin{align*}
\tilde{\pi}(b | \xib) = \frac{\tilde{\pi}(\xi,b)}{q_{\text{SMC}}(\xib) \frac{\hat{Z}}{Z}} 
= \frac{q_{\text{PIMH}}(\xib,b) \frac{\hat{Z}}{Z}}{q_{\text{SMC}}(\xib) \frac{\hat{Z}}{Z}} = \bar{w}_T^b
\end{align*}
as required.  We thus have that both~\eqref{eq:part:pg-updates1} and ~\eqref{eq:part:pg-updates2} are valid
Gibbs updates on our extended target $\tilde{\pi}(\xi,b)$.  Now applying each 
of~\eqref{eq:part:pg-updates1} and~\eqref{eq:part:pg-updates2} once can change all of the variables in
our target as it can change the retained particle, the index $b$, and all the other particles.\footnote{Note
	also that applying the update cycle twice can potentially completely remove the retained particle from the
	system and so we need not worry about the possibility of the retained particle simply being ``passed around''.}
Therefore the combination of the two updates forms a valid Gibbs sampler for the target $\tilde{\pi}(\xi,b)$.
Because $\tilde{\pi}(\xi,b)$ has a marginal distribution on the returned samples $\pi (\xb^b)$ which is equal to
the desired target, we have thus proven that using the \pg algorithm and calculating estimates in the manner 
defined in~\eqref{eq:part:pimh-est} leads to a consistent estimator.

\subsection{Path Degeneracy}
\label{sec:part:pmcmc:path-deg}

A drawback of particle-based methods, and in particular the \pg algorithm, is that they can be adversely 
affected by \emph{path degeneracy} in the (C)SMC sweep.  Path degeneracy is the tendency of the number
of unique samples to diminish as one follows the ancestry backward through the sweep.  In other words, because
of the resampling, there will typically be fewer (and never more) unique instances of $x_{t-1}$ than of $x_t$
in the final particle set $\{x_{1:T}^i,\nw_{T}^i\}_{i=1}^T$ and therefore there are often few distinct samples
for the earlier steps by the end of the sweep.  It is not uncommon for the ancestral paths to collapse back to a single sample for
small $t$, an example of which is demonstrated in the bottom right of Figure~\ref{fig:part:smc_explan}
where there is a collapse to a single trajectory for $t\le6$.
Degeneracy can be especially detrimental when the posterior on the early latent variables is significantly
affected by later observations, e.g. when some of the early latent variables correspond to global parameters,
as this creates a significant mismatch between the intermediate targets.  Consequently, observations should
be made as early as possible in the state sequence when taking a particle-based inference approach, e.g.
placing \observe statements as early as possible in probabilistic programming query.

For methods that run independent \smc sweeps such as \smc itself and PIMH, the detrimental impact
of path degeneracy is generally seen through high variance of the marginal likelihood estimates,  resulting
in  low effective sample sizes and or slow mixing rates.  For \pg then path degeneracy can be even
more catastrophic.  Conditioning on an existing trajectory means 
that whenever resampling of the trajectories results in a common ancestor, this ancestor must correspond 
to this trajectory.  For a \pg sampler, any common ancestor is, by construction, guaranteed to be equal 
to the retained particle, such that the early part of the trajectory in the retained particle cannot
change from one iteration to the next if the particle set has coalesced to a single ancestor.
This results in high correlation between the samples, and poor mixing of the Markov chain.
Approaches for alleviating this degeneracy include resample-move methods~\citep{chopin2013smc2},
which rejuvenate the particle set by interleaving resampling with MCMC updates for the \emph{full} trace,
and, for the particular case of \pg, ancestor sampling \citep{lindstenJS2014} methods, 
which sample new ancestors for the retained particle as the 
\csmc sweep is run.  Though highly effective, for many models these methods cause a quadratic increase
in the computational cost with the length of the state space, meaning that they are often prohibitively expensive
in practice.  In Section~\ref{sec:part:ipmcmc} we introduce an alternative, and often complementary, 
means of overcoming degeneracy
problems in the form of the interacting PMCMC algorithm~\citep{rainforth2016interacting}.


\subsection{Global Parameters}
\label{sec:part:pmcmc:global}

An important feature of PMCMC methods that we have thus far omitted is that they allow for
distinct treatment of global parameters.  Imagine we are interested in sampling from $p(\theta,x_{1:T} | y_{1:T})$
where $\theta$ are some global parameters that are of particular importance as they directly
affect all the other variables, e.g. because they are effect each transition and or emission distribution.
As we explained in Section~\ref{sec:part:pmcmc:path-deg}, SMC / PMCMC methods can do relatively poorly on sampling
the earlier parameters, particularly if these have long-range dependencies. One may often therefore wish 
to use a different sampling scheme
for the global parameters, which is possible in PMCMC methods using either Gibbs sampling or Metropolis-within-Gibbs
sampling to update $\theta$, rather than including them in the SMC sweep.

Perhaps the simplest way of doing this is using the \emph{particle marginal Metropolis-Hastings} (PMMH)
sampler.  This extends the PIMH sampler by using a standard MH update proposal $q(\hat{\theta}|\theta=\mathbf{\theta}[r-1])$ 
before each SMC sweep such that the overall proposal is
\begin{align}
q_{\text{PMMH}}(\xib,\hat{\theta}|\mathbf{\theta}[r-1]) = q(\hat{\theta}|\mathbf{\theta}[r-1]) 
q_{\text{PIMH}}(\xib | \hat{\theta})
\end{align}
and samples are now accepted with probability
\begin{align}
P(\text{Accept}) = \min \left(1,\frac{\hat{Z} q(\mathbf{\theta}[r-1] | \hat{\theta})}
{\mathbf{Z}'[r-1] q(\hat{\theta}|\mathbf{\theta}[r-1])}\right).
\end{align}
Typically more effectively, one can also use manual updates for $\theta$ in the \pg algorithm by alternating
between running \csmc sweeps, sampling the index of the retained particle, and updating $\theta$ given
the retained particle (note the difference to PMMH where $\theta$ is updated independently of $\xb'[r]$).
Here one either relies on being able to sample from $\theta \sim p(\theta | x_{1:T}=\xb'[r], y_{1:T})$, which is 
occasionally possible, or uses a MH step to update $\theta$ targeting $p(\theta | x_{1:T}=\xb'[r], y_{1:T})$ as
a Metropolis-with-Gibbs update.  In the latter case ,it is typically preferable to carry out multiple update steps
on the parameters between each \csmc sweep to ensure fast mixing, noting that the latter is generally at least a 
factor of $N$ more times expensive.

\subsection{Rao-Blackwellization}
\label{sec:part:pmcmc:all}

At each \mcmc iteration $r$, we generate $N$ full particle trajectories. 
Using only one of these as in \eqref{eq:part:pimh-est} might seem a bit wasteful. 
We can, however, make use of all particles to estimate expectations of interest for all
of the PMCMC methods introduced so far by analytically averaging over the possible
values of $b$ that could be sampled at each iteration. 
We can do this noting that $\E\left[\frac{1}{R} \sum_{r=1}^{R} f(\xb'[r]) \right]
= \frac{1}{R} \sum_{r=1}^{R} \E\left[\E\left[ f(\xb'[r]) \middle| \xib\right]\right]$,
and then replacing $f(\xb'[r])$ in \eqref{eq:part:pimh-est}  by the analytically calculable
\begin{align}
\label{eq:part:rao-pg}
\E\left[f(\xb'[r]) \middle| \xib \right] = \E\left[f(x_{1:T}^b) \middle| \xib \right]
= \sum_{i=1}^N \nw_{T,m}^i f(\xb_{m}^i),
\end{align}
where the expectation is over the sampling of $b$ and  the second equality follows 
from the definition of the expectation of a discrete distribution,
remembering $b \sim \Discrete\left(\left\{\nw_{T}^i\right\}_{i=1}^N\right)$.
This procedure is known as \emph{Rao-Blackwellization} of a statistical estimator and is (in terms of variance) 
never detrimental~\citep{casella1996rao}.  At a high level, we are taking an analytic expectation over part of
the randomness of the system, namely the sampling of $b$.
%When also doing global parameter updates, we can think of the samples being returned immediately after
%sampling $b$ and so that we can still Rao-Blackwellize in the same manner.

%In the same way as above for the standard \smc algorithm we can define a joint probability distribution induced by running Algorithm~\ref{alg:csmc} %$q_{\text{CSMC}}(\xb^{1:N},\ab^{1:N}\backslash\{\xb^N,\bb^N\} | \xb^N,\bb^N)$, induced by running Algorithm~\ref{alg:csmc}, where $\xb^N, \bb^N$ is the retained (conditioning) particle. 
%\begin{align}
%&q_{\text{CSMC}}\left(\xb^{1:N},\ab^{1:N} \backslash \{\xb^N, \bb^N\} \mid \xb^N, \bb^N, k \right) = \nonumber \\
%&\prod_{\substack{i=1\\i\neq b_{1}}}^N \left[ q_1(x_{1}^i) \right] \prod_{t=2}^T \prod_{\substack{i=1\\i\neq b_{t}}}^N \left[\frac{W_{t-1}^{a_{t-1}^i}}{\sum_\ell W_{t-1}^\ell} q_t(x_{t}^i|x_{1:t-1}^{a_{t-1}^i})\right],
%\end{align}
%where $\xb^N, \bb^N$ is the retained (conditioning) particle.
%\brooks{doesn't make sense --- if the retained particle is $N$, why is it $\xb_m^k, \bb_m^k$ in the above equation? shouldn't $\xb_m^{1:N},\ab_m^{1:N} \backslash \{\xb_m^k, \bb_m^k\}$ actually be $\xb_m^{1:N-1},\ab_m^{1:N-1}$?}


%
%   Limitations
%
%\subsection{Parallelisation and Limitations}
%\label{sec:limitations}
%Our main goal is to increase the efficiency of particle \mcmc, particle Gibbs especially, by coupling independent \smc methods with \csmc algorithms, perhaps running on different workers or threads. The method we propose, interacting particle Markov chain Monte Carlo (\ipmc), makes efficient use of multi-core and distributed computing architectures to increase accuracy of the Monte Carlo sampler.

%The basic \pg typically suffers from the \emph{path degeneracy} effect of \smc samplers, \ie sample impoverishment due to frequent resampling, which leads to bad mixing of the Markov chain. Since we force one trajectory, the conditional part, to survive to the end it means that for early time steps we will almost always pick the corresponding sample from last iteration. To counteract this we might need a very high number of particles to get good mixing for all latent variables $x_{1:T}$, which can be infeasible due to e.g.~limited available memory. The \ipmc can alleviate this issue by a non-standard coupling of several conditional and unconditional (standard) \smc algorithms. The algorithm lets us, from time to time, completely switch out a \csmc particle system with a completely independent \smc one, resulting in improved mixing of the Markov chain.
