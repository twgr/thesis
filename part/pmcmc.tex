% !TEX root = ../main.tex

\section{Particle Markov Chain Monte Carlo Methods}
\label{sec:part:pmcmc}

Particle Markov chain Monte Carlo (\pmcmc) methods, introduced by \citet{andrieuDH2010}, make use of 
sequential Monte Carlo (\smc) algorithms \citep{gordon1993novel,doucet2001sequential} to construct 
efficient proposals for an \mcmc sampler. This allows it to both utilize the ability of SMC to
exploit the structure of the target problem and the hill climbing behavior of MCMC methods.
The critical difference from running independent SMC sweeps is that information can be transferred
from sweep to the next. 
%The core reason for wanting to do this is that
%one is typically memory restricted in the number of particles that can be run $N$.  Though as we explained
%before, we can run multiple sweeps and combine these using the marginal likelihood estimates, if $N$ is
%not large enough, this typically results it widely varying estimates.  Although these estimates are unbiased,
%they are typically extremely skew, often following a roughly Gaussian distribution in their \emph{log} marginal
%likelihood CITE SOMETHING.  As such, it usually happens if $N$ is not large enough that one sweep dominates the others because
%its marginal likelihood is many orders of magnitude larger than the others and our estimate is
%effectively just the particle sweep with the highest marginal likelihood.  We therefore desire a more principled
%means of transferring the information of one iteration to the next which we can do by constructing an appropriate MCMC
%sampler.  We can then combine the advantages of SMC in its exploitation of the structure of the target with
%the local updating advantages of MCMC methods.  
Naturally this will come with the drawbacks of MCMC samplers
discussed in Section~\ref{sec:inf:foundation:mcmc}, in particular the loss of unbiasedness or marginal likelihood estimates.
However, the advantages will generally outweigh these drawbacks.  PMCMC methods will also allow us to explicitly
treat global parameters of our system differently to the latent states in a manner that can substantially improve
the performance of the model.
Though PMCMC can be applied to models with arbitrary series of targets in the same manner as SMC, we will stick
to the NMSSM case in this section for notational simplicity.

\subsection{Particle Independent Metropolis Hastings}
\label{sec:part:pmcmc:pimh}

Particle independent Metropolis Hastings (PIMH) is the simplest PMCMC algorithm.  Although in isolation it is
not especially useful (as it strictly worse than running independent SMC sweeps and combining 
them),\footnote{There is, though, utility in doing this when also including MCMC steps on global parameters, see~\cite{andrieu2010particle}.}
 it is an
important theoretical stepping stone to more advanced approaches.  The idea from a practical perspective 
is very simple: use an SMC sweep as an independent proposal for an MCMC algorithm targeting $\pi(x_{1:T}) = p(x_{1:T}|y_{1:T})$.
From a theoretical perspective, the approach is rather more profound as it can be viewed as a sampler on 
an \emph{extended space} whose marginal on the returned particles is the target.  
%We will then be able to use
%this to construct more powerful samplers.

\begin{algorithm}[tb]
	\caption{Particle Independent Metropolis Hastings}
	\label{alg:part:pimh}
	\begin{spacing}{1.2}
		\begin{algorithmic}[1]
			\renewcommand{\algorithmicrequire}{\textbf{Inputs:}}
			\renewcommand{\algorithmicensure}{\textbf{Outputs:}}				 
			\Require SMC sampler, number of MCMC iterations R
			\Ensure MCMC samples $\{\hat{x}_{1:T}^r\}_{r=1}^R$
			\State Run SMC giving particle set $X_{1:T}^0 = \{x_{1:T}^{i,0},w_T^{i,0}\}_{i=1}^N$ and marginal likelihood $\hat{Z}^0$
			\State Sample a single particle from set $\hat{x}_{1:T}^0 \sim X_{1:T}^0$ with probability proportional to weight
			\For{$r=2:R$}
			\State Run SMC giving candidate $\tilde{X}_{1:T}^r = \{x_{1:T}^{i,r},w_T^{i,r}\}_{i=1}^N$
				 and $\tilde{Z}^r$
			\If{$u\le \min \left(1,\frac{\tilde{Z}^r}{\hat{Z}^{r-1}}\right)$ where $u\sim \textsc{Uniform}(0,1)$}
			\State $\hat{x}_{1:T}^r \sim \tilde{X}_{1:T}^r, \quad \hat{Z}^{r} \leftarrow \tilde{Z}^r$
			\Else
			\State $\hat{x}_{1:T}^r \leftarrow \hat{x}_{1:T}^{r-1}, \quad \hat{Z}^{r} \leftarrow \hat{Z}^{r-1}$
			\EndIf
			\EndFor
		\end{algorithmic}
	\end{spacing}
\end{algorithm}

The PIMH algorithm is given in Algorithm~\ref{alg:part:pimh}.  We see that PIMH is an MCMC
algorithm where our proposal involves running an independent SMC
sweep and then sampling one of the particles from this particle set in proportion to
the weight of the particle.  This sample is then accepted or rejected using a MH accept-reject
step that  uses the marginal likelihoods of the sweep.  Because our proposal
is independent of our current point, this is strictly worse than just running independent SMC sweeps
(which can also be thought of as applying waste recycling to PIMH ~\citep{frenkel2006waste}).  
It might seem wasteful to only use
one particle from each sweep, but we will be able to Rao-Blackwellize this step and actually
return all the particles at each step as we explain in Section INSERT. 

%Imagine that we were able to exactly calculate the posterior probability of the of samples
%generated by an SMC sweep up to a normalization constant $\gamma(X_{1:T} |y_{1:T})$.  It would
%now be straightforward to construct a valid sampler on this distribution by constructing an independent
%MH proposal and accept/reject the particle sets in the standard way.
The key component of proving the correctness of the PIMH algorithm is in showing that it is a valid
MH sampler on an extended target whose marginal is the distribution of interest.
%The two key components of proving
%the correctness of the PIMH algorithm are in showing that running and SMC sweep then sampling
%one of the samples produced an extended target distribution whose normalized marginal distribution is
%the posterior of interest $\pi(x_{1:T}|y_{1:T})$ and that our MH algorithm remains valid when
%provided with an \emph{unbiased estimate} of the target distribution rather than an exact calculation.
Let $\xib \eqdef \{x_{t}^i\}_{\substack{i=1:N\\t=1:T}} \bigcup \{a_{t}^i\}_{\substack{i=1:N\\t=1:T-1}}$
denote all generated particles and ancestor variables of a \smc sampler.  The density of the distribution induced
by running a SMC sweep is now given by
\begin{align}
\label{eq:part:smc:proposal}
q_{\text{SMC}}(\xib) &= \prod_{i=1}^N q_1(x_{1}^i) \cdot \prod_{t=2}^T \prod_{i=1}^N \left[ 
\nw_{t-1}^{a_{t-1}^i}
%\frac{w_{t-1}^{a_{t-1}^i}}{\sum_\ell w_{t-1}^{\ell}}
q_t(x_{t}^i|x_{1:t-1}^{a_{t-1}^i}) \right]
\end{align}
and the distribution induced by running an SMC sweep and then sampling particle $b$ from the
sample set is 
\begin{align}
q_{\text{PIMH}}(\xib,b) = \bar{w}_T^b q_{\text{SMC}}(\xib) \quad \text{where} \quad \bar{w}_t^i = \frac{{w}_t^i}{\sum_{\ell=1}^{N}w_t^{\ell}}.
\end{align}
Let $\xb^i = x_{1:T,m}^i$ denote one of the final particles and let the trajectory associated
with the particle we sample be $\{\xb^{b},\bb\}$, with $\bb = (\beta_{1,},\ldots,\beta_{T})$,
$\beta_{T} = b$ and $\beta_{t} = a_{t}^{\beta_{t+1}}$. The proof for the validity of the PIMH
algorithm is now demonstrated by showing that it a valid MH sampler for an \emph{extended target distribution}
whose marginal distribution on $\xb^b$ is the distribution of interest $\pi(\xb^b)$.  To construct our
extended target distribution, we consider the following hypothetical sampling process
\begin{enumerate}
	\item Sample a particle exactly from the target $\xb^b \sim \pi(\xb^b)$,
	\item Sample a path for the particle uniformly at random path by independently sampling each $\beta_t \sim \textsc{UniformDiscrete}(1,N)$,
	\item Sample all of the other particles and trajectories conditioned on $\{\xb^{b},\bb\}$ using \begin{align}
	\label{eq:part:csmc}
	q_{\text{CSMC}}\left(\xib \backslash \{\xb', \bb\} \mid \xb', \bb \right) = 
	\prod_{\substack{i=1\\i\neq b_{1}}}^N  q_1(x_{1}^i) \cdot \prod_{t=2}^T \prod_{\substack{i=1\\i\neq b_{t}}}^N \left[
	\nw_{t-1}^{a_{t-1}^i}q_t(x_{t}^i|x_{1:t-1}^{a_{t-1}^i})\right].
	\end{align}
\end{enumerate}
Together these steps induce the distribution
\begin{align}
\label{eq:part:pimh-target}
\tilde{\pi}(\xi,b) = \frac{\pi(\xb^{b})}{N^T} \prod_{i=1, i\neq\beta_1}^N q_1(x_{1}^i) \cdot \prod_{t=2}^T \prod_{i=1, i\neq\beta_t}^N \left[ 
\nw_{t-1}^{a_{t-1}^i}
q_t(x_{t}^i|x_{1:t-1}^{a_{t-1}^i}) \right].
\end{align}
By construction, the marginal of this distribution is $\pi(\xb^{b})$.
Therefore, although it is not possible to actually
sample from $\tilde{\pi}(\xi,b)$ directly (we started the definition by sampling exactly
from the distribution of interest), if we can
construct a consistent MCMC estimator on~\ref{eq:part:pimh-target} then this by proxy
produces a consistent estimator for $\pi(\xb^{b})$.
We can now show that this is exactly what the
PIMH algorithm does by explicitly calculating the importance weight implied by
targeting $\tilde{\pi}(\xi,b)$ using the proposal $q_{\text{PIMH}}(\xib,b)$
\begin{align}
\frac{\tilde{\pi}(\xi,b)}{q_{\text{PIMH}}(\xib,b)} &= \frac{\pi(\xb^{b}) q_{\text{CSMC}}\left(\xib \backslash \{\xb', \bb\} \mid \xb', \bb \right)}
{N^T \bar{w}_T^b q_{\text{SMC}}(\xib)} \\
&= \frac{\pi(\xb^{b})}{N^T \bar{w}_T^b q_1(x_1^{\beta_1}) \prod_{t=2}^{T} \bar{w}_{t-1}^{\beta_{t-1}} q_t(x_t^{\beta_t} | x_{t-1}^{\beta_{t-1}})} \nonumber \\
&= \left(\frac{\gamma(\xb^{b})/Z}{
	q_1(x_1^{\beta_1}) \prod_{t=2}^{T} q_t(x_t^{\beta_t} | x_{t-1}^{\beta_{t-1}})}\right) \cdot
	\left( \frac{1}{N^T \bar{w}_T^b\prod_{t=2}^{T} \bar{w}_{t-1}^{\beta_{t-1}}} \right) \nonumber \\
&= \left(\frac{w_T^b}{Z}
	 \prod_{t=2}^{T} w_{t-1}^{\beta_{t-1}}\right)\cdot\left(
	\frac{1}{N^T \bar{w}_T^b \prod_{t=2}^{T} \bar{w}_{t-1}^{\beta_{t-1}}}\right) \nonumber \\
&= \left(\frac{w_T^b}{Z}
	\prod_{t=2}^{T} w_{t-1}^{\beta_{t-1}}\right)\cdot\left(
	\frac{\prod_{t=1}^T \frac{1}{N} \sum_{\ell=1}^N w_{t}^{\ell}}{w_T^b \prod_{t=2}^{T} w_{t-1}^{\beta_{t-1}}}\right) \nonumber \\
&= \frac{1}{Z} \prod_{t=1}^T \frac{1}{N} \sum_{\ell=1}^N w_{t}^{\ell}
= \frac{\hat{Z}}{Z}.
\end{align}
We thus have that $\hat{Z}$ is the importance weight for sampling the unnormalized
version of the target $\tilde{\gamma}(\xi,b) = Z \tilde{\pi}(\xi,b)$ and so using the
ratio of marginal likelihood estimates provides is exactly the acceptance ratio required for
the MH sampler.  We
have therefore proven that the PIMH algorithm induces a consistent Markov chain for
the target $\pi(x_{1:T})$.

Note that as an aside, this also shows the unbiasedness of the SMC marginal likelihood estimate
as we see that
\begin{align}
\E_{q_{\text{SMC}}(\xib)} \left[\hat{Z}\right] = \E_{q_{\text{PIMH}}(\xib,b)} 
\left[\hat{Z}\right]=\E_{\tilde{\pi}(\xi,b)} \left[Z\right]=Z.
\end{align}
However, SMC will not, in general, provide unbiased estimates for expectations of
functions, for the same reasons that self-normalized importance sampling gives biased
estimates of expectations (see Section~\ref{sec:inf:foundation:importance:self-norm}).

\subsection{Particle Gibbs}
\label{sec:part:pmcmc:pgibbs}

One particularly widely used \pmcmc algorithm is particle Gibbs (\pg). The \pg algorithm modifies the 
\smc step in the \pmcmc algorithm to sample the latent variables conditioned on an existing particle
 trajectory, resulting in what is called a conditional sequential Monte Carlo (\csmc) step. The \pg method
  was first introduced as an efficient Gibbs sampler for latent variable models with static parameters 
  \citep{andrieuDH2010}. Since then, the \pg algorithm and the extension by \citet{lindstenJS2014} have 
  found numerous applications in \eg Bayesian non-parametrics \citep{ValeraFSPC2015,tripuraneni2015}, 
  probabilistic programming \citep{wood2014new,vandemeent_aistats_2015} and graphical models 
  \citep{everitt2012,naessethLS2014,naessethLS2015nested}.  

The \pg algorithm targets the same extended target $\tilde{\pi}(\xib,b)$ as the PIMH algorithm defined
in~\ref{eq:part:pimh-target}, but rather than constructing a MH sampler with independent proposals for
this target, it constructs a Gibbs sampler.  This is done by iteratively 
running \emph{conditional} sequential Monte Carlo (\csmc) sweeps. As described in Algorithm~\ref{alg:csmc},
a \csmc sweep is similar to a standard, unconditional \smc sweep, except that it starts
with an existing \emph{conditional trajectory} $x_{1:T}'$, known as a \emph{retained particle} in the \pg
context, and runs the sweep conditioned on this conditional trajectory being present in the final sample
set.  One can think of this as running a SMC sweep conditioned on the predefined particle surviving each
of the resampling steps.  In other words, the other particles can sample the retained particle as an
ancestor but not vice versa, with the values and ancestral path of the retained particle prefixed. 
 In Algorithm~\ref{alg:csmc} we have
presumed  that this ancestral path is $\bb = (N,\dots,N)$ which is not always the case from a theoretical
perspective.  However, because the path is fixed up front, all possible paths are equivalent from the point
of view of running the sweep.  Therefore,
given we only actually care about the $\xb$ sampled by the algorithm and not the ancestral paths themselves,
we can just use a convenient fixed ancestral path for the retained particle in practice, as done in Algorithm~\ref{alg:csmc}.

\begin{algorithm}[tb]
	\caption{Conditional sequential Monte Carlo}
	\label{alg:csmc}
	\begin{spacing}{1.2}
		\begin{algorithmic}[1]
			\renewcommand{\algorithmicrequire}{\textbf{Inputs:}}
			\renewcommand{\algorithmicensure}{\textbf{Outputs:}}				 
			\Require data $y_{1:T}$, number of particles $N$, proposals $q_t$, conditional trajectory $x_{1:T}'$
			\State $x_1^i \sim q_1(x_1), ~i=1,\ldots,N-1$ and set $x_1^N = x_1'$
			\State $w_1^i = \frac{g_1(y_1|x_1^i) \mu(x_1^i)}{q_1(x_1^i)}, ~i=1,\ldots,N$
			\For{$t = 2$ {\bfseries to} $T$}
			\State $a_{t-1}^i \sim \Discrete\left(\left\{\nw_{t-1}^\ell\right\}_{\ell=1}^N\right), ~i=1,\ldots,N-1$
			\State $x_t^i \sim q_t(x_t | x_{1:t-1}^{a_{t-1}^i}), ~i=1,\ldots,N-1$
			\State Set $a_{t-1}^N = N$ and $x_t^N = x_t'$
			\State Set $x_{1:t}^i = (x_{1:t-1}^{a_{t-1}^i},x_t^i), ~i=1,\ldots,N$
			\State $w_t^i = \frac{g_t(y_t|x_{1:t}^i) f_t(x_t^i | x_{1:t-1}^{a_{t-1}^i})}{q_t(x_t^i|x_{1:t-1}^{a_{t-1}^i})}, ~i=1,\ldots,N$
			\EndFor
		\end{algorithmic}
	\end{spacing}
\end{algorithm}

Unlike \smc sweeps, \csmc sweeps can be linked together by conditioning each sweep using a \emph{retained particle}
sampled from the previous sweep with probability proportional to the final particle weights $\bar{w}^i_T$.
Therefore, once initialized, say using a standard \smc sweep, one can iterate between sampling a retained
particle in the same manner ancestor indices are sampled and running \csmc sweeps conditioned on this
retained particle.  Considerations about global parameters aside (see Section INSERT), this is know
as iterated \csmc and constitutes the \pg algorithm.  A characterization is provided in INSERT. 

\todo[inline]{Add PG characterization figure.}

The theoretical justification for the \pg algorithm can be shown in a similar manner as the PIMH algorithm.
The sampled index $b$ now corresponds the index of the retained particle and we can think of the
approach as alternating between Gibbs updates on $b$ and $\xib \backslash \{\xb,\bb\}$.    In other
words, we alternate between sampling $b \sim \tilde{\pi}(\cdot | \xib)$ and 
$\xib \backslash \{\xb,\bb\} \sim \tilde{\pi}(\cdot | \xb,\bb)$.  \todo[inline]{Continue here}


Though \pg allows for inference over both latent variables and static parameters, 
we will in this paper focus on sampling of the former.  

A drawback of PG is that it can be particularly adversely affected by \emph{path degeneracy} in the CSMC step.  Conditioning on an existing trajectory means that whenever resampling of the trajectories results in a common ancestor, this ancestor must correspond to this trajectory.  Consequently, the mixing of the Markov chain for the early steps in the state sequence can become very slow when the particle set typically coalesces to a single ancestor during the CSMC sweep.
We address this next with the iPMCMC algorithm.

\todo[inline]{Rao-Black}

%In the same way as above for the standard \smc algorithm we can define a joint probability distribution induced by running Algorithm~\ref{alg:csmc} %$q_{\text{CSMC}}(\xb^{1:N},\ab^{1:N}\backslash\{\xb^N,\bb^N\} | \xb^N,\bb^N)$, induced by running Algorithm~\ref{alg:csmc}, where $\xb^N, \bb^N$ is the retained (conditioning) particle. 
%\begin{align}
%&q_{\text{CSMC}}\left(\xb^{1:N},\ab^{1:N} \backslash \{\xb^N, \bb^N\} \mid \xb^N, \bb^N, k \right) = \nonumber \\
%&\prod_{\substack{i=1\\i\neq b_{1}}}^N \left[ q_1(x_{1}^i) \right] \prod_{t=2}^T \prod_{\substack{i=1\\i\neq b_{t}}}^N \left[\frac{W_{t-1}^{a_{t-1}^i}}{\sum_\ell W_{t-1}^\ell} q_t(x_{t}^i|x_{1:t-1}^{a_{t-1}^i})\right],
%\end{align}
%where $\xb^N, \bb^N$ is the retained (conditioning) particle.
%\brooks{doesn't make sense --- if the retained particle is $N$, why is it $\xb_m^k, \bb_m^k$ in the above equation? shouldn't $\xb_m^{1:N},\ab_m^{1:N} \backslash \{\xb_m^k, \bb_m^k\}$ actually be $\xb_m^{1:N-1},\ab_m^{1:N-1}$?}


%
%   Limitations
%
%\subsection{Parallelisation and Limitations}
%\label{sec:limitations}
%Our main goal is to increase the efficiency of particle \mcmc, particle Gibbs especially, by coupling independent \smc methods with \csmc algorithms, perhaps running on different workers or threads. The method we propose, interacting particle Markov chain Monte Carlo (\ipmc), makes efficient use of multi-core and distributed computing architectures to increase accuracy of the Monte Carlo sampler.

%The basic \pg typically suffers from the \emph{path degeneracy} effect of \smc samplers, \ie sample impoverishment due to frequent resampling, which leads to bad mixing of the Markov chain. Since we force one trajectory, the conditional part, to survive to the end it means that for early time steps we will almost always pick the corresponding sample from last iteration. To counteract this we might need a very high number of particles to get good mixing for all latent variables $x_{1:T}$, which can be infeasible due to e.g.~limited available memory. The \ipmc can alleviate this issue by a non-standard coupling of several conditional and unconditional (standard) \smc algorithms. The algorithm lets us, from time to time, completely switch out a \csmc particle system with a completely independent \smc one, resulting in improved mixing of the Markov chain.
