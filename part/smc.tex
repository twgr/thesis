% !TEX root = ../main.tex

\section{Sequential Monte Carlo}
\label{sec:part:smc:smc}

\subsection{Non-Markovian State-Space Models}

Although SMC can be used for for an arbitrary series of targets as we will explain
later, we will mostly introduce them in the context of non-Markovian state-space
models (SSMs).  SSMs are probabilistic models over a set of latent variables 
$X_t \in \mathcal{X}_t, \forall t = 1:T$
and observed variables $Y_t \in \mathcal{Y}_t, \forall t = 1:T$.  
We can further consider a model to be parameterized by $\theta \in \Theta$ which
we will for now presume is known.
They are similar to
the HMM introduced in~\ref{sec:bayes:paradigm:graph}, but different by not
making the Markov assumption.  This leads to the graphical model shown in INSERT.
They are fully defined by an initial density $\mu_{\theta} (x_1)$,
a series of transition densities $f_{t,\theta} (x_t | x_{1:t-1})$, and a series of
emission densities $g_{t,\theta} (y_t | x_{1:t})$
\begin{align*}
X_1 &\sim \mu_{\theta}(\cdot), \\
X_t \| (X_{1:t - 1} = x_{1:t - 1}) &\sim f_{t,\theta}(\cdot \| x_{1:t - 1}), \\
Y_t \| (X_{1:t} = x_{1:t}) &\sim g_{t,\theta}(\cdot \| x_{1:t}).
\end{align*}
which gives a joint density of
\begin{align*}
p_{\theta}(x_{1:T}, y_{1:T}) = \mu_{\theta}(x_1) \prod_{t = 2}^T f_{t,\theta}(x_t \| x_{1:t - 1}) \prod_{t = 1}^T g_{t,\theta}(y_t \| x_{1:t}).
\end{align*}
We are free to choose any density for
$\mu_{\theta} (x_1)$ and each $f_{t,\theta} (x_t | x_{1:t-1})$ and $g_{t,\theta} (y_t | x_{1:t})$. One is usually interested characterizing the posterior
\begin{align*}
p_{\theta}(x_{1:T} \| y_{1:T}) \propto p_{\theta}(x_{1:T}, y_{1:T})
\end{align*}
or expectations of some function $\varphi$ under this posterior
\begin{align*}
I(\varphi) = \int \varphi(x_{1:T}) p_{\theta}(x_{1:T} \| y_{1:T}) \,\mathrm dx_{1:T}
\end{align*}
which can be used further in some decision-theoretic framework.
We refer to these two tasks as inference.
Inference in models which are non-linear, non-discrete, and non-Gaussian is difficult
and one must resort to approximate methods, for which SMC has been shown to
be one of the most successful approaches \citep{doucet2009tutorial}.

We start by briefly reviewing sequential Monte Carlo \citep{gordon1993novel,doucet2001sequential} and the particle Gibbs algorithm \citep{andrieuDH2010}. Let us consider a non-Markovian latent variable model of the following form
\begin{subequations}
	\label{eq:ssm}
	\begin{alignat}{2}
	x_t | x_{1:t-1} &\sim f_t(x_t | x_{1:t-1}), \\
	y_t | x_{1:t} &\sim g_t(y_t|x_{1:t}),
	\end{alignat}
\end{subequations}
where $x_t \in \setX$ is the latent variable and $y_t \in \setY$ the observation at time step $t$, respectively,
with transition densities $f_t$ and observation densities $g_t$; $x_1$ is drawn from some initial distribution $\mu(\cdot)$. The method we propose is not restricted to the above model, it can in fact be applied to an arbitrary sequence of targets.

%We focus on the non-Markovian latent variable model because it has been shown to be useful within \eg probabilistic programming \citep{wood2014new}.%However, we restrict the exposition to the latent variable model for clarity and to see the potential usefulness of it to \eg probabilistic programming \citep{wood2014new}. \tom{I am not sure I agree with this statement - PP should actually allow the most general possible use of iPMCMC.  I think we would be better making the point that its ability to operate on arbitrary models make it a suitable candidate for PP inference engines.  By the final draft I would expect us to have it running and publically availible in Anglican}

We are interested in calculating expectations with respect to the posterior distribution $p(x_{1:T}|y_{1:T})$ on latent variables $x_{1:T} \eqdef (x_1,\ldots,x_T)$ conditioned on observations $y_{1:T} \eqdef (y_1,\ldots,y_T)$, which is proportional to the joint distribution $p(x_{1:T}, y_{1:T})$,
\begin{align}
\label{eq:jointdistribution}
p(x_{1:T} | y_{1:T}) \propto  \mu(x_1) \prod_{t=2}^T f_t(x_t | x_{1:t-1}) \prod_{t=1}^T g_t(y_t|x_{1:t}).\nonumber
\end{align}
In general, computing the posterior $p(x_{1:T}|y_{1:T})$ is intractable and we have to resort to approximations. We will in this paper focus on, and extend, the family of particle Markov chain Monte Carlo algorithms originally proposed by \citet{andrieuDH2010}. The key idea in \pmcmc is to use \smc to construct efficient proposals of the latent variables $x_{1:T}$ for an \mcmc sampler.

%
%   SMC
%

\begin{algorithm}[tb]
	\caption{Sequential Monte Carlo \hfill {\small (all for $i=1,\ldots,N$)}}
	\label{alg:smc}
	\begin{spacing}{1.2}
		\begin{algorithmic}[1]
			\renewcommand{\algorithmicrequire}{\textbf{Inputs:}}
			\renewcommand{\algorithmicensure}{\textbf{Outputs:}}				 
			\Require  data $y_{1:T}$, number of particles $N$, proposals $q_t$
			\State $x_1^i \sim q_1(x_1)$
			\State $w_1^i = \frac{g_1(y_1|x_1^i) \mu(x_1^i)}{q_1(x_1^i)}$
			\For{$t = 2$ {\bfseries to} $T$}
			\State $a_{t-1}^i \sim \Discrete\left(\left\{\nw_{t-1}^{\ell}\right\}_{\ell=1}^N\right)$% \tom{We can maybe more general that categorical here?}
			\State $x_t^i \sim q_t(x_t | x_{1:t-1}^{a_{t-1}^i})$ 
			\State Set $x_{1:t}^i = (x_{1:t-1}^{a_{t-1}^i},x_t^i)$
			\State $w_t^i = \frac{g_t(y_t|x_{1:t}^i) f_t(x_t^i | x_{1:t-1}^{a_{t-1}^i})}{q_t(x_t^i|x_{1:t-1}^{a_{t-1}^i})}$
			\EndFor
		\end{algorithmic}
	\end{spacing}
\end{algorithm}

The \smc method is a widely used technique for approximating a sequence of target distributions: in our case $p(x_{1:t}|y_{1:t}) = p(y_{1:t})^{-1} p(x_{1:t},y_{1:t}), ~t=1,\ldots,T$. 
At each time step $t$ we 
%assume we have access to 
generate a \emph{particle system}
$\{(x_{1:t}^i,w_{t}^i)\}_{i=1}^N$ which provides a weighted approximation  to $p(x_{1:t}|y_{1:t})$. Given such a weighted particle system at time $t-1$, this 
%The particle system is then
is propagated forward in time to $t$ by first drawing an ancestor variable $a_{t-1}^i$ for each particle from its corresponding distribution:
\begin{align}
\Prb(a_{t-1}^i = \ell) &= \nw_{t-1}^\ell.
&
\ell&=1,\ldots,N,
\end{align}
where $\nw_{t-1}^\ell = w_{t-1}^\ell / \sum_i w_{t-1}^i$. This is commonly known as the resampling step in the literature. We introduce the ancestor variables $\{a_{t-1}^i\}_{i=1}^N$ explicitly to simplify the exposition of the theoretical justification | in Section \ref{sec:theory}.

We continue by simulating from some | proposal density $x_t^i \sim q_t(x_t | x_{1:t-1}^{a_{t-1}^i})$ and re-weight the system of particles as follows:
\begin{align}
\label{eq:smcweights}
w_t^i = \frac{g_t(y_t|x_{1:t}^i) f_t(x_t^i | x_{1:t-1}^{a_{t-1}^i})}{q_t(x_t^i|x_{1:t-1}^{a_{t-1}^i})},
\end{align}
where $x_{1:t}^i = (x_{1:t-1}^{a_{t-1}^i},x_t^i)$. This results in a new particle system $\{(x_{1:t}^i,w_t^i)\}_{i=1}^N$ that approximates $p(x_{1:t}|y_{1:t})$. A summary is | in Algorithm~\ref{alg:smc}.

%Let $q_{\text{SMC}}(\xb^{1:N},\ab^{1:N})$ denote the joint probability distribution over $\xb^{1:N}=x_{1:T}^{1:N}, \ab^{1:N} = a_{1:t-1}^{1:N}$ induced by running Algorithm~\ref{alg:smc}. We can write the complete distribution, which will be useful for the correctness proof, as follows
%\begin{align}
%q_{\text{SMC}}(\xb^{1:N},\ab^{1:N}) = \prod_{i=1}^N q_1(x_1^i) \prod_{t=2}^T \frac{W_{t-1}^{a_{t-1}^i}}{\sum_\ell W_{t-1}^\ell} q_t(x_t^i|x_{1:t-1}^{a_{t-1}^i}).
%\end{align}