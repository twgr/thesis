% !TEX root = ../../main.tex

% Here we describe the proposed method and its theoretical properties
\subsection{Interacting Particle Markov Chain Monte Carlo}
\label{sec:method}
%Our main goal with the interacting particle Markov chain Monte Carlo method is to increase the efficiency of particle \mcmc, particle Gibbs especially, by coupling independent \smc methods with \csmc algorithms, perhaps running on different nodes or threads. The method we propose, interacting particle Markov chain Monte Carlo (\ipmc), makes efficient use of multi-core and distributed computing architectures to increase accuracy of the Monte Carlo sampler.

The main goal of \ipmcmc is to increase the efficiency of \pmcmc, in particular particle Gibbs. The basic \pg algorithm is especially susceptible to the \emph{path degeneracy} effect of \smc samplers, \ie sample impoverishment due to frequent resampling.  Whenever the ancestral lineage collapses at the early stages of the state sequence, the common ancestor is, by construction, guaranteed to be equal to the retained particle.  This results in high correlation between the samples, and poor mixing of the Markov chain. %Since we force one trajectory, the conditional part, to survive to the end it means that for early time steps we will almost always pick the corresponding sample from last iteration. 
To counteract this we might need a very high number of particles to get good mixing for all latent variables $x_{1:T}$, which can be infeasible due to e.g.~limited available memory. \ipmc can alleviate this issue by, from time to time, switching out a \csmc particle system with a completely independent \smc one, resulting in improved mixing.

\ipmcmc, summarized in Algorithm~\ref{alg:ipmc}, consists of $M$ interacting separate \csmc and \smc algorithms, exchanging only very limited information at each iteration to draw new \mcmc samples. We will refer to these internal \csmc and \smc algorithms as nodes, and assign an index $m=1,\ldots,M$. 
At every iteration, we have $P$ nodes running local \csmc algorithms, with the remaining
$M-P$ nodes running independent \smc.
The \csmc nodes are given an identifier $c_j \in \{1,\ldots,M\}, ~j=1,\ldots,P$ with $c_j \neq c_k,~k \neq j$ and we write $c_{1:P} = \{c_1,\ldots,c_P\}$. Let $\xb_m^i = x_{1:T,m}^i$ be the internal particle trajectories of node $m$.

\begin{algorithm}[tb]
	\caption{\ipmcmc sampler}
	\label{alg:ipmc}
	\begin{spacing}{1.2}
	\begin{algorithmic}[1]
		\renewcommand{\algorithmicrequire}{\textbf{Inputs:}}
		\renewcommand{\algorithmicensure}{\textbf{Outputs:}}				 
		\Require number of nodes $M$, conditional nodes $P$ and \mcmc steps $R$, initial $\xb_{1:P}'[0]$
		\For{$r = 1$ {\bfseries to} $R$}
		\State Workers $1:M \backslash c_{1:P}$ run Algorithm~\ref{alg:smc} (\smc)
		\State Workers $c_{1:P}$ run Algorithm~\ref{alg:csmc} (\csmc), conditional on $\xb_{1:P}'[r-1]$ respectively.
		\For{$j = 1$ {\bfseries to} $P$}
		\State Select a new conditional node by simulating $c_j$ according to \eqref{eq:simConditional}. %with probability 
		\State Set new \mcmc sample $\xb_j'[r] = \xb_{c_j}^{b_j}$ by simulating $b_j$ according to~\eqref{eq:simTrajectory}
		\EndFor
		\EndFor
	\end{algorithmic}
\end{spacing}
\end{algorithm}

Suppose we have access to $P$ trajectories ${\xb_{1:P}'[0]=(\xb_1'[0],\ldots,\xb_P'[0])}$ corresponding to the initial retained particles, where the index $[\cdot]$ denotes \mcmc iteration. At each iteration $r$, the nodes $c_{1:P}$ run \csmc (Algorithm~\ref{alg:csmc}) with the previous \mcmc sample $\xb_j'[r-1]$ as the retained particle. The remaining $M-P$ nodes run standard (unconditional) \smc, \ie Algorithm~\ref{alg:smc}.  Each node $m$ returns an estimate of the marginal likelihood for the internal particle system defined as
\begin{align}
\label{eq:ML}
\hat Z_{m} = \prod_{t=1}^T \frac{1}{N} \sum_{i=1}^N w_{t,m}^{i}.
\end{align}
%along with a single trajectory $\xb_{m}^{s_m}$ sampled according to 
%\begin{align}
%\label{eq:simTrajectory}
%\Prb(s_m = i) &= \nw_{T,m}^i
%\end{align}
%where $s_m$ is the local index of the sampled particle.  

The new conditional nodes are then set using a single loop $j=1:P$ of Gibbs updates, sampling new indices $c_j$ where
\begin{align}
\label{eq:simConditional}
&\Prb(c_j = m|c_{1:P\backslash j}) = \hat\nz_{m}^j \\
\label{eq:zeta_def}
\mathrm{and}  \quad &{\hat\nz_{m}^j = \frac{\hat Z_{m} \iden_{m \notin c_{1:P \backslash j}}}{ \sum_{n=1}^M \hat Z_{n} \iden_{n \notin c_{1:P \backslash j}}}},
%\Prb(c_j = m|c_{1:P\backslash j}) = \frac{\hat Z_{\pi_T,m} \iden_{m \notin c_{1:P \backslash j}}}{\sum_{n=1}^M \hat Z_{\pi_T,n} \iden_{n \notin c_{1:P \backslash j}}},
\end{align}
defining ${c_{1:P\backslash j} = \{c_1,\ldots,c_{j-1},c_{j+1},\ldots,c_P\}}$.  We thus loop once through the conditional node indices and resample them from the union of the current node index and the unconditional node indices\footnote{Unconditional node indices here refers to all $m \notin c_{1:P}$ at that point in the loop. It may thus include nodes who just ran a CSMC sweep, but have been ``switched out'' earlier in the loop.}, in proportion to their marginal likelihood estimates.  This is the key step that lets us switch completely the nodes from which the retained particles are drawn.


%The retained particles are the corresponding trajectories sampled in \eqref{eq:simTrajectory} such that 
%\begin{align}
%\label{eq:setTrajectory}
%\xb_j'[r] &= \xb_{c_j}^{b_j}, \quad \mathrm{where} \quad b_j = s_{c_j}, \quad j=1,\dots,P.
%\end{align}

%This step, by far the most computationally demanding, can be trivially parallelised over the $M$ nodes. However, it need not be parallelised to see convergence benefits and reduced memory footprints compared to competing \pmcmc methods.
%\begin{figure}[h]
%\centering
%\resizebox{.45\textwidth}{!}{
%\input{./figures/algorithm.tex}
%}
%\caption{A high-level illustration of the \ipmcmc algorithm flow for $M=5$ and $P=2$. \csmc nodes are \emph{red} and \smc nodes are \emph{blue}, which means that for example at iteration $r-1$ we have $c_{1:P} = \{3,5\}$.}\label{fig:algorithm}
%\end{figure}
%\tom{You can't tell the difference between these nodes when printed in black and white so would be good to adjust the colours slightly.  I think the index needs to be m not j?  Also might be nice to have something in caption like here we have have $c_{1:P}[r-1] = {1,2}$ here just allow the figure to be a reference to the notation.} 

%The next step involves exchange of information--we need access to the normalisation constant estimates from each node to sample the next \mcmc output $\xb_j'[r]$. The normalisation constant estimate for each node $m$ is computed using the internal particle system as ${\hat Z_{m} = \prod_{t=1}^T \frac{1}{N} \sum_{i=1}^N w_{t,m}^{i}}$.
%%\begin{align}
%%\hat Z_{\pi_T,m} = \prod_{t=1}^T \frac{1}{N} \sum_{i=1}^N w_{t,m}^{i}.
%%\end{align}
%%Note that this estimate is unbiased for the standard \smc methods but positively biased for the \csmc{s}. 
%These estimates are then used to set new conditional nodes by simulating new node indices $c_j$ from
%\begin{align}
%\label{eq:simConditional}
%\Prb(c_j = m|c_{1:P\backslash j}) = \hat\nz_{m}^j, \quad j=1,\ldots,P
%%\Prb(c_j = m|c_{1:P\backslash j}) = \frac{\hat Z_{\pi_T,m} \iden_{m \notin c_{1:P \backslash j}}}{\sum_{n=1}^M \hat Z_{\pi_T,n} \iden_{n \notin c_{1:P \backslash j}}},
%\end{align}
%with ${\hat\nz_{m}^j = \hat Z_{m} \iden_{m \notin c_{1:P \backslash j}} / \sum_{n=1}^M \hat Z_{n} \iden_{n \notin c_{1:P \backslash j}}}$ and ${c_{1:P\backslash j} = \{c_1,\ldots,c_{j-1},c_{j+1},\ldots,c_P\}}$. This is the key step that lets us switch completely the nodes from which we draw our next \mcmc samples (retained particles) $\xb_{1:P}'[r]$.%This ensures that all the conditional node indices $c_{1:P}$ will be distinct.
%
One \mcmc iteration $r$ is concluded by setting the new samples $\xb_{1:P}'[r]$ by simulating from the corresponding conditional node's, $c_j$, internal particle system
\begin{align}
\label{eq:simTrajectory}
\Prb(b_j = i | c_j) &= \nw_{T,c_j}^i, \nonumber\\%\frac{w_{T,c_j}^{i}}{\sum_\ell w_{T,c_j}^{\ell}}, \nonumber\\
\xb_j'[r] &= \xb_{c_j}^{b_j}.
\end{align}
The potential to pick from updated nodes $c_j$, having run independent \smc algorithms, decreases correlation and improves mixing of the  \mcmc sampler. Furthermore, as each Gibbs update corresponds to a one-to-many comparison for maintaining the same conditional index, the probability of switching is much higher than in an analogous non-interacting system.
%A summary of the \ipmcmc algorithm can be found in Algorithm~\ref{alg:ipmc}. % and a high-level overview of the algorithm flow can be found in Figure~\ref{fig:algorithm}.

The theoretical justification for iPMCMC is independent of how the initial trajectories $\xb_{1:P}'[0]$ are generated.  One simple and effective method (that we use in our experiments) is to run standard SMC sweeps for the ``conditional'' nodes at the first iteration.

The \ipmc samples $\xb_{1:P}'[r]$ can be used to estimate expectations for test functions $f: \setX^T \mapsto \reals$ in the standard Monte Carlo sense, with
\begin{align}
\label{eq:mcestimate}
\E[f(\xb)] \approx \frac{1}{RP}\sum_{r=1}^R\sum_{j=1}^P f(\xb_j'[r]).
\end{align}
However, we can improve upon this if we have access to all particles generated by the algorithm, see Section~\ref{sec:allparticles}.

We note that \ipmcmc is suited to distributed and multi-core architectures. In practise, the particle to be retained, should the node be a conditional node at the next iteration, can be sampled upfront and discarded if unused.  Therefore, at each iteration, only a single particle trajectory and normalisation constant estimate need be communicated between the nodes, whilst the time taken for calculation of the updates of $c_{1:P}$ is negligible.  Further, iPMCMC should be amenable to an asynchronous adaptation under the assumption of a random execution time, independent of $\xb_j'[r-1]$ in Algorithm~\ref{alg:ipmc}. We leave this asynchronous variant to future work.
%\brooks{maybe mention right away that we can improve this?}

%The method we propose is to couple a conditional \smc method with several independent standard \smc{s}. Assume that we have one \csmc and $M-1$ standard \smc processes running, each supplying an estimate of the normalisation constant $p_m^N(y_{1:T}), m=1,\ldots,M$ based on its $N$ particles. 

%The method proceeds by, at each \mcmc iteration, drawing the next process $m^*$ to become the \csmc according to the estimates $\{p_m^N(y_{1:T})\}$. Then, the conditional trajectory $x_{1:t}'$ is drawn from the corresponding process' internal particle representation either by simulating from the final weights or by doing backward simulation \citet{TODO}.

%\begin{algorithm}[tb]
%\caption{Parallel iterated \csmc}
%\label{alg:picsmc}
%\begin{enumerate}
%\item Initialize $x_{1:T}'[0]$ and set $m^* = 1$
%\item \textbf{for $r=1$ to $R$}
%\begin{enumerate}
%\item In process $m \neq m^*$ run $\operatorname{SMC}$
%\item In process $m = m^*$ run $\operatorname{CSMC}(x_{1:T}'[r-1])$
%\item Simulate $m^* \sim \cat \left( \frac{p_m^N(y_{1:T})}{\sum_{\ell=1}^M p_\ell^N(y_{1:T})} \right)$
%\item Extract $x_{1:T}'[r]$ from process $m^*$
%\end{enumerate}
%\end{enumerate}
%\end{algorithm}
%We do this by picking the next conditional trajectory $x_{1:T}'$ in the following way. First, draw a categorical random variable according to


% Theoretical foundation
\subsubsection{Theoretical Justification}
\label{sec:theory}
In this section we will give some crucial results to justify the proposed \ipmc sampler. This section is due to space constraints fairly brief and it is helpful to be familiar with the proof of \pg in \citet{andrieuDH2010}.
We start by defining some additional notation.
% Let $\nw_t^i \eqdef w_t^i/\sum_\ell w_t^\ell$ denote the normalised importance weights,
% and let 
Let $\xib \eqdef \{x_{t}^i\}_{\substack{i=1:N\\t=1:T}} \bigcup \{a_{t}^i\}_{\substack{i=1:N\\t=1:T-1}}$
denote all generated particles and ancestor variables of a (C)\smc sampler.
We write $\xib_m$ when referring to the variables of the sampler local to node $m$.
%
% We start by denoting the internal particle system, \ie all generated particles and ancestor variables, of node $m$ by $\xib_m \eqdef \{x_{t,m}^i\}_{\substack{i=1:N\\t=1:T}} \bigcup \{a_{t,m}^i\}_{\substack{i=1:N\\t=1:T-1}}$.
Let the conditional particle trajectory and corresponding ancestor variables for node $c_j$ be denoted by $\{\xb_{c_j}^{b_j},\bb_{c_j}\}$, with $\bb_{c_j} = (\beta_{1,c_j},\ldots,\beta_{T,c_j})$,
%\fredrik{I changed to lower case $b_j$ here to agree with (7), but the notation might be a bit confusing. Use a different symbol in (7) or here?}
$\beta_{T,c_j} = b_j$ and $\beta_{t,c_j} = a_{t,c_j}^{\beta_{t+1,c_j}}$. %\tom{Feel that mabye this could do with an extra line of explanation for people not already familiar with this notation from the PMCMC paper}. 
Let the posterior distribution of the latent variables be denoted by $\pi_T(\xb) \eqdef p(x_{1:T}|y_{1:T})$ with normalisation constant $Z \eqdef p(y_{1:T})$. 
%
Finally we % the induced distributions of the \smc and \csmc algorithms
note that the \smc and \csmc algorithms induce the respective distributions over the random variables
generated by the procedures:
\vspace{-2mm}
\begin{align*}
q_{\text{SMC}}(\xib) &= \prod_{i=1}^N q_1(x_{1}^i) \cdot \prod_{t=2}^T \prod_{i=1}^N \left[ 
\nw_{t-1}^{a_{t-1}^i}
%\frac{w_{t-1}^{a_{t-1}^i}}{\sum_\ell w_{t-1}^{\ell}}
q_t(x_{t}^i|x_{1:t-1}^{a_{t-1}^i}) \right], \\
q_{\text{CSMC}}\left(\xib \backslash \{\xb', \bb\} \mid \xb', \bb \right) &= \prod_{\substack{i=1\\i\neq b_{1}}}^N  q_1(x_{1}^i) \cdot \prod_{t=2}^T \prod_{\substack{i=1\\i\neq b_{t}}}^N \left[
\nw_{t-1}^{a_{t-1}^i}
%\frac{w_{t-1}^{a_{t-1}^i}}{\sum_\ell w_{t-1}^\ell}
q_t(x_{t}^i|x_{1:t-1}^{a_{t-1}^i})\right].
\end{align*}
Note that running Algorithm~\ref{alg:csmc} corresponds to simulating from $q_\text{CSMC}$ using a fixed
choice for the index variables $\bb = (N\,\ldots,N)$. While these indices are used to facilitate the
proof of validity of the proposed method, they have no practical relevance and can thus be set to arbitrary
values, as is done in Algorithm~\ref{alg:csmc}, in a practical implementation.

% \begin{align*}
% &q_{\text{SMC}}(\xib_m) = \nonumber \\
% &\prod_{i=1}^N q_1(x_{1,m}^i) \cdot \prod_{t=2}^T \prod_{i=1}^N \left[ \frac{w_{t-1,m}^{a_{t-1,m}^i}}{\sum_\ell w_{t-1,m}^\ell} q_t(x_{t,m}^i|x_{1:t-1,m}^{a_{t-1,m}^i}) \right],\\
% &q_{\text{CSMC}}\left(\xib_m \backslash \{\xb_m^j, \bb_m\} \mid \xb_m^j, \bb_m, m, j \right) = \nonumber \\
% &\prod_{\substack{i=1\\i\neq b_{1,m}}}^N  q_1(x_{1,m}^i) \cdot \prod_{t=2}^T \prod_{\substack{i=1\\i\neq b_{t,m}}}^N \left[\frac{w_{t-1,m}^{a_{t-1,m}^i}}{\sum_\ell w_{t-1,m}^\ell} q_t(x_{t,m}^i|x_{1:t-1,m}^{a_{t-1,m}^i})\right].
% \end{align*}
Now we are ready to state the main theoretical result.
\begin{theorem}
	\label{thm:one}
	The interacting particle Markov chain Monte Carlo sampler of Algorithm~\ref{alg:ipmc} is a partially collapsed Gibbs sampler \citep{van2008partially} for the target distribution
	\begin{align}
	\label{eq:targetdistribution}
	&\tilde \pi(\xib_{1:M}, c_{1:P}, b_{1:P}) =  \nonumber \\
	&\frac{1}{N^{PT} \binom{M}{P}} \prod_{\substack{m=1\\m\notin c_{1:P}}}^M q_{\text{SMC}}\left(\xib_m\right) \cdot \prod_{j = 1}^P \left[ \pi_T\left(\xb_{c_j}^{b_j}\right) \iden_{c_j \notin c_{1:j-1}} 
	q_{\text{CSMC}}\left(\xib_{c_j} \backslash \{\xb_{c_j}^{b_j}, \bb_{c_j}\} \mid \xb_{c_j}^{b_j}, \bb_{c_j}\right) \right].
	\end{align}
\end{theorem}
\begin{proof}
	The proof follows similar ideas as \citet{andrieuDH2010}. We prove that the interacting particle Markov chain Monte Carlo sampler is in fact a standard partially collapsed Gibbs sampler \citep{van2008partially} on an extended space \[
	{\Upsilon \eqdef \setX^{\otimes MTN} \times [N]^{\otimes M(T-1)N} \times [M]^{\otimes P} \times [N]^{\otimes P}}.
	\]
	%Assume the setup of Section~\ref{sec:method}. %For convenience, we repeat the target distribution $\tilde\pi(\cdot)$, \ie \eqref{eq:targetdistribution}, on $\Upsilon$ here 
	%\begin{align}
	%\label{app:targetdistribution}
	%&\tilde \pi(\xib_{1:M}, c_{1:P}, b_{1:P}) = \nonumber \\
	%& \frac{1}{N^{PT} \binom{M}{P}} \prod_{\substack{m=1\\m\notin c_{1:P}}}^M q_{\text{SMC}}\left(\xib_m\right) \times \prod_{j = 1}^P \pi_T\left(\xb_{c_j}^{b_j}\right) \iden_{c_j \notin c_{1:j-1}} \nonumber \\
	%&\prod_{j = 1}^P q_{\text{CSMC}}\left(\xib_{c_j} \backslash \{\xb_{c_j}^{b_j}, \bb_{c_j}\} \mid \xb_{c_j}^{b_j}, \bb_{c_j}, c_j, b_j \right).
	%\end{align}
	%\begin{align}
	%\label{eq:supptargetdist}
	%\tilde \pi(\xb_{1:M}^{1:N}, \ab_{1:M}^{1:N}, C_{1:P}, B_{1:P}) &= \frac{1}{N^{PT} \binom{M}{P}} \prod_{\substack{m=1\\m\notin C_{1:P}}}^M q_{\text{SMC}}\left(\xb_m^{1:N},\ab_m^{1:N}\right)  \times \prod_{j = 1}^P \pi_T\left(\xb_{C_j}^{B_j}\right) \mathbbm{1}_{C_j \notin C_{1:j-1}}  \nonumber\\
	%&\times \prod_{j = 1}^P q_{\text{CSMC}}\left(\xb_{C_j}^{1:N},\ab_{C_j}^{1:N} \backslash \{\xb_{C_j}^{B_j}, \bb_{C_j}^{B_j}\} \mid \xb_{C_j}^{B_j}, \bb_{C_j}^{B_j}, C_j, B_j \right),
	%\end{align}
	%with $q_{\text{SMC}}(\cdot), ~q_{\text{CSMC}}(\cdot)$ given by the following expressions
	%\begin{align}
	%q_{\text{SMC}}(\xb_m^{1:N},\ab_m^{1:N}) &= \prod_{i=1}^N q_1(x_1^i) \prod_{t=2}^T \frac{W_{t-1}^{a_{t-1,m}^i}}{\sum_\ell W_{t-1,m}^\ell} q_t(x_{t,m}^i|x_{1:t-1,m}^{a_{t-1,m}^i}),\\
	%q_{\text{CSMC}}\left(\xb_m^{1:N},\ab_m^{1:N} \backslash \{\xb_m^k, \bb_m^k\} \mid \xb_m^k, \bb_m^k, m, k \right) &= \prod_{\substack{i=1\\i\neq b_{1,m}}}^N q_1(x_{1,m}^i) \prod_{t=2}^T \prod_{\substack{i=1\\i\neq b_{t,m}}}^N\frac{W_{t-1,m}^{a_{t-1,m}^i}}{\sum_\ell W_{t-1,m}^\ell} q_t(x_{t,m}^i|x_{1:t-1,m}^{a_{t-1,m}^i}),
	%\end{align}
	%where $\bb_m^k = (b_{1,m},\ldots,b_{T,m})$ with the conditional trajectory indices defined recursively as follows $b_{T,m} = k$ and $b_{t,m} = a_{t,m}^{b_{t+1,m}}$.
	With $\tilde\pi(\cdot)$ with as per \eqref{eq:targetdistribution}, we will show that the Gibbs sampler on the extended space, $\Upsilon$, defined as follows	
	\begin{subequations}
		\label{eq:gibbs}
		\begin{align}
		\xib_{1:M} \backslash\{\xb_{c_{1:P}}^{b_{1:P}}, \bb_{c_{1:P}} \} ~&\sim \tilde \pi(~\cdot~|\xb_{c_{1:P}}^{b_{1:P}}, \bb_{c_{1:P}},c_{1:P}, b_{1:P})\label{eq:particles},\\
		c_j &\sim \tilde \pi(~\cdot~|\xib_{1:M}, c_{1:P\backslash j}), ~~j=1,\ldots,P,\label{eq:worker}\\
		b_j &\sim \tilde \pi(~\cdot~|\xib_{1:M}, c_{1:P}), ~~j=1,\ldots,P,\label{eq:index}
		\end{align}
	\end{subequations}
	is equivalent to the \ipmcmc method in Algorithm~\ref{alg:ipmc}.
	%where $\tilde \pi( \cdot )$ is given by \eqref{eq:supptargetdist}.
	
	First, the initial step \eqref{eq:particles} corresponds to sampling from
	\begin{align*}
	\tilde\pi(\xib_{1:M} &\backslash\{\xb_{c_{1:P}}^{b_{1:P}}, \bb_{c_{1:P}} \} | \xb_{c_{1:P}}^{b_{1:P}}, \bb_{c_{1:P}},c_{1:P}, b_{1:P}) = \\ 
	& \prod_{\substack{m=1\\m\notin c_{1:P}}}^M q_{\text{SMC}}\left(\xib_m\right) \prod_{j = 1}^P q_{\text{CSMC}}\left(\xib_{c_j} \backslash \{\xb_{c_j}^{b_j}, \bb_{c_j}\} \mid \xb_{c_j}^{b_j}, \bb_{c_j}, c_j, b_j \right).
	\end{align*}
	This, excluding the conditional trajectories, just corresponds to steps 3--4 in Algorithm~\ref{alg:ipmc}, \ie running $P$ \csmc and $M-P$ \smc algorithms independently.
	
	We continue with a reformulation of \eqref{eq:targetdistribution} which will be useful to prove correctness for the other two steps
	\begin{align}
	\label{eq:reformtargetdist}
	\tilde \pi & (\xib_{1:M},  c_{1:P}, b_{1:P}) \nonumber\\ &=\frac{1}{\binom{M}{P}} \prod_{m=1}^M q_{\text{SMC}}\left(\xib_m\right) \cdot
	\prod_{j = 1}^P \left[
	\iden_{c_j \notin c_{1:j-1}} \nw_{T,c_j}^{b_j}
	\pi_T\left(\xb_{c_j}^{b_j}\right) \frac{q_{\text{CSMC}}\left(\xib_{c_j} \backslash \{\xb_{c_j}^{b_j}, \bb_{c_j}\} \mid \xb_{c_j}^{b_j}, \bb_{c_j}, c_j, b_j \right)}{N^{T} 
		\nw_{T,c_j}^{b_j}
		%\frac{w_{T,c_j}^{b_j}}{\sum_{i=1}^N w_{T,c_j}^i} 
		q_{\text{SMC}}\left(\xib_{c_j}\right)}\right] \nonumber\\
	&= \frac{1}{\binom{M}{P}} \prod_{m=1}^M q_{\text{SMC}}\left(\xib_m\right) \cdot \prod_{j = 1}^P \frac{\hat Z_{c_j}}{Z}\iden_{c_j \notin c_{1:j-1}} 
	\nw_{T,c_j}^{b_j}
	%\frac{w_{T,c_j}^{b_j}}{\sum_{i=1}^N w_{T,c_j}^i}
	.
	\end{align}
	
	Furthermore, we note that by marginalising (collapsing) the above reformulation, \ie \eqref{eq:reformtargetdist}, over $b_{1:P}$ we get
	\begin{align*}
	\tilde\pi(\xib_{1:M}, c_{1:P}) 
	%&= \sum_{b_{1:P}}\tilde\pi(\xib_{1:M}, c_{1:P}, b_{1:P}) \nonumber \\
	&= \frac{1}{\binom{M}{P}} \prod_{m=1}^M q_{\text{SMC}}\left(\xib_m\right) \prod_{j = 1}^P \frac{\hat Z_{c_j}}{Z}\iden_{c_j \notin c_{1:j-1}} .\nonumber
	\end{align*}
	From this it is easy to see that $\tilde\pi(c_j | \xib_{1:M}, c_{1:P\backslash j}) = \hat\nz_{c_j}^j$, which 
	%\begin{align*}
	%\tilde\pi(c_j | \xib_{1:M}, c_{1:P\backslash j}) = \hat\nz_{\pi_T,c_j}^j
	%\tilde\pi(c_j | \xib_{1:M}, c_{1:P\backslash j}) = \frac{\hat Z_{\pi_T,c_j} \iden_{c_j \notin c_{1:P\backslash j}}}{\sum_{m=1}^M \hat Z_{\pi_T,m} \iden_{m \notin c_{1:P\backslash j}}}
	%\end{align*}
	corresponds to sampling the conditional node indices, \ie step 6 in Algorithm~\ref{alg:ipmc}. Finally, from \eqref{eq:reformtargetdist} we can see that simulating $b_{1:P}$ can be done independently as follows
	\begin{align*}
	&\tilde\pi(b_{1:P} | \xib_{1:M}, c_{1:P}) = \frac{\tilde\pi(b_{1:P} ,\xib_{1:M}, c_{1:P})}{\tilde\pi(\xib_{1:M}, c_{1:P})} =  \prod_{j = 1}^P 
	\nw_{T,c_j}^{b_j}
	%\frac{w_{T,c_j}^{b_j}}{\sum_{i=1}^N w_{T,c_j}^i}
	.
	\end{align*}
	This corresponds to step 7 in the \ipmcmc sampler, Algorithm~\ref{alg:ipmc}. So the procedure defined by \eqref{eq:gibbs} is a partially collapsed Gibbs sampler, derived from \eqref{eq:targetdistribution}, and we have shown that it is exactly equal to the \ipmcmc sampler described in Algorithm~\ref{alg:ipmc}.
\end{proof}
\newtheorem{rem}{Remark}
\begin{rem}
	The marginal distribution of $(\xb_{c_{1:P}}^{b_{1:P}},c_{1:P},b_{1:P})$, with $\xb_{c_{1:P}}^{b_{1:P}} = (\xb_{c_1}^{b_1},\ldots,\xb_{c_P}^{b_P})$, under \eqref{eq:targetdistribution} is given by
	\begin{align}
	\label{eq:marginaldistribution}
	&\tilde \pi\left(\xb_{c_{1:P}}^{b_{1:P}},c_{1:P},b_{1:P}\right) = \frac{\prod_{j = 1}^P \pi_T\left(\xb_{c_j}^{b_j}\right) \iden_{c_j \notin c_{1:j-1}}}{N^{PT} \binom{M}{P}} .
	\end{align}
	This means that each trajectory $\xb_{c_j}^{b_j}$ is marginally distributed according to the
	posterior distribution of interest, $\pi_T$. Indeed, the $P$ retained trajectories of \ipmcmc
	will in the limit $R \rightarrow \infty$ %(or $N \rightarrow \infty$) 
	be independent draws from $\pi_T$.
	% , by targeting \eqref{eq:targetdistribution} with an \mcmc sampler we will, in the limit, equivivalently draw $P$ exact samples from $\pi_T$ as a byproduct at each iteration.
\end{rem}
Note that adding a backward or ancestor simulation step can drastically increase mixing when sampling the conditional trajectories $\xb_j'[r]$ \citep{lindsten2013backward}. In the \ipmcmc sampler we can replace simulating from the final weights on line~7 by a backward simulation step. Another option for the \csmc nodes is to replace this step by internal ancestor sampling \citep{lindstenJS2014} steps and simulate from the final weights as normal.
%According to the above remark if we can generate samples from \eqref{eq:targetdistribution} we will equivivalently draw exact samples from $\pi_T$ as a byproduct. We formalize this and show a basic convergence result of the \mcmc samples $\xb^{1:P}[r]$ generated by running Algorithm~\ref{alg:ipmc}.
%\begin{theorem}[Convergence]
%\begin{align}
%\label{eq:convergence}
%\|\mathcal{L}\{\xb^j[r] \in \cdot \}-\pi_T(\cdot) \| \rightarrow 0, \quad \text{as}~~r\to\infty,~\forall j=1,\ldots,P
%\end{align}
%\end{theorem}
%\begin{proof}
%See Section~\ref{} in the supplementary material.
%\end{proof}

% Parameters, Rao-Blackwellization, BS etc.
%\subsection{Extensions and Improvements}
%We will here discuss some potential extensions and improvements on the \ipmcmc. The first one, making use of all particles, we use in the experiments and the following two, introducing backward simulation and asynchronous implementation, we leave for future work.


% How to use all particles when estimating expectations
\subsubsection{Using All Particles}
\label{sec:allparticles}
At each \mcmc iteration $r$, we generate $MN$ full particle trajectories. Using only $P$ of these as in \eqref{eq:mcestimate} might seem a bit wasteful. We can however make use of all particles to estimate expectations of interest by, for each Gibbs update $j$, averaging over the possible new values for the conditional node index $c_j$ and corresponding particle index $b_j$. We can do this by replacing $f(\xb_j'[r])$ in \eqref{eq:mcestimate} by
\begin{align*}
\E_{c_j|c_{1:P\backslash j}}\left[\E_{b_j | c_j}\left[f(\xb_j'[r])\right]\right] 
= \sum_{m=1}^M 
\hat\nz_{m}^j
%\frac{\hat Z_{\pi_T,m} \iden_{m \notin c_{1:P \backslash j}}}{\sum_n \hat Z_{\pi_T,n} \iden_{n \notin c_{1:P \backslash j}}} 
\sum_{i=1}^N
\nw_{T,m}^i f(\xb_{m}^i).
%\frac{w_{T,m}^{i}}{\sum_\ell w_{T,m}^{\ell}} f(\xb_{m}^i),
\end{align*}
This procedure is referred to as a Rao-Blackwellization of a statistical estimator and is (in terms of variance) never worse than the original one.  We highlight that each $\hat\nz_{m}^j$, as defined in~\eqref{eq:zeta_def}, depends on which indices are sampled earlier in the index reassignment loop.  

To derive this we first note that for iteration $r$ we need to calculate the following
\begin{align*}
\frac{1}{P}\sum_{j=1}^P f(\xb_j'[r]) = \frac{1}{P}\sum_{j=1}^P f(\xb_{c_j}^{b_j}),
\end{align*}
where we can Rao-Blackwellize the selection of the retained particle along with each individual Gibbs update as following
\begin{align*}
\frac{1}{P}\sum_{j=1}^P \E_{c_j, b_j | \xi_{1:M}, c_{1:P \backslash j}}\left[f(\xb_{c_j}^{b_j}) \right] =& \frac{1}{P}\sum_{j=1}^P \E_{c_j | \xi_{1:M}, c_{1:P \backslash j}}\left[\sum_{i=1}^N \bar w_{T,c_j}^i  f(\xb_{c_j}^{i}) \right] \\ =& \frac{1}{P}\sum_{j=1}^P \sum_{i=1}^N \E_{c_j | \xi_{1:M}, c_{1:P \backslash j}}\left[\bar w_{T,c_j}^i  f(\xb_{c_j}^{i}) \right] \\
=& \frac{1}{P}\sum_{j=1}^P \sum_{i=1}^N \sum_{m=1}^M \hat \zeta_m^j \bar w_{T,m}^i  f(\xb_{m}^{i}) \\=& \frac{1}{P}\sum_{j=1}^P \sum_{m=1}^M \hat \zeta_m^j \sum_{i=1}^N \bar w_{T,m}^i  f(\xb_{m}^{i})
\\=& \frac{1}{P} \sum_{m=1}^M  \left[\left(\sum_{j=1}^P \hat \zeta_m^j \right) \cdot \left(\sum_{i=1}^N \bar w_{T,m}^i  f(\xb_{m}^{i}) \right)\right].
%&\E_{c_j|c_{1:P\backslash j}}\left[\E_{b_{1:P}}\left[\frac{1}{P}\sum_{j=1}^P f(\xb_{c_j}^{b_j})\right]\right] = \frac{1}{P}\sum_{j=1}^P \E_{c_j|c_{1:P\backslash j}}\left[\E_{b_{1:P}}\left[ f(\xb_{c_j}^{b_j})\right]\right] = \frac{1}{P}\sum_{j=1}^P \E_{c_j|c_{1:P\backslash j}}\left[ \sum_{i=1}^N \bar w_{T,c_j}^i  f(\xb_{c_j}^{i})\right] \\
%&= \frac{1}{P}\sum_{j=1}^P \sum_{i=1}^N \E_{c_j|c_{1:P\backslash j}}\left[ \bar w_{T,c_j}^i  f(\xb_{c_j}^{i})\right] = \frac{1}{P}\sum_{j=1}^P \sum_{i=1}^N \sum_{m=1}^M \hat \zeta_m^j \bar w_{T,m}^i  f(\xb_{m}^{i}) = \frac{1}{P}\sum_{j=1}^P \sum_{m=1}^M \hat \zeta_m^j \sum_{i=1}^N \bar w_{T,m}^i  f(\xb_{m}^{i}),
\end{align*}
Here we have made use of the knowledge that the internal particle system $\{(\xb_{m}^{i},\bar w_{T,m}^i)\}$ does not change between Gibbs updates of the $c_j$'s, whereas the $\hat \zeta_m^j$ do.  We emphasise that this is a separate Rao-Blackwellization of each Gibbs update of the conditional node indices, such that each is conditioned upon the actual update made at $j-1$, rather than a simultaneous Rao-Blackwellization of the full batch of $P$ updates.  Though the latter also has analytic form and should theoretically be lower variance, it suffers from inherent numerical instability and so is difficult to calculate in practise.  We found that empirically there was not a noticeable difference between the performance of the two procedures.  Furthermore, one can always run additional Gibbs updates on the $c_j$'s and obtain an improve estimate on the relative sample weightings if desired.

%\tom{I feel it might be better to move the asynchronous and backward simulation to the discussion section given we are leaving them for future work?}

% Introduce \theta and sample that as well
%\subsubsection{Static Parameters}
%We can also use the \ipmcmc algorithm to sample static parameters $\theta$ in a Gibbs-type method by alternating between sampling latent variables $x_{1:T}$ and $\theta$. The basic version of this would add two extra steps in Algorithm~\ref{alg:ipmc} by simulating new parameters from the full conditional distributions for the \csmc nodes and the parameter prior for the standard \smc nodes.

\subsubsection{Choosing P}
\label{sec:choosingP}
Before jumping into the full details of our experimentation, we quickly consider the choice of $P$. Intuitively we can think of the independent \smc's as particularly useful if they are selected as the next conditional node. The probability of the event %(denoted by $\mathcal{S}$) 
that at least one conditional node switches with an unconditional, is given by
\begin{align}
\label{eq:switchingprob}
%\Prb(\mathcal{S}) 
\Prb(\{\text{switch}\}) 
= 1 - \E\Big[\prod_{j=1}^P \frac{\hat Z_{c_j}}{\hat Z_{c_j} +\sum_{m \notin c_{1:P}}^M \hat Z_{m}}\Big].
\end{align}
There exist theoretical and experimental results \citep{pitt2012some,berard2014lognormal,doucet2015efficient} that show that the distributions of the normalisation constants are well-approximated by their log-Normal limiting distributions. Now, with $\sigma^2$ ($\propto \frac{1}{N}$) being the variance of the (C)\smc estimate, it means we have $\log \left(Z^{-1} \hat Z_{c_j} \right) \sim \N(\frac{\sigma^2}{2},\sigma^2)$ and $\log \left(Z^{-1} \hat Z_{m} \right) \sim \N(-\frac{\sigma^2}{2},\sigma^2)$, $m\notin c_{1:P}$ at stationarity, where $Z$ is the true normalization constant. Under this assumption, we can accurately estimate the probability \eqref{eq:switchingprob} for different choices of $P$ an example of which is shown in Figure~\ref{fig:theSwitchingProb} along with additional analysis in Appendix~\ref{sec:supp-choosep}. These provide strong empirical evidence that the switching probability is maximised for $P=M/2$.

\begin{figure}[t]
	\centering
	\begin{subfigure}[t]{0.4\textwidth}
		\includegraphics[height=0.75\textwidth]{swtiching_prob_sweep_sigma_3}
		\caption{Limiting log-Normal\label{fig:theSwitchingProb}}
	\end{subfigure}
	~~~~~~~~~~~
	\begin{subfigure}[t]{0.4\textwidth}
		\includegraphics[height=0.75\textwidth]{big_font_p_sweep}
		\caption{Gaussian state space model\label{fig:Psweep}}
	\end{subfigure}
	\caption{a) Estimation of switching probability for different choices of P and M assuming the log-Normal limiting distribution for $\hat{Z}_m$ with $\sigma=3$. b) Median error in mean estimate for different choices of P and M over 10 different synthetic datasets of the linear Gaussian state space model given in~\eqref{eq:LGSS} after 1000 MCMC iterations. Here errors are normalized by the error of a multi-start PG sampler which is a special case of iPMCMC for which $P=M$ (see Section \ref{sec:experiments}).
	}
\end{figure}

%
%\begin{figure}[h]
%
%\end{figure}
%~ %add desired spacing 

In practice we also see that best results are achieved when $P$ makes up roughly half of the nodes, see Figure~\ref{fig:Psweep} for performance on the state space model introduced in~\eqref{eq:LGSS}. Note also that the accuracy seems to be fairly robust with respect to the choice of $P$. % At least for this model, three things are clear from this sweep - firstly the optimal choice for the ratio of P/M is roughly 1/2, secondly that the performance of iPMCMC is relatively robust to changes in P around this optimum and thirdly that as $M$ increases, to relatively more preferable iPMCMC is to the trivial distribution of PG given by $P=M$ (this reason this occurs is discussed in more detail in Section \ref{sec:discussion}). 
%
Based on these results, we set the value of $P=\frac{M}{2}$ for the rest of our experiments.
