% !TEX root = ../../main.tex

% Discussion for things such as choice of P
\subsection{Discussion}
\label{sec:discussion}

The \ipmcmc sampler overcomes degeneracy issues in \pg by allowing the newly sampled particles from \smc nodes to replace the retained particles in \csmc nodes. Our experimental results demonstrate that, for the models considered, this switching in rate is far higher than the rate at which PG generates fully independent samples. Moreover, the results in Figure~\ref{fig:Psweep} suggest that the degree of improvement over an m\pg sampler with the same total number of nodes increases with the total number of nodes in the pool. 
The mAPG sampler performs an accept reject step that compares the marginal likelihood estimate of a single \csmc sweep to that of a single \smc sweep. In the \ipmcmc sampler the \csmc estimate of the marginal likelihood is compared to a population sample of \smc estimates, resulting in a higher probability that at least one of the \smc nodes will become a \csmc node.
Since the original \pmcmc paper~\citep{andrieu2009pseudo} there have been several papers studying %\fredrik{Should we give some references to theoretical work on PG? for instance, I know of a paper in SJOS which is very good ;)}
and improving upon the basic \pg
 algorithm~\citep{chopin2015,lindsten2015uniform,whiteley2010efficient,lindsten2013backward,lindstenJS2014},
 many of which also be used to improve the \ipmcmc method ever further.  

%Noting that the Gibbs update in \eqref{eq:simConditional} requires no interaction between the \csmc nodes, iPMCMC should be amenable to an asynchronous adaptation under the assumption of a random execution time, independent of $\xb'$, in Algorithm~\ref{alg:csmc}.

%For this one would run a number of \smc nodes independently, communicating only their normalisation constant estimate and a sampled trajectory to a pool of possible retained particles with associated weights.  Whenever a \csmc sweep finishes its execution, it samples a new retained particle from either the pool or itself, replenishing the pool with a new sample if the new retained particle was not from the original \csmc sweep.  It should be noted that as this pool could be increased indefinitely, this adaptation has the potential to increase the scope and potential performance of iPMCMC even further.



% MOVED BACK TO METHODS
% Use backward sampling and/or ancestor sampling
%\subsection{Backward Simulation and Ancestor Sampling}
%Adding a backward or ancestor simulation step can drastically increase mixing when sampling the conditional trajectories $\xb_j'[r]$ \citep{lindsten2013backward}. In the \ipmcmc sampler we can replace simulating from the final weights on line~7 by a backward simulation step. Another option for the \csmc nodes is to replace this step by internal ancestor sampling \citep{lindstenJS2014} steps and simulate from the final weights as normal.



%To explain the benefits of \ipmcmc  over mPIMH and mAPG methods consider a mAPG sampler where the PG and PIMH updates are out of sync for the different nodes such that at any particular MCMC iteration, half of the nodes are applying a PG update and the other half a PIMH update.  One could now informally view the sampling of the retained particles in mAPG as a simplified version of iPMCMC with $P=M/2$, except that the node-weights have been set equally and each of the unconditional SMC sweeps has been arbitrarily assigned as a proposal for one of the CSMC nodes.  Clearly this arbitrary assignment is detrimental as whilst the conditional nodes in iPMCMC consider both themselves and all the of the unconditional nodes for sampling a new retained particle, in mAPG they are restricted to drawing from either themselves or single alternative SMC sweep.  iPMCMC thus, in an informal sense, only requires the lowest of the CSMC node weights to be comparable to the highest of SMC node weights for switching to occur, whereas mAPG requires one of the arbitrary pairings to be comparable.  We therefore recommend setting $M$ as higher as possible, potentially even beyond the level of distribution available, noting the performance improvements of serialized PG shown in the supplementary material.



%Whenever PG degenerates to a single particle, this is guaranteed to correspond to the retained particle.  Therefore PG requires multiple particles to be retained from the start of the state sequence in order to generate new unique samples for all the latent variables in an MCMC iteration, causing it to become stuck at the same sample for variables early in the state sequence.  To quantify this improvement we note that $14.9\%$ of the retained particles produced by the iPMCMC sampler (after a short burn-in period), originated from unconditional SMC sweeps at the previous iteration.  Further, on average $85.4\%$ of the MCMC iterations for iPMCMC generated new retained particles for all stages of the state sequence. This contrasts with each PG sampler in mPG case producing an entirely new retained particle at a rate of only $0.076\%$.

%To explain the benefits of iPMCMC over mPIMH and mAPG consider a mAPG sampler where the PG and PIMH updates are out of sync for the different nodes such that at any particular MCMC iteration, half of the nodes are applying a PG update and the other half a PIMH update.  One could now informally view the sampling of the retained particles in mAPG as a simplified version of iPMCMC with $P=M/2$, except that the node-weights have been set equally and each of the unconditional SMC sweeps has been arbitrarily assigned as a proposal for one of the CSMC nodes.  Clearly this arbitrary assignment is detrimental as whilst the conditional nodes in iPMCMC consider both themselves and all the of the unconditional nodes for sampling a new retained particle, in mAPG they are restricted to drawing from either themselves or single alternative SMC sweep.  iPMCMC thus, in an informal sense, only requires the lowest of the CSMC node weights to be comparable to the highest of SMC node weights for switching to occur, whereas mAPG requires one of the arbitrary pairings to be comparable.  We therefore recommend setting $M$ as higher as possible, potentially even beyond the level of distribution available, noting the performance improvements of serialized PG shown in the supplementary material.

%Referring back to Figure~\ref{fig:Psweep}, we see that as $M$ is increased, the better the relative performance of iPMCMC.  As the reported errors are as a proportion of error given by mPG with the same $M$, this improvement is not simply because more computational resources have been allocated, but because the ``pool" from which the retained node indexes can be draw increases.  As the distribution in the ratio of CSMC node weights to SMC node weights is independent of $M$, the probability that all of the retained particles at the next MCMC iteration originate from the CSMC sweeps diminishes as shown by INSERT REF DEPENDING ON WHETHER IN SUP OR SEC XX.  The resulting improvement in performance with increasing $M$ seen in Figure~\ref{fig:Psweep} thus verifies the benefits from the increase interaction provided by iPMCMC.