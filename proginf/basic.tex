% !TEX root = ../main.tex

\section{Basic Inference Algorithms for Universal Programs}
\label{sec:proginf:inf}

We start our introduction to some basic general purpose inference algorithms for
universal PPLs by linking our Anglican compilation back to our execution-based 
definition of the conditional distribution specified by a program given in 
Section~\ref{sec:probprog:models:general} and consider what classes of inference
algorithms might be able to operate in such settings.  Taking stock, what has our compilation
given access to and what do we not have access to?  We have means of running the program
forwards and controlling the behavior at each \sample and \observe statement.  We can
stop or restart the program at any one of our checkpoints and chose whether to do so
adaptively, for example, by killing of certain evaluations or duplicating others.  Once
a program is run, we can test the effect of changing one or more of our sampled variables
in an MCMC fashion, though it may be difficult to statically determine an appropriate global proposal
as we can only establish the structure of the target through evaluation.  Though we might be
able to do so with other other code analysis, we do not directly have access to any information
about independence relationships or even knowledge under what conditions a certain
variable will exist.  We can transfer information from one sampling iteration to the next
using a database, giving us the potential to avoid repeated computation or adaptively learn proposals.
In theory, we can query the probability of any fixed set of parameter values, by effectively making
\sample operate as an \observe statement, though it may be difficult, or even impossible, to find
combinations that have non-zero probability unless those combinations are generated by running
the program forwards.\todo{Something about implicitly assuming zero prob for impossible traces.}