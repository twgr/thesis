% !TEX root =  main.tex

\section{Implications For Nesting Probabilistic Programs}
\label{sec:design:imp}

Given our results, it is now natural to ask the question what the implications
for nesting probabilistic programming queries?  In particular, when is doing
this valid and are their any precautions we can take to avoid problems?  Before
we get to these question though, we first need to explicitly define what we
mean by a nested query.  To this end, we distinguish between nested calling
structures (such as the example given in Figure~\ref{fig:probprog:schell}) and
queries that do not represent a single estimation, which we will refer
to as nested queries.  Both of these cases have at times been referred to as
nested queries in the literature.  Our motivation for defining only the later
as nested is that the former can always be represented as a single
query because they still represent a single expectation and define models
for which the unnormalized target distribution can be evaluated exactly
~\eqref{eq:probprog:universal-cond}.  Therefore, although these models are
of clear importance, they are not a fundamentally different problem class
to standard Bayesian inference problems and so we assert that existing MC
converge results directly apply.  However, the distinction between models that
use nested calling and nested queries can be surprisingly difficult to establish.
For example, the Schelling coordination example we gave in Figure~\ref{fig:probprog:schell}
was clearly an example of a nested calling structure, but was explicitly a single query.
On the other hand, the original version of this problem in~\cite[]{stuhlmuller2014reasoning}
is actually an (equivalent!) example of a nested query problem because the Church
query 

Conditional renormalization.

Discrete and continuous problems are a fundamentally different problem class
because of Theorem~\ref{the:finite-res}.

\todo[inline]{Voting probprog example?}

%We have shown that it is theoretically possible for a nested Monte Carlo scheme to yield a
%consistent estimator, and have quantified the convergence error associated with doing so.
%However, we have also revealed a number of pitfalls that can arise if nesting is applied
%na\"{i}vely, such as the resulting estimator becoming necessarily biased, requiring additional
%assumptions on $f$, being unlikely to converge unless the number of samples used in the inner
%estimator is driven to infinity,
%and is likely to converge at a significantly slower rate than un-nested Monte
%Carlo. These results have implications for applications ranging from experimental design
%to probabilistic programming, and serve both as an invitation for further inquiry and a
%caveat against careless use.

%We have shown that although consistent nested inference is still possible, it is inherently biased, requires Lipshitz continuity, and has a convergence rate that reduces exponentially in the nesting depth.  
%These results have implications for many applications such as experimental design and probabilistic programming.
%For the latter, it shows that when there is only a linear dependence on the nested query, the problem can be unravelled to a single inference, but that otherwise there are additional severe restrictions on the problems that can be solved and the performance that can be achieved.
%When there is only a linear dependence of the outer integration on the nested expectation, the problem can be unravelled to a single inference, therefore, although nested queries in probabilistic programs do increase the scope of models which can be defined, these models have continuity restrictions and only permit MC inference at prohibitively slower convergence rates than ordinary inference.
